{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"The Journey towards Lovem \u00b6 This is a journal for my journey towards building a low overhead virtual embedded machine . What that is and why I started building it will come clear from the entries in this journal. For some reason I feel the need to add the history of lovem's creation (so far) to it. So I wrote down the history of it before I recently came back to it in three articles, which I then shamelessly split into multiple shorter posts, so I have more to publish. This is new to me, let's see what will happen! My work on lovem so far has been focused on self education. Why not share my insights? I hope it will be useful to someone \u2013 maybe even for my future self? \u2014 The journey starts here \u2014 Lovem \u00b6 Lovem is meant to become a virtual machine for use in constrained embedded devices. It was started by me, @kratenko , for reasons I am writing about in this journal You can find lovem on GitHub: https://github.com/kratenko/lovem Me \u00b6 If for some reason you want to contact me, you can find me on Mastodon @kratenko@chaos.social or of course on GitHub as @kratenko . This site \u00b6 So I quickly googled mkdocs blog to find some sensible way to document my journey online. https://squidfunk.github.io/mkdocs-material/blog/ was not quite what I was looking for. It is the blog of @squidfunk the guy who writes Material for MkDocs , where they blog about their work on Material for MkDocs. They (unsurprisingly) do this with the help of Material for MkDocs. It looks like the blog entries are generated by some preprocessing script, which I might be trying to also build at some point, because I like the previews on the \"Blog\" page. So, big shout out to @squidfunk for their work! I managed to hack together a little script I called blogem , that solves blogging for me. It is not ready to be used for other projects, but if you are curious, you are welcome to take a look at it. It uses mkdocs-gen-files and mkdocs-literate-nav by @oprypin . Or maybe it abuses those plugins, I'm not sure, but it works for now. See Journal entry State of the journal for more that part of the story. Pretty sure I will change every thing again at some point. But currently, I quite like it.","title":"The Journey"},{"location":"index.html#the-journey-towards-lovem","text":"This is a journal for my journey towards building a low overhead virtual embedded machine . What that is and why I started building it will come clear from the entries in this journal. For some reason I feel the need to add the history of lovem's creation (so far) to it. So I wrote down the history of it before I recently came back to it in three articles, which I then shamelessly split into multiple shorter posts, so I have more to publish. This is new to me, let's see what will happen! My work on lovem so far has been focused on self education. Why not share my insights? I hope it will be useful to someone \u2013 maybe even for my future self? \u2014 The journey starts here \u2014","title":"The Journey towards Lovem"},{"location":"index.html#lovem","text":"Lovem is meant to become a virtual machine for use in constrained embedded devices. It was started by me, @kratenko , for reasons I am writing about in this journal You can find lovem on GitHub: https://github.com/kratenko/lovem","title":"Lovem"},{"location":"index.html#me","text":"If for some reason you want to contact me, you can find me on Mastodon @kratenko@chaos.social or of course on GitHub as @kratenko .","title":"Me"},{"location":"index.html#this-site","text":"So I quickly googled mkdocs blog to find some sensible way to document my journey online. https://squidfunk.github.io/mkdocs-material/blog/ was not quite what I was looking for. It is the blog of @squidfunk the guy who writes Material for MkDocs , where they blog about their work on Material for MkDocs. They (unsurprisingly) do this with the help of Material for MkDocs. It looks like the blog entries are generated by some preprocessing script, which I might be trying to also build at some point, because I like the previews on the \"Blog\" page. So, big shout out to @squidfunk for their work! I managed to hack together a little script I called blogem , that solves blogging for me. It is not ready to be used for other projects, but if you are curious, you are welcome to take a look at it. It uses mkdocs-gen-files and mkdocs-literate-nav by @oprypin . Or maybe it abuses those plugins, I'm not sure, but it works for now. See Journal entry State of the journal for more that part of the story. Pretty sure I will change every thing again at some point. But currently, I quite like it.","title":"This site"},{"location":"source-code.html","text":"Source Code \u00b6 Getting the source code \u00b6 The best way to work with the source code, is cloning the complete repo to your computer. If you do not know how to do that, GitHub has documentation on cloning a repositry . The way to do this in bash: git clone git@github.com:kratenko/lovem.git Or, if you have problems using git over ssh, use https: git clone https://github.com/kratenko/lovem.git This will create a directory named lovem inside your current directory, that holds all the source code and its complete history as a git repository. Tags \u00b6 Lovem is a developing project that I write about while creating it. My journal entries (blog posts, if you prefere) often talk about a very distinct state of the source code. I am describing, what I do, while I do it. It is a very likely possibility, that at the time you are reading my journal entries, the code will look nothing like it did, when I posted the entry. I will dump a lot of my ideas. Sometimes I write code that I know I will be changing, in order to illustrate my thoughts and, ultimately, to let you participate in my journey. Luckily, it is easy for us, to travel back in time, using the magical powers of git! To make it easy, I will create a tag (and with it a pre-release) for the entries that refer to source code. They should be named something like v1.2.3-journey , and you can find them in header card of the entries (where author and publication date, etc. are shown). At the bottom of the pages, holding entries with a tag, there will be some additional links that take you directly to the source code of that tag. The easiest way to view source code for my posts, is having the repository cloned locally , and then checking out the tag. So, if you want to check out tag v1.2.3-journey , while inside your lovem directory, simply type: git checkout v1.2.3-journey And you will have the code for that journal entry ready to be inspected with you favourite IDE or editor. And you can fire up cargo to build the code and run the examples. You can then mess around with the source and try out stuff. This really helps to understand what we are doing! And the best thing: you can mess around as much as you like. It is git! You can always switch back to the current state of the code by typing git checkout master You can even commit your tinkering to your own copy of the repo - be it inside your own branches, or however you prefer. I will not be linking to the source code explicitly in my entries (only in the first ones, before I introduced this). So be sure to use the link at the top or bottom, to find the source \u2013 or better yet, just check out the tag in your local repo clone. The git command will be listed in the bottom of the entry.","title":"Source Code"},{"location":"source-code.html#source-code","text":"","title":"Source Code"},{"location":"source-code.html#getting-the-source-code","text":"The best way to work with the source code, is cloning the complete repo to your computer. If you do not know how to do that, GitHub has documentation on cloning a repositry . The way to do this in bash: git clone git@github.com:kratenko/lovem.git Or, if you have problems using git over ssh, use https: git clone https://github.com/kratenko/lovem.git This will create a directory named lovem inside your current directory, that holds all the source code and its complete history as a git repository.","title":"Getting the source code"},{"location":"source-code.html#tags","text":"Lovem is a developing project that I write about while creating it. My journal entries (blog posts, if you prefere) often talk about a very distinct state of the source code. I am describing, what I do, while I do it. It is a very likely possibility, that at the time you are reading my journal entries, the code will look nothing like it did, when I posted the entry. I will dump a lot of my ideas. Sometimes I write code that I know I will be changing, in order to illustrate my thoughts and, ultimately, to let you participate in my journey. Luckily, it is easy for us, to travel back in time, using the magical powers of git! To make it easy, I will create a tag (and with it a pre-release) for the entries that refer to source code. They should be named something like v1.2.3-journey , and you can find them in header card of the entries (where author and publication date, etc. are shown). At the bottom of the pages, holding entries with a tag, there will be some additional links that take you directly to the source code of that tag. The easiest way to view source code for my posts, is having the repository cloned locally , and then checking out the tag. So, if you want to check out tag v1.2.3-journey , while inside your lovem directory, simply type: git checkout v1.2.3-journey And you will have the code for that journal entry ready to be inspected with you favourite IDE or editor. And you can fire up cargo to build the code and run the examples. You can then mess around with the source and try out stuff. This really helps to understand what we are doing! And the best thing: you can mess around as much as you like. It is git! You can always switch back to the current state of the code by typing git checkout master You can even commit your tinkering to your own copy of the repo - be it inside your own branches, or however you prefer. I will not be linking to the source code explicitly in my entries (only in the first ones, before I introduced this). So be sure to use the link at the top or bottom, to find the source \u2013 or better yet, just check out the tag in your local repo clone. The git command will be listed in the bottom of the entry.","title":"Tags"},{"location":"2022-06/index.html","text":"Journal entries from June 2022 \u00b6 Read all in single page Script or virtual \u00b6 After the quest for a scripting languages failed, we plan writing our own. kratenko \u00b7 kratenko 2022-06-28 \u00b7 Entry #4 \u00b7 2 min read Script it then! \u00b6 Okay, okay. Let's say you bought my argumentation. Go ahead, hack together some scripting, knock yourself out. Just parse it in your firmware and execute it. Continue reading That use-case I was talking about \u00b6 This is why every existing scripting language is objectively bad! Sorry, I wanted to say: This is my problem and languages do not seem to be designed for it. kratenko \u00b7 kratenko 2022-06-27 \u00b7 Entry #3 \u00b7 2 min read I was mentioning it, was I not? Languages do not seem to fit very well on by problem. What do I mean by that? Continue reading We need another wheel \u00b6 There are many wheels out there, why o why do you want to invent it again? Well, are there, though? Because that is what I thought. I started looking at what I know. Soo... kratenko \u00b7 kratenko 2022-06-26 \u00b7 Entry #2 \u00b7 4 min read Lua \u00b6 [Lua][lua] is a tested scripting language to use in host languages like C. I first experimented with it when I was trying to write games for fun, back in the early 2000s. I was somewhat intrigued when I came upon it again some 10 years later while playing heavily modded Minecraft. In [ComputerCraft][computercraft] you have a block that is a computer, which you can write programs for in Lua. It even has a little operating system where you store your files (edit them, horribly, in an editor on an in-game monitor), execute programs that you can store on in-game floppies to carry around. It was a horrible kind of fun to do just anything inside that world. Continue reading Lovem again! \u00b6 It seems like that dude dug out one of his time-wasting projects and put some more work into it. This time in a public repo even. And for some reason he wants to let the world know, how and what he is doing. The journey starts here. kratenko \u00b7 kratenko 2022-06-24 \u00b7 Entry #1 \u00b7 2 min read So, I am back at writing my Low Overhead Virtual Embedded Machine . From scratch. Everything I had was dumped (have the code still, somewhere, but it is okay to start anew - I learned during my previous attempts). Continue reading","title":"Journal entries from June 2022"},{"location":"2022-06/index.html#journal-entries-from-june-2022","text":"Read all in single page","title":"Journal entries from June 2022"},{"location":"2022-06/index.html#script-or-virtual","text":"After the quest for a scripting languages failed, we plan writing our own. kratenko \u00b7 kratenko 2022-06-28 \u00b7 Entry #4 \u00b7 2 min read","title":"Script or virtual"},{"location":"2022-06/index.html#script-it-then","text":"Okay, okay. Let's say you bought my argumentation. Go ahead, hack together some scripting, knock yourself out. Just parse it in your firmware and execute it. Continue reading","title":"Script it then!"},{"location":"2022-06/index.html#that-use-case-i-was-talking-about","text":"This is why every existing scripting language is objectively bad! Sorry, I wanted to say: This is my problem and languages do not seem to be designed for it. kratenko \u00b7 kratenko 2022-06-27 \u00b7 Entry #3 \u00b7 2 min read I was mentioning it, was I not? Languages do not seem to fit very well on by problem. What do I mean by that? Continue reading","title":"That use-case I was talking about"},{"location":"2022-06/index.html#we-need-another-wheel","text":"There are many wheels out there, why o why do you want to invent it again? Well, are there, though? Because that is what I thought. I started looking at what I know. Soo... kratenko \u00b7 kratenko 2022-06-26 \u00b7 Entry #2 \u00b7 4 min read","title":"We need another wheel"},{"location":"2022-06/index.html#lua","text":"[Lua][lua] is a tested scripting language to use in host languages like C. I first experimented with it when I was trying to write games for fun, back in the early 2000s. I was somewhat intrigued when I came upon it again some 10 years later while playing heavily modded Minecraft. In [ComputerCraft][computercraft] you have a block that is a computer, which you can write programs for in Lua. It even has a little operating system where you store your files (edit them, horribly, in an editor on an in-game monitor), execute programs that you can store on in-game floppies to carry around. It was a horrible kind of fun to do just anything inside that world. Continue reading","title":"Lua"},{"location":"2022-06/index.html#lovem-again","text":"It seems like that dude dug out one of his time-wasting projects and put some more work into it. This time in a public repo even. And for some reason he wants to let the world know, how and what he is doing. The journey starts here. kratenko \u00b7 kratenko 2022-06-24 \u00b7 Entry #1 \u00b7 2 min read So, I am back at writing my Low Overhead Virtual Embedded Machine . From scratch. Everything I had was dumped (have the code still, somewhere, but it is okay to start anew - I learned during my previous attempts). Continue reading","title":"Lovem again!"},{"location":"2022-06/ALL.html","text":"Complete month of June 2022 \u00b6 Lovem again! \u00b6 It seems like that dude dug out one of his time-wasting projects and put some more work into it. This time in a public repo even. And for some reason he wants to let the world know, how and what he is doing. The journey starts here. kratenko \u00b7 kratenko 2022-06-24 \u00b7 Entry #1 \u00b7 2 min read So, I am back at writing my Low Overhead Virtual Embedded Machine . From scratch. Everything I had was dumped (have the code still, somewhere, but it is okay to start anew - I learned during my previous attempts). Why? \u00b6 Why am I doing this? Well, that has a history. Basically, I am writing firmware at work for our IIoT devices. They are pretty versatile, so configuring them tends to be rather complicated. And still, I want them to be able to do more: react to situations depending on sensor data, prepare data read from sensors, so that it transmitted with less overhead, etc. Right now, that would mean writing custom firmware for those customer cases (in C) and deploy it for their devices - and maintain those firmwares over years. And no one wants to pay for that! Nor do I care to do the maintaining. What's the alternative? Add those features to the standard firmware and add more configuration features. Great. So it will be even more complicated. And every second time you have a new use case, you will find your current solution insufficient, so you need to modify your firmware again to include that one more special case. And make your config more powerful (please keep it backwards compatible, while you at it, thank you very much - remember, there are thousands of devices out there, that still need to work with their configuration, when the firmware update hits them). And your config? You want to be able to react to triggers, and you want to do react in any random way. And you want to be able to manipulate your data points in any way needed. So when you walk that road for some time, you will end up with a configuration that is basically a programming language, since that is the only thing powerful enough, to do all that. And it will be a badly grown one, you can be sure about that! So let's embrace that consequence, and simply start with using a scripting language as means for advanced configuration! We will end there, cut some corners on the journey! Sorry, what are we trying to do again? \u00b6 We are in need of a scripting language that runs on a very constrained device. Think of a microcontroller that has 352 kiB flash space and 191 kiB RAM for our complete firmware. And keep in mind that most of the behaviour of our device will not be implemented in the scripting language. There will be a number of hooks that should give control to the user supplied script, which will execute for a very short time, collect some data from sensors, act on them (maybe control actuators, but mostly generate data to be uploaded), and then return control to the firmware. And yeah, we will need to store the \"script\" somewhere on that device, so it would be great if it was not multiple kiB of program. I could use an SD-card in the dive (so I guess could store 1 TiB of script on the device if I needed), but those are not that reliable and are an optional extension that could already have a different use. We need another wheel \u00b6 There are many wheels out there, why o why do you want to invent it again? Well, are there, though? Because that is what I thought. I started looking at what I know. Soo... kratenko \u00b7 kratenko 2022-06-26 \u00b7 Entry #2 \u00b7 4 min read Lua \u00b6 Lua is a tested scripting language to use in host languages like C. I first experimented with it when I was trying to write games for fun, back in the early 2000s. I was somewhat intrigued when I came upon it again some 10 years later while playing heavily modded Minecraft. In ComputerCraft you have a block that is a computer, which you can write programs for in Lua. It even has a little operating system where you store your files (edit them, horribly, in an editor on an in-game monitor), execute programs that you can store on in-game floppies to carry around. It was a horrible kind of fun to do just anything inside that world. Lua was invented to solve a similar sounding problem: scripting in computer games. Level designers, story writers, etc. should not be bothered with having to write C-code to achieve their tasks (and re-compiling during developing those is not the way). So yeah, that is, more or less, my problem. And you can even compile Lua to byte code which is run in the interpreter. Neado! But, oh, the interpreter... turn's out, it is quite big! At least when you are working with embedded hardware. To quote lua users : Smaller footprint than Python. e.g. Look at the size of python22.dll, 824kb. A basic Lua engine, including parser/compiler/interpreter, but excluding standard libraries, weighs in at under 100kb. That's fine and all, but still a bit much for me - to be fair, I would need neither parser nor compiler. Other sources give numbers like <300 kB - which is overkill. I did compile it for our architecture - and the VM alone, without any of our own code doing stuff, exceeded the flash size I had. This stackoverflow question quotes the eLua FAQ to recommend 256 kB flash and 64k kB RAM which is too much for me - at time of writing this, eLua documentation seems offline in parts, so that does not give me confidence either. Quote from an answer to that question : I would recommend LUA (or eLUA http://www.eluaproject.net/ ). I've \"ported\" LUA to a Cortex-M3 a while back. From the top of my head it had a flash size of 60~100KB and needed about 20KB RAM to run. I did strip down to the bare essentials, but depending on your application, that might be enough. There's still room for optimization, especially about RAM requirements, but I doubt you can run it comfortable in 8KB. Back then I found a post I cannot find again that claimed, you can get the footprint of the Java VM smaller than that of the Lua VM (if you cut standard lib, which is part of Java and not of its VM). That sounds possible to me, when you have a glimpse on how those languages work. But then again you would not have any of the parts you are used to in Java. Also, there are some thoughts on how fitting that language is for my case, I'll have something about that later on. So I dropped that. Java VM \u00b6 So... to the JVM then? To be honest: I do not want to go there. It does not feel right! JVM does not mean Java, I know that. I could use the VM and create my own language that compiles to this highly optimised VM. I could use any of those many languages that already compile to Java bytecode. And yes, JVM does not equal Oracle; there are free open JVM implementations out there. I admit I did not try to find out how small that VM would be. But it just feels so wrong on so many levels. I simply cannot imagine JVM is the tool for the task. As I teasered for Lua before, more thoughts on this later. But: no. JavaScript \u00b6 Where do I begin? How about here: no I did not even try to find a solution for running JavaScript on the device. I am sure there are some. But so there are reasons against using this language. Once again, more on that later, when I reflect more on my use-case. Python \u00b6 I do like Python. But it is pretty big. There are some broken projects like tinypy. That looks dead. And there is, of course MicroPython . MicroPython is packed full of advanced features such as an interactive prompt, arbitrary precision integers, closures, list comprehension, generators, exception handling and more. Yet it is compact enough to fit and run within just 256k of code space and 16k of RAM. That 256k is a pretty big \"just\" for my liking. It is meant for the pyboard, having an STM with 1024 KiB flash ROM and 192 KiB RAM. And that device will not have a main firmware \"next to it\". So again, not really my use-case. Are there others? \u00b6 I googled. I looked at quite a few of them. It never feels close to what I want. First of all I found, that \"embedded scripting\" is a term that most of the time is not meant as in \"embedded device\". That's because the scripting language itself is what is embedded in the host language (be it C, Java, Rust, or whatever). Lua is a prime example on that terminology problem. So what I am really looking for is an \"embedded embedded scripting language\". Good luck on googling that! There are projects that try to be what I am looking for. Few such projects seem to be in a state that I would by willing to use them in a commercial product. Think long term maintainability here. And, again, they often do not aim at my problem very well. They want some ease of usage, which is fine, but they tend to have a too-high-level approach for my linking. Yes, I will start to talk about what I mean, soon. Maybe I should have taken a closer look at languages like Neko . But the first impression was hinting at many of the problems I try to describe here. No language was sticking out. I did not spend much time on any other language. Conclusion \u00b6 So, languages are never a good fit on what I want. They are hard to integrate in my existing system. They are too big. They are often not well maintained. Is this already the end of my journey? It does not have to be. But it will be a very different journey, if I proceed. That use-case I was talking about \u00b6 This is why every existing scripting language is objectively bad! Sorry, I wanted to say: This is my problem and languages do not seem to be designed for it. kratenko \u00b7 kratenko 2022-06-27 \u00b7 Entry #3 \u00b7 2 min read I was mentioning it, was I not? Languages do not seem to fit very well on by problem. What do I mean by that? I am doing very low level stuff. I am pushing bytes, often even bits around. Imagine receiving a bunch of raw bytes from a sensor attached via UART. You dump them in a buffer. The task for the script is now, to parse a few specific bytes out of that buffer, and make sense of them. Some are uint16 integers in little endian. Others are int32, spread over two uint16 BE registers, that are not next to each other, and you need to combine the two uint16 BE values in LE order to get your value. This scenario is fictional, but much more likely, than you would expect. All this sound horrible, and it is sometimes tricky, but of course you can do all this in any language that gives you access to bytes in any way. If you ever worked with LoRaWAN, you might have had to do such things in your network server (e.g. TTN ), to parse your uploaded data from bytes into, say, JSON. On many network servers you can do so with your own scripts (hey, that's close to what I want to do). And they give you the language suited best for this kind of problems: JavaScript. No, really. You are doing bit-manipulation on your bytes in a language where every number is stored as a float. You push your data around in JSON, a format that does not support byte arrays, so you have to communicate your bytes encoded in base64 or hex and store those inside strings. And you hope that the receiving end is able to decide if the date should be interpreted as a string or as hex or as base64 (and for hex strings, all of that can be possible at the same time). That is a problem, that I have with most scripting languages that I encountered. You get a giant infrastructure supporting classes with multiple inheritance support and polymorphism. You get on-the-go code interpreting. You get asynchronous execution support, dynamical typing, garbage collection, and whatnot. And I want to write a function, that is called when needed, and gets handed a few bytes. I want it to extract a few of those bytes, interpret them as a number, compare that number to a threshold, and if the value exceeds said threshold, call a different function with a few bytes, that are then send back over some peripheral (but that is not for the script language to control, just pass them to the system). Those languages tend to have a huge set of features that I do not need (or even to not want to have), while lacking many features that would be useful to me. So all that features would have to be implemented by me somehow, anyway. You see now, why I cannot find any language that I like? Script or virtual \u00b6 After the quest for a scripting languages failed, we plan writing our own. kratenko \u00b7 kratenko 2022-06-28 \u00b7 Entry #4 \u00b7 2 min read Script it then! \u00b6 Okay, okay. Let's say you bought my argumentation. Go ahead, hack together some scripting, knock yourself out. Just parse it in your firmware and execute it. Yeah, I could do that. Simple syntax. Parse it on the fly. Store variables in some hashmap, execute functions by name, have them call functions supplied by the firmware to interact with the hardware. And you can just throw those scripts into your git repo. Easy peasy. Only it wouldn't. But that language would grow oh ever so horribly. And it would never be good. Ever tried to parse an expression like f = 3 * a + (b + 2) * 1.2 . In C? And that expression is not too complex even. There would be so many parsing errors that only happen at runtime (on the device, remote, in the field, without any logging, let alone debugging). Besides: I do not want the complicated (read: big) parsing code on all of my devices. That is space (and execution time, which translates to power usage) that could be done once, on a more powerful device that I can monitor directly (that is: my laptop). Also: source code is long! I will need to store that on my device somewhere. And trying to write source code extra short makes it even worse. Let's get virtual \u00b6 So what is the solution here? We need a virtual machine that executes programs precompiled into bytecode. And we want that VM to be lightweight. If you design it carefully, a VM can be pretty small. What bloats things up often is the standard library with all the tools you need to efficiently write programs. But I do have a mighty host language (C, mostly), that already has a huge library of functions ready to be used (and which are often used already and henceforth already inside my firmware). I only need to provide a wrapper, that exposes them to my VM, and I can have them all: sinus/cosinus, logarithms, AES-encryption, Ethernet. You name it, we got it (well, most of it... be sensible.. we should at least be able to find an implementation somewhere...). And the best part? I postpone the pain of having to design the language. If you have a solid VM that supports the operations you need to get your work done nicely, you can pretty much design a language any way you want. You just need a bytecode compiler. You can even have multiple languages, in case you have too much time on your hands. But more important: you can develop the language without needing to change your VM (if you know what you do and if you plan well enough). That means: no need to update the firmware on your devices everytime the language advances. As long as your bytecode stays compatible. Is it realistic to finish this project, maybe even, to build something good? I highly doubt it. This is a huge project, if I make it all I want it to be. But at least I have learned quite a lot on the way so far. Why do you think I threw everything away (for the second time) and started on an empty board? So I guess, my time was not wasted, huh?","title":"June 2022 complete"},{"location":"2022-06/ALL.html#complete-month-of-june-2022","text":"","title":"Complete month of June 2022"},{"location":"2022-06/ALL.html#lovem-again","text":"It seems like that dude dug out one of his time-wasting projects and put some more work into it. This time in a public repo even. And for some reason he wants to let the world know, how and what he is doing. The journey starts here. kratenko \u00b7 kratenko 2022-06-24 \u00b7 Entry #1 \u00b7 2 min read So, I am back at writing my Low Overhead Virtual Embedded Machine . From scratch. Everything I had was dumped (have the code still, somewhere, but it is okay to start anew - I learned during my previous attempts).","title":"Lovem again!"},{"location":"2022-06/ALL.html#why","text":"Why am I doing this? Well, that has a history. Basically, I am writing firmware at work for our IIoT devices. They are pretty versatile, so configuring them tends to be rather complicated. And still, I want them to be able to do more: react to situations depending on sensor data, prepare data read from sensors, so that it transmitted with less overhead, etc. Right now, that would mean writing custom firmware for those customer cases (in C) and deploy it for their devices - and maintain those firmwares over years. And no one wants to pay for that! Nor do I care to do the maintaining. What's the alternative? Add those features to the standard firmware and add more configuration features. Great. So it will be even more complicated. And every second time you have a new use case, you will find your current solution insufficient, so you need to modify your firmware again to include that one more special case. And make your config more powerful (please keep it backwards compatible, while you at it, thank you very much - remember, there are thousands of devices out there, that still need to work with their configuration, when the firmware update hits them). And your config? You want to be able to react to triggers, and you want to do react in any random way. And you want to be able to manipulate your data points in any way needed. So when you walk that road for some time, you will end up with a configuration that is basically a programming language, since that is the only thing powerful enough, to do all that. And it will be a badly grown one, you can be sure about that! So let's embrace that consequence, and simply start with using a scripting language as means for advanced configuration! We will end there, cut some corners on the journey!","title":"Why?"},{"location":"2022-06/ALL.html#sorry-what-are-we-trying-to-do-again","text":"We are in need of a scripting language that runs on a very constrained device. Think of a microcontroller that has 352 kiB flash space and 191 kiB RAM for our complete firmware. And keep in mind that most of the behaviour of our device will not be implemented in the scripting language. There will be a number of hooks that should give control to the user supplied script, which will execute for a very short time, collect some data from sensors, act on them (maybe control actuators, but mostly generate data to be uploaded), and then return control to the firmware. And yeah, we will need to store the \"script\" somewhere on that device, so it would be great if it was not multiple kiB of program. I could use an SD-card in the dive (so I guess could store 1 TiB of script on the device if I needed), but those are not that reliable and are an optional extension that could already have a different use.","title":"Sorry, what are we trying to do again?"},{"location":"2022-06/ALL.html#we-need-another-wheel","text":"There are many wheels out there, why o why do you want to invent it again? Well, are there, though? Because that is what I thought. I started looking at what I know. Soo... kratenko \u00b7 kratenko 2022-06-26 \u00b7 Entry #2 \u00b7 4 min read","title":"We need another wheel"},{"location":"2022-06/ALL.html#lua","text":"Lua is a tested scripting language to use in host languages like C. I first experimented with it when I was trying to write games for fun, back in the early 2000s. I was somewhat intrigued when I came upon it again some 10 years later while playing heavily modded Minecraft. In ComputerCraft you have a block that is a computer, which you can write programs for in Lua. It even has a little operating system where you store your files (edit them, horribly, in an editor on an in-game monitor), execute programs that you can store on in-game floppies to carry around. It was a horrible kind of fun to do just anything inside that world. Lua was invented to solve a similar sounding problem: scripting in computer games. Level designers, story writers, etc. should not be bothered with having to write C-code to achieve their tasks (and re-compiling during developing those is not the way). So yeah, that is, more or less, my problem. And you can even compile Lua to byte code which is run in the interpreter. Neado! But, oh, the interpreter... turn's out, it is quite big! At least when you are working with embedded hardware. To quote lua users : Smaller footprint than Python. e.g. Look at the size of python22.dll, 824kb. A basic Lua engine, including parser/compiler/interpreter, but excluding standard libraries, weighs in at under 100kb. That's fine and all, but still a bit much for me - to be fair, I would need neither parser nor compiler. Other sources give numbers like <300 kB - which is overkill. I did compile it for our architecture - and the VM alone, without any of our own code doing stuff, exceeded the flash size I had. This stackoverflow question quotes the eLua FAQ to recommend 256 kB flash and 64k kB RAM which is too much for me - at time of writing this, eLua documentation seems offline in parts, so that does not give me confidence either. Quote from an answer to that question : I would recommend LUA (or eLUA http://www.eluaproject.net/ ). I've \"ported\" LUA to a Cortex-M3 a while back. From the top of my head it had a flash size of 60~100KB and needed about 20KB RAM to run. I did strip down to the bare essentials, but depending on your application, that might be enough. There's still room for optimization, especially about RAM requirements, but I doubt you can run it comfortable in 8KB. Back then I found a post I cannot find again that claimed, you can get the footprint of the Java VM smaller than that of the Lua VM (if you cut standard lib, which is part of Java and not of its VM). That sounds possible to me, when you have a glimpse on how those languages work. But then again you would not have any of the parts you are used to in Java. Also, there are some thoughts on how fitting that language is for my case, I'll have something about that later on. So I dropped that.","title":"Lua"},{"location":"2022-06/ALL.html#java-vm","text":"So... to the JVM then? To be honest: I do not want to go there. It does not feel right! JVM does not mean Java, I know that. I could use the VM and create my own language that compiles to this highly optimised VM. I could use any of those many languages that already compile to Java bytecode. And yes, JVM does not equal Oracle; there are free open JVM implementations out there. I admit I did not try to find out how small that VM would be. But it just feels so wrong on so many levels. I simply cannot imagine JVM is the tool for the task. As I teasered for Lua before, more thoughts on this later. But: no.","title":"Java VM"},{"location":"2022-06/ALL.html#javascript","text":"Where do I begin? How about here: no I did not even try to find a solution for running JavaScript on the device. I am sure there are some. But so there are reasons against using this language. Once again, more on that later, when I reflect more on my use-case.","title":"JavaScript"},{"location":"2022-06/ALL.html#python","text":"I do like Python. But it is pretty big. There are some broken projects like tinypy. That looks dead. And there is, of course MicroPython . MicroPython is packed full of advanced features such as an interactive prompt, arbitrary precision integers, closures, list comprehension, generators, exception handling and more. Yet it is compact enough to fit and run within just 256k of code space and 16k of RAM. That 256k is a pretty big \"just\" for my liking. It is meant for the pyboard, having an STM with 1024 KiB flash ROM and 192 KiB RAM. And that device will not have a main firmware \"next to it\". So again, not really my use-case.","title":"Python"},{"location":"2022-06/ALL.html#are-there-others","text":"I googled. I looked at quite a few of them. It never feels close to what I want. First of all I found, that \"embedded scripting\" is a term that most of the time is not meant as in \"embedded device\". That's because the scripting language itself is what is embedded in the host language (be it C, Java, Rust, or whatever). Lua is a prime example on that terminology problem. So what I am really looking for is an \"embedded embedded scripting language\". Good luck on googling that! There are projects that try to be what I am looking for. Few such projects seem to be in a state that I would by willing to use them in a commercial product. Think long term maintainability here. And, again, they often do not aim at my problem very well. They want some ease of usage, which is fine, but they tend to have a too-high-level approach for my linking. Yes, I will start to talk about what I mean, soon. Maybe I should have taken a closer look at languages like Neko . But the first impression was hinting at many of the problems I try to describe here. No language was sticking out. I did not spend much time on any other language.","title":"Are there others?"},{"location":"2022-06/ALL.html#conclusion","text":"So, languages are never a good fit on what I want. They are hard to integrate in my existing system. They are too big. They are often not well maintained. Is this already the end of my journey? It does not have to be. But it will be a very different journey, if I proceed.","title":"Conclusion"},{"location":"2022-06/ALL.html#that-use-case-i-was-talking-about","text":"This is why every existing scripting language is objectively bad! Sorry, I wanted to say: This is my problem and languages do not seem to be designed for it. kratenko \u00b7 kratenko 2022-06-27 \u00b7 Entry #3 \u00b7 2 min read I was mentioning it, was I not? Languages do not seem to fit very well on by problem. What do I mean by that? I am doing very low level stuff. I am pushing bytes, often even bits around. Imagine receiving a bunch of raw bytes from a sensor attached via UART. You dump them in a buffer. The task for the script is now, to parse a few specific bytes out of that buffer, and make sense of them. Some are uint16 integers in little endian. Others are int32, spread over two uint16 BE registers, that are not next to each other, and you need to combine the two uint16 BE values in LE order to get your value. This scenario is fictional, but much more likely, than you would expect. All this sound horrible, and it is sometimes tricky, but of course you can do all this in any language that gives you access to bytes in any way. If you ever worked with LoRaWAN, you might have had to do such things in your network server (e.g. TTN ), to parse your uploaded data from bytes into, say, JSON. On many network servers you can do so with your own scripts (hey, that's close to what I want to do). And they give you the language suited best for this kind of problems: JavaScript. No, really. You are doing bit-manipulation on your bytes in a language where every number is stored as a float. You push your data around in JSON, a format that does not support byte arrays, so you have to communicate your bytes encoded in base64 or hex and store those inside strings. And you hope that the receiving end is able to decide if the date should be interpreted as a string or as hex or as base64 (and for hex strings, all of that can be possible at the same time). That is a problem, that I have with most scripting languages that I encountered. You get a giant infrastructure supporting classes with multiple inheritance support and polymorphism. You get on-the-go code interpreting. You get asynchronous execution support, dynamical typing, garbage collection, and whatnot. And I want to write a function, that is called when needed, and gets handed a few bytes. I want it to extract a few of those bytes, interpret them as a number, compare that number to a threshold, and if the value exceeds said threshold, call a different function with a few bytes, that are then send back over some peripheral (but that is not for the script language to control, just pass them to the system). Those languages tend to have a huge set of features that I do not need (or even to not want to have), while lacking many features that would be useful to me. So all that features would have to be implemented by me somehow, anyway. You see now, why I cannot find any language that I like?","title":"That use-case I was talking about"},{"location":"2022-06/ALL.html#script-or-virtual","text":"After the quest for a scripting languages failed, we plan writing our own. kratenko \u00b7 kratenko 2022-06-28 \u00b7 Entry #4 \u00b7 2 min read","title":"Script or virtual"},{"location":"2022-06/ALL.html#script-it-then","text":"Okay, okay. Let's say you bought my argumentation. Go ahead, hack together some scripting, knock yourself out. Just parse it in your firmware and execute it. Yeah, I could do that. Simple syntax. Parse it on the fly. Store variables in some hashmap, execute functions by name, have them call functions supplied by the firmware to interact with the hardware. And you can just throw those scripts into your git repo. Easy peasy. Only it wouldn't. But that language would grow oh ever so horribly. And it would never be good. Ever tried to parse an expression like f = 3 * a + (b + 2) * 1.2 . In C? And that expression is not too complex even. There would be so many parsing errors that only happen at runtime (on the device, remote, in the field, without any logging, let alone debugging). Besides: I do not want the complicated (read: big) parsing code on all of my devices. That is space (and execution time, which translates to power usage) that could be done once, on a more powerful device that I can monitor directly (that is: my laptop). Also: source code is long! I will need to store that on my device somewhere. And trying to write source code extra short makes it even worse.","title":"Script it then!"},{"location":"2022-06/ALL.html#lets-get-virtual","text":"So what is the solution here? We need a virtual machine that executes programs precompiled into bytecode. And we want that VM to be lightweight. If you design it carefully, a VM can be pretty small. What bloats things up often is the standard library with all the tools you need to efficiently write programs. But I do have a mighty host language (C, mostly), that already has a huge library of functions ready to be used (and which are often used already and henceforth already inside my firmware). I only need to provide a wrapper, that exposes them to my VM, and I can have them all: sinus/cosinus, logarithms, AES-encryption, Ethernet. You name it, we got it (well, most of it... be sensible.. we should at least be able to find an implementation somewhere...). And the best part? I postpone the pain of having to design the language. If you have a solid VM that supports the operations you need to get your work done nicely, you can pretty much design a language any way you want. You just need a bytecode compiler. You can even have multiple languages, in case you have too much time on your hands. But more important: you can develop the language without needing to change your VM (if you know what you do and if you plan well enough). That means: no need to update the firmware on your devices everytime the language advances. As long as your bytecode stays compatible. Is it realistic to finish this project, maybe even, to build something good? I highly doubt it. This is a huge project, if I make it all I want it to be. But at least I have learned quite a lot on the way so far. Why do you think I threw everything away (for the second time) and started on an empty board? So I guess, my time was not wasted, huh?","title":"Let's get virtual"},{"location":"2022-06/NAV.html","text":"Script or virtual That use-case I was talking about We need another wheel Lovem again!","title":"NAV"},{"location":"2022-06/lovem-again.html","text":"Lovem again! \u00b6 It seems like that dude dug out one of his time-wasting projects and put some more work into it. This time in a public repo even. And for some reason he wants to let the world know, how and what he is doing. The journey starts here. kratenko \u00b7 kratenko 2022-06-24 \u00b7 Entry #1 \u00b7 2 min read So, I am back at writing my Low Overhead Virtual Embedded Machine . From scratch. Everything I had was dumped (have the code still, somewhere, but it is okay to start anew - I learned during my previous attempts). Why? \u00b6 Why am I doing this? Well, that has a history. Basically, I am writing firmware at work for our IIoT devices. They are pretty versatile, so configuring them tends to be rather complicated. And still, I want them to be able to do more: react to situations depending on sensor data, prepare data read from sensors, so that it transmitted with less overhead, etc. Right now, that would mean writing custom firmware for those customer cases (in C) and deploy it for their devices - and maintain those firmwares over years. And no one wants to pay for that! Nor do I care to do the maintaining. What's the alternative? Add those features to the standard firmware and add more configuration features. Great. So it will be even more complicated. And every second time you have a new use case, you will find your current solution insufficient, so you need to modify your firmware again to include that one more special case. And make your config more powerful (please keep it backwards compatible, while you at it, thank you very much - remember, there are thousands of devices out there, that still need to work with their configuration, when the firmware update hits them). And your config? You want to be able to react to triggers, and you want to do react in any random way. And you want to be able to manipulate your data points in any way needed. So when you walk that road for some time, you will end up with a configuration that is basically a programming language, since that is the only thing powerful enough, to do all that. And it will be a badly grown one, you can be sure about that! So let's embrace that consequence, and simply start with using a scripting language as means for advanced configuration! We will end there, cut some corners on the journey! Sorry, what are we trying to do again? \u00b6 We are in need of a scripting language that runs on a very constrained device. Think of a microcontroller that has 352 kiB flash space and 191 kiB RAM for our complete firmware. And keep in mind that most of the behaviour of our device will not be implemented in the scripting language. There will be a number of hooks that should give control to the user supplied script, which will execute for a very short time, collect some data from sensors, act on them (maybe control actuators, but mostly generate data to be uploaded), and then return control to the firmware. And yeah, we will need to store the \"script\" somewhere on that device, so it would be great if it was not multiple kiB of program. I could use an SD-card in the dive (so I guess could store 1 TiB of script on the device if I needed), but those are not that reliable and are an optional extension that could already have a different use.","title":" Lovem again!"},{"location":"2022-06/lovem-again.html#lovem-again","text":"It seems like that dude dug out one of his time-wasting projects and put some more work into it. This time in a public repo even. And for some reason he wants to let the world know, how and what he is doing. The journey starts here. kratenko \u00b7 kratenko 2022-06-24 \u00b7 Entry #1 \u00b7 2 min read So, I am back at writing my Low Overhead Virtual Embedded Machine . From scratch. Everything I had was dumped (have the code still, somewhere, but it is okay to start anew - I learned during my previous attempts).","title":"Lovem again!"},{"location":"2022-06/lovem-again.html#why","text":"Why am I doing this? Well, that has a history. Basically, I am writing firmware at work for our IIoT devices. They are pretty versatile, so configuring them tends to be rather complicated. And still, I want them to be able to do more: react to situations depending on sensor data, prepare data read from sensors, so that it transmitted with less overhead, etc. Right now, that would mean writing custom firmware for those customer cases (in C) and deploy it for their devices - and maintain those firmwares over years. And no one wants to pay for that! Nor do I care to do the maintaining. What's the alternative? Add those features to the standard firmware and add more configuration features. Great. So it will be even more complicated. And every second time you have a new use case, you will find your current solution insufficient, so you need to modify your firmware again to include that one more special case. And make your config more powerful (please keep it backwards compatible, while you at it, thank you very much - remember, there are thousands of devices out there, that still need to work with their configuration, when the firmware update hits them). And your config? You want to be able to react to triggers, and you want to do react in any random way. And you want to be able to manipulate your data points in any way needed. So when you walk that road for some time, you will end up with a configuration that is basically a programming language, since that is the only thing powerful enough, to do all that. And it will be a badly grown one, you can be sure about that! So let's embrace that consequence, and simply start with using a scripting language as means for advanced configuration! We will end there, cut some corners on the journey!","title":"Why?"},{"location":"2022-06/lovem-again.html#sorry-what-are-we-trying-to-do-again","text":"We are in need of a scripting language that runs on a very constrained device. Think of a microcontroller that has 352 kiB flash space and 191 kiB RAM for our complete firmware. And keep in mind that most of the behaviour of our device will not be implemented in the scripting language. There will be a number of hooks that should give control to the user supplied script, which will execute for a very short time, collect some data from sensors, act on them (maybe control actuators, but mostly generate data to be uploaded), and then return control to the firmware. And yeah, we will need to store the \"script\" somewhere on that device, so it would be great if it was not multiple kiB of program. I could use an SD-card in the dive (so I guess could store 1 TiB of script on the device if I needed), but those are not that reliable and are an optional extension that could already have a different use.","title":"Sorry, what are we trying to do again?"},{"location":"2022-06/script-or-virtual.html","text":"Script or virtual \u00b6 After the quest for a scripting languages failed, we plan writing our own. kratenko \u00b7 kratenko 2022-06-28 \u00b7 Entry #4 \u00b7 2 min read Script it then! \u00b6 Okay, okay. Let's say you bought my argumentation. Go ahead, hack together some scripting, knock yourself out. Just parse it in your firmware and execute it. Yeah, I could do that. Simple syntax. Parse it on the fly. Store variables in some hashmap, execute functions by name, have them call functions supplied by the firmware to interact with the hardware. And you can just throw those scripts into your git repo. Easy peasy. Only it wouldn't. But that language would grow oh ever so horribly. And it would never be good. Ever tried to parse an expression like f = 3 * a + (b + 2) * 1.2 . In C? And that expression is not too complex even. There would be so many parsing errors that only happen at runtime (on the device, remote, in the field, without any logging, let alone debugging). Besides: I do not want the complicated (read: big) parsing code on all of my devices. That is space (and execution time, which translates to power usage) that could be done once, on a more powerful device that I can monitor directly (that is: my laptop). Also: source code is long! I will need to store that on my device somewhere. And trying to write source code extra short makes it even worse. Let's get virtual \u00b6 So what is the solution here? We need a virtual machine that executes programs precompiled into bytecode. And we want that VM to be lightweight. If you design it carefully, a VM can be pretty small. What bloats things up often is the standard library with all the tools you need to efficiently write programs. But I do have a mighty host language (C, mostly), that already has a huge library of functions ready to be used (and which are often used already and henceforth already inside my firmware). I only need to provide a wrapper, that exposes them to my VM, and I can have them all: sinus/cosinus, logarithms, AES-encryption, Ethernet. You name it, we got it (well, most of it... be sensible.. we should at least be able to find an implementation somewhere...). And the best part? I postpone the pain of having to design the language. If you have a solid VM that supports the operations you need to get your work done nicely, you can pretty much design a language any way you want. You just need a bytecode compiler. You can even have multiple languages, in case you have too much time on your hands. But more important: you can develop the language without needing to change your VM (if you know what you do and if you plan well enough). That means: no need to update the firmware on your devices everytime the language advances. As long as your bytecode stays compatible. Is it realistic to finish this project, maybe even, to build something good? I highly doubt it. This is a huge project, if I make it all I want it to be. But at least I have learned quite a lot on the way so far. Why do you think I threw everything away (for the second time) and started on an empty board? So I guess, my time was not wasted, huh?","title":" Script or virtual"},{"location":"2022-06/script-or-virtual.html#script-or-virtual","text":"After the quest for a scripting languages failed, we plan writing our own. kratenko \u00b7 kratenko 2022-06-28 \u00b7 Entry #4 \u00b7 2 min read","title":"Script or virtual"},{"location":"2022-06/script-or-virtual.html#script-it-then","text":"Okay, okay. Let's say you bought my argumentation. Go ahead, hack together some scripting, knock yourself out. Just parse it in your firmware and execute it. Yeah, I could do that. Simple syntax. Parse it on the fly. Store variables in some hashmap, execute functions by name, have them call functions supplied by the firmware to interact with the hardware. And you can just throw those scripts into your git repo. Easy peasy. Only it wouldn't. But that language would grow oh ever so horribly. And it would never be good. Ever tried to parse an expression like f = 3 * a + (b + 2) * 1.2 . In C? And that expression is not too complex even. There would be so many parsing errors that only happen at runtime (on the device, remote, in the field, without any logging, let alone debugging). Besides: I do not want the complicated (read: big) parsing code on all of my devices. That is space (and execution time, which translates to power usage) that could be done once, on a more powerful device that I can monitor directly (that is: my laptop). Also: source code is long! I will need to store that on my device somewhere. And trying to write source code extra short makes it even worse.","title":"Script it then!"},{"location":"2022-06/script-or-virtual.html#lets-get-virtual","text":"So what is the solution here? We need a virtual machine that executes programs precompiled into bytecode. And we want that VM to be lightweight. If you design it carefully, a VM can be pretty small. What bloats things up often is the standard library with all the tools you need to efficiently write programs. But I do have a mighty host language (C, mostly), that already has a huge library of functions ready to be used (and which are often used already and henceforth already inside my firmware). I only need to provide a wrapper, that exposes them to my VM, and I can have them all: sinus/cosinus, logarithms, AES-encryption, Ethernet. You name it, we got it (well, most of it... be sensible.. we should at least be able to find an implementation somewhere...). And the best part? I postpone the pain of having to design the language. If you have a solid VM that supports the operations you need to get your work done nicely, you can pretty much design a language any way you want. You just need a bytecode compiler. You can even have multiple languages, in case you have too much time on your hands. But more important: you can develop the language without needing to change your VM (if you know what you do and if you plan well enough). That means: no need to update the firmware on your devices everytime the language advances. As long as your bytecode stays compatible. Is it realistic to finish this project, maybe even, to build something good? I highly doubt it. This is a huge project, if I make it all I want it to be. But at least I have learned quite a lot on the way so far. Why do you think I threw everything away (for the second time) and started on an empty board? So I guess, my time was not wasted, huh?","title":"Let's get virtual"},{"location":"2022-06/that-use-case.html","text":"That use-case I was talking about \u00b6 This is why every existing scripting language is objectively bad! Sorry, I wanted to say: This is my problem and languages do not seem to be designed for it. kratenko \u00b7 kratenko 2022-06-27 \u00b7 Entry #3 \u00b7 2 min read I was mentioning it, was I not? Languages do not seem to fit very well on by problem. What do I mean by that? I am doing very low level stuff. I am pushing bytes, often even bits around. Imagine receiving a bunch of raw bytes from a sensor attached via UART. You dump them in a buffer. The task for the script is now, to parse a few specific bytes out of that buffer, and make sense of them. Some are uint16 integers in little endian. Others are int32, spread over two uint16 BE registers, that are not next to each other, and you need to combine the two uint16 BE values in LE order to get your value. This scenario is fictional, but much more likely, than you would expect. All this sound horrible, and it is sometimes tricky, but of course you can do all this in any language that gives you access to bytes in any way. If you ever worked with LoRaWAN, you might have had to do such things in your network server (e.g. TTN ), to parse your uploaded data from bytes into, say, JSON. On many network servers you can do so with your own scripts (hey, that's close to what I want to do). And they give you the language suited best for this kind of problems: JavaScript. No, really. You are doing bit-manipulation on your bytes in a language where every number is stored as a float. You push your data around in JSON, a format that does not support byte arrays, so you have to communicate your bytes encoded in base64 or hex and store those inside strings. And you hope that the receiving end is able to decide if the date should be interpreted as a string or as hex or as base64 (and for hex strings, all of that can be possible at the same time). That is a problem, that I have with most scripting languages that I encountered. You get a giant infrastructure supporting classes with multiple inheritance support and polymorphism. You get on-the-go code interpreting. You get asynchronous execution support, dynamical typing, garbage collection, and whatnot. And I want to write a function, that is called when needed, and gets handed a few bytes. I want it to extract a few of those bytes, interpret them as a number, compare that number to a threshold, and if the value exceeds said threshold, call a different function with a few bytes, that are then send back over some peripheral (but that is not for the script language to control, just pass them to the system). Those languages tend to have a huge set of features that I do not need (or even to not want to have), while lacking many features that would be useful to me. So all that features would have to be implemented by me somehow, anyway. You see now, why I cannot find any language that I like?","title":" That use-case I was talking about"},{"location":"2022-06/that-use-case.html#that-use-case-i-was-talking-about","text":"This is why every existing scripting language is objectively bad! Sorry, I wanted to say: This is my problem and languages do not seem to be designed for it. kratenko \u00b7 kratenko 2022-06-27 \u00b7 Entry #3 \u00b7 2 min read I was mentioning it, was I not? Languages do not seem to fit very well on by problem. What do I mean by that? I am doing very low level stuff. I am pushing bytes, often even bits around. Imagine receiving a bunch of raw bytes from a sensor attached via UART. You dump them in a buffer. The task for the script is now, to parse a few specific bytes out of that buffer, and make sense of them. Some are uint16 integers in little endian. Others are int32, spread over two uint16 BE registers, that are not next to each other, and you need to combine the two uint16 BE values in LE order to get your value. This scenario is fictional, but much more likely, than you would expect. All this sound horrible, and it is sometimes tricky, but of course you can do all this in any language that gives you access to bytes in any way. If you ever worked with LoRaWAN, you might have had to do such things in your network server (e.g. TTN ), to parse your uploaded data from bytes into, say, JSON. On many network servers you can do so with your own scripts (hey, that's close to what I want to do). And they give you the language suited best for this kind of problems: JavaScript. No, really. You are doing bit-manipulation on your bytes in a language where every number is stored as a float. You push your data around in JSON, a format that does not support byte arrays, so you have to communicate your bytes encoded in base64 or hex and store those inside strings. And you hope that the receiving end is able to decide if the date should be interpreted as a string or as hex or as base64 (and for hex strings, all of that can be possible at the same time). That is a problem, that I have with most scripting languages that I encountered. You get a giant infrastructure supporting classes with multiple inheritance support and polymorphism. You get on-the-go code interpreting. You get asynchronous execution support, dynamical typing, garbage collection, and whatnot. And I want to write a function, that is called when needed, and gets handed a few bytes. I want it to extract a few of those bytes, interpret them as a number, compare that number to a threshold, and if the value exceeds said threshold, call a different function with a few bytes, that are then send back over some peripheral (but that is not for the script language to control, just pass them to the system). Those languages tend to have a huge set of features that I do not need (or even to not want to have), while lacking many features that would be useful to me. So all that features would have to be implemented by me somehow, anyway. You see now, why I cannot find any language that I like?","title":"That use-case I was talking about"},{"location":"2022-06/we-need-another-wheel.html","text":"We need another wheel \u00b6 There are many wheels out there, why o why do you want to invent it again? Well, are there, though? Because that is what I thought. I started looking at what I know. Soo... kratenko \u00b7 kratenko 2022-06-26 \u00b7 Entry #2 \u00b7 4 min read Lua \u00b6 Lua is a tested scripting language to use in host languages like C. I first experimented with it when I was trying to write games for fun, back in the early 2000s. I was somewhat intrigued when I came upon it again some 10 years later while playing heavily modded Minecraft. In ComputerCraft you have a block that is a computer, which you can write programs for in Lua. It even has a little operating system where you store your files (edit them, horribly, in an editor on an in-game monitor), execute programs that you can store on in-game floppies to carry around. It was a horrible kind of fun to do just anything inside that world. Lua was invented to solve a similar sounding problem: scripting in computer games. Level designers, story writers, etc. should not be bothered with having to write C-code to achieve their tasks (and re-compiling during developing those is not the way). So yeah, that is, more or less, my problem. And you can even compile Lua to byte code which is run in the interpreter. Neado! But, oh, the interpreter... turn's out, it is quite big! At least when you are working with embedded hardware. To quote lua users : Smaller footprint than Python. e.g. Look at the size of python22.dll, 824kb. A basic Lua engine, including parser/compiler/interpreter, but excluding standard libraries, weighs in at under 100kb. That's fine and all, but still a bit much for me - to be fair, I would need neither parser nor compiler. Other sources give numbers like <300 kB - which is overkill. I did compile it for our architecture - and the VM alone, without any of our own code doing stuff, exceeded the flash size I had. This stackoverflow question quotes the eLua FAQ to recommend 256 kB flash and 64k kB RAM which is too much for me - at time of writing this, eLua documentation seems offline in parts, so that does not give me confidence either. Quote from an answer to that question : I would recommend LUA (or eLUA http://www.eluaproject.net/ ). I've \"ported\" LUA to a Cortex-M3 a while back. From the top of my head it had a flash size of 60~100KB and needed about 20KB RAM to run. I did strip down to the bare essentials, but depending on your application, that might be enough. There's still room for optimization, especially about RAM requirements, but I doubt you can run it comfortable in 8KB. Back then I found a post I cannot find again that claimed, you can get the footprint of the Java VM smaller than that of the Lua VM (if you cut standard lib, which is part of Java and not of its VM). That sounds possible to me, when you have a glimpse on how those languages work. But then again you would not have any of the parts you are used to in Java. Also, there are some thoughts on how fitting that language is for my case, I'll have something about that later on. So I dropped that. Java VM \u00b6 So... to the JVM then? To be honest: I do not want to go there. It does not feel right! JVM does not mean Java, I know that. I could use the VM and create my own language that compiles to this highly optimised VM. I could use any of those many languages that already compile to Java bytecode. And yes, JVM does not equal Oracle; there are free open JVM implementations out there. I admit I did not try to find out how small that VM would be. But it just feels so wrong on so many levels. I simply cannot imagine JVM is the tool for the task. As I teasered for Lua before, more thoughts on this later. But: no. JavaScript \u00b6 Where do I begin? How about here: no I did not even try to find a solution for running JavaScript on the device. I am sure there are some. But so there are reasons against using this language. Once again, more on that later, when I reflect more on my use-case. Python \u00b6 I do like Python. But it is pretty big. There are some broken projects like tinypy. That looks dead. And there is, of course MicroPython . MicroPython is packed full of advanced features such as an interactive prompt, arbitrary precision integers, closures, list comprehension, generators, exception handling and more. Yet it is compact enough to fit and run within just 256k of code space and 16k of RAM. That 256k is a pretty big \"just\" for my liking. It is meant for the pyboard, having an STM with 1024 KiB flash ROM and 192 KiB RAM. And that device will not have a main firmware \"next to it\". So again, not really my use-case. Are there others? \u00b6 I googled. I looked at quite a few of them. It never feels close to what I want. First of all I found, that \"embedded scripting\" is a term that most of the time is not meant as in \"embedded device\". That's because the scripting language itself is what is embedded in the host language (be it C, Java, Rust, or whatever). Lua is a prime example on that terminology problem. So what I am really looking for is an \"embedded embedded scripting language\". Good luck on googling that! There are projects that try to be what I am looking for. Few such projects seem to be in a state that I would by willing to use them in a commercial product. Think long term maintainability here. And, again, they often do not aim at my problem very well. They want some ease of usage, which is fine, but they tend to have a too-high-level approach for my linking. Yes, I will start to talk about what I mean, soon. Maybe I should have taken a closer look at languages like Neko . But the first impression was hinting at many of the problems I try to describe here. No language was sticking out. I did not spend much time on any other language. Conclusion \u00b6 So, languages are never a good fit on what I want. They are hard to integrate in my existing system. They are too big. They are often not well maintained. Is this already the end of my journey? It does not have to be. But it will be a very different journey, if I proceed.","title":" We need another wheel"},{"location":"2022-06/we-need-another-wheel.html#we-need-another-wheel","text":"There are many wheels out there, why o why do you want to invent it again? Well, are there, though? Because that is what I thought. I started looking at what I know. Soo... kratenko \u00b7 kratenko 2022-06-26 \u00b7 Entry #2 \u00b7 4 min read","title":"We need another wheel"},{"location":"2022-06/we-need-another-wheel.html#lua","text":"Lua is a tested scripting language to use in host languages like C. I first experimented with it when I was trying to write games for fun, back in the early 2000s. I was somewhat intrigued when I came upon it again some 10 years later while playing heavily modded Minecraft. In ComputerCraft you have a block that is a computer, which you can write programs for in Lua. It even has a little operating system where you store your files (edit them, horribly, in an editor on an in-game monitor), execute programs that you can store on in-game floppies to carry around. It was a horrible kind of fun to do just anything inside that world. Lua was invented to solve a similar sounding problem: scripting in computer games. Level designers, story writers, etc. should not be bothered with having to write C-code to achieve their tasks (and re-compiling during developing those is not the way). So yeah, that is, more or less, my problem. And you can even compile Lua to byte code which is run in the interpreter. Neado! But, oh, the interpreter... turn's out, it is quite big! At least when you are working with embedded hardware. To quote lua users : Smaller footprint than Python. e.g. Look at the size of python22.dll, 824kb. A basic Lua engine, including parser/compiler/interpreter, but excluding standard libraries, weighs in at under 100kb. That's fine and all, but still a bit much for me - to be fair, I would need neither parser nor compiler. Other sources give numbers like <300 kB - which is overkill. I did compile it for our architecture - and the VM alone, without any of our own code doing stuff, exceeded the flash size I had. This stackoverflow question quotes the eLua FAQ to recommend 256 kB flash and 64k kB RAM which is too much for me - at time of writing this, eLua documentation seems offline in parts, so that does not give me confidence either. Quote from an answer to that question : I would recommend LUA (or eLUA http://www.eluaproject.net/ ). I've \"ported\" LUA to a Cortex-M3 a while back. From the top of my head it had a flash size of 60~100KB and needed about 20KB RAM to run. I did strip down to the bare essentials, but depending on your application, that might be enough. There's still room for optimization, especially about RAM requirements, but I doubt you can run it comfortable in 8KB. Back then I found a post I cannot find again that claimed, you can get the footprint of the Java VM smaller than that of the Lua VM (if you cut standard lib, which is part of Java and not of its VM). That sounds possible to me, when you have a glimpse on how those languages work. But then again you would not have any of the parts you are used to in Java. Also, there are some thoughts on how fitting that language is for my case, I'll have something about that later on. So I dropped that.","title":"Lua"},{"location":"2022-06/we-need-another-wheel.html#java-vm","text":"So... to the JVM then? To be honest: I do not want to go there. It does not feel right! JVM does not mean Java, I know that. I could use the VM and create my own language that compiles to this highly optimised VM. I could use any of those many languages that already compile to Java bytecode. And yes, JVM does not equal Oracle; there are free open JVM implementations out there. I admit I did not try to find out how small that VM would be. But it just feels so wrong on so many levels. I simply cannot imagine JVM is the tool for the task. As I teasered for Lua before, more thoughts on this later. But: no.","title":"Java VM"},{"location":"2022-06/we-need-another-wheel.html#javascript","text":"Where do I begin? How about here: no I did not even try to find a solution for running JavaScript on the device. I am sure there are some. But so there are reasons against using this language. Once again, more on that later, when I reflect more on my use-case.","title":"JavaScript"},{"location":"2022-06/we-need-another-wheel.html#python","text":"I do like Python. But it is pretty big. There are some broken projects like tinypy. That looks dead. And there is, of course MicroPython . MicroPython is packed full of advanced features such as an interactive prompt, arbitrary precision integers, closures, list comprehension, generators, exception handling and more. Yet it is compact enough to fit and run within just 256k of code space and 16k of RAM. That 256k is a pretty big \"just\" for my liking. It is meant for the pyboard, having an STM with 1024 KiB flash ROM and 192 KiB RAM. And that device will not have a main firmware \"next to it\". So again, not really my use-case.","title":"Python"},{"location":"2022-06/we-need-another-wheel.html#are-there-others","text":"I googled. I looked at quite a few of them. It never feels close to what I want. First of all I found, that \"embedded scripting\" is a term that most of the time is not meant as in \"embedded device\". That's because the scripting language itself is what is embedded in the host language (be it C, Java, Rust, or whatever). Lua is a prime example on that terminology problem. So what I am really looking for is an \"embedded embedded scripting language\". Good luck on googling that! There are projects that try to be what I am looking for. Few such projects seem to be in a state that I would by willing to use them in a commercial product. Think long term maintainability here. And, again, they often do not aim at my problem very well. They want some ease of usage, which is fine, but they tend to have a too-high-level approach for my linking. Yes, I will start to talk about what I mean, soon. Maybe I should have taken a closer look at languages like Neko . But the first impression was hinting at many of the problems I try to describe here. No language was sticking out. I did not spend much time on any other language.","title":"Are there others?"},{"location":"2022-06/we-need-another-wheel.html#conclusion","text":"So, languages are never a good fit on what I want. They are hard to integrate in my existing system. They are too big. They are often not well maintained. Is this already the end of my journey? It does not have to be. But it will be a very different journey, if I proceed.","title":"Conclusion"},{"location":"2022-07/index.html","text":"Journal entries from July 2022 \u00b6 Read all in single page Parsing the source \u00b6 kratenko \u00b7 kratenko 2022-07-27 \u00b7 Entry #22 \u00b7 4 min read \u00b7 v0.0.8-journey So far we have read an assembly source file into a string, and we got to know some new data structures. It is time we use the one to fill the other. Let us start parsing. Continue reading Assemble! \u00b6 We introduce an API for assembly to our lovem library. kratenko \u00b7 kratenko 2022-07-26 \u00b7 Entry #21 \u00b7 5 min read \u00b7 v0.0.8-journey Last time, we built the frame of a command line program, that will become our new assembler, lovas . It is time that we give that program the power to assemble. Continue reading Don't byte me! \u00b6 I have had it with these motherloving bytes in this motherloving bytecode! kratenko \u00b7 kratenko 2022-07-25 \u00b7 Entry #20 \u00b7 5 min read \u00b7 v0.0.7-journey By now you should have come to a realisation: writing bytecode sucks! It wasn't fun to begin with, but now that we introduce jumps in our code, we need to count how many bytes the jump takes \u2013 and that with instructions that have different numbers of bytes as opargs. Encoding negative numbers in bytes is also no fun. And just think about it: if you change your program (e.g. add a few instructions), you have to adjust those relative jumps! How horrible is that? Can't someone else do it? Well, yeah, of course. We invented a machine that can do annoying and monotone tasks that require accuracy and that must be done over and over again. That machine is, of course, the computer. Continue reading Go ahead and jump! \u00b6 All our programs have been linear so far. Let's build the base for jumping around. kratenko \u00b7 kratenko 2022-07-22 \u00b7 Entry #19 \u00b7 5 min read \u00b7 v0.0.6-journey In every program we have written so far, each instruction just advances the PC[^pc], until we reach the end. That is very linear. We will now introduce a new opcode, that jumps to a different position in the program. Continue reading Reverse polish notation \u00b6 We are using the design of a stack machine to efficiently execute some calculations. kratenko \u00b7 kratenko 2022-07-21 \u00b7 Entry #18 \u00b7 4 min read \u00b7 v0.0.5-journey The way stack machines work can be used in programs that execute calculations. We will look at it by implementing an example from the Wikipedia page about stack machines. Continue reading More operations \u00b6 The basic operation of the VM is working. Let us add a few more opcodes, so that we can do calculations. kratenko \u00b7 kratenko 2022-07-20 \u00b7 Entry #17 \u00b7 4 min read \u00b7 v0.0.4-journey We have created a rust library that holds our virtual register machine. We can now add multiple executables to it, so that makes it easier, to write different programs and keep them (to mess around with the VM). We will add a few more opcodes to our repertoire, because only adding numbers is just plain boring. Continue reading Early VM decisions \u00b6 Many design decisions must be made for lovem. Here I talk about some of those in the current state. kratenko \u00b7 kratenko 2022-07-19 \u00b7 Entry #16 \u00b7 3 min read \u00b7 v0.0.3-journey I have shared and discussed source code in the recent posts. Now it is time again, to write about design decisions. I made a few of them for the code you saw. So far I have not been reasoning about those here, and some of you might have wondered already. Let's talk about them. Continue reading To the library! \u00b6 We turn our project from a binary project into a library project. kratenko \u00b7 kratenko 2022-07-18 \u00b7 Entry #15 \u00b7 5 min read \u00b7 v0.0.3-journey So far, our lovem cargo project holds a single binary. That is not very useful for something that should be integrated into other projects. What we need is a library . How is that done? Simple: we rename our main.rs to lib.rs . Continue reading Becoming social \u00b6 A new way for you to participate in my journey. kratenko \u00b7 kratenko 2022-07-15 \u00b7 Entry #14 \u00b7 < 1 min read After a few days of progress on the project itself, I spent a bit of time on the site again. We have the fancy link to our GitHub repo in the upper right corner now. But more important, I added support for comments on my entries. You can now react and ask questions or share your thought. Continue reading Turn \"fragile\" into \"rusty\" \u00b6 After we got our Proof of Concept running, we clean up our code and make it look like a respectable Rust program. kratenko \u00b7 kratenko 2022-07-14 \u00b7 Entry #13 \u00b7 2 min read Did you play around with the program from the previous post? If you are new to Rust, you really should! At least mess around with our bytecode. You should find, that our VM does not react well to errors, yet. It simply panics! That is no behaviour for a respectable rust program. Continue reading Running our first program \u00b6 Now, that we have a VM, we will run a program on it. kratenko \u00b7 kratenko 2022-07-12 \u00b7 Entry #12 \u00b7 3 min read So we built our very first VM and studied the code in detail. It is time to execute a program on it and look at it's output. We will look at every single step the program takes. Aren't we lucky, that our VM is so talkative during execution? Continue reading A VM \u00b6 The first draft of source code, that will be our VM, explained. kratenko \u00b7 kratenko 2022-07-11 \u00b7 Entry #11 \u00b7 8 min read I dumped some source code in front of you, and then I started to talk about programming languages. Time now, to explain what I did and why. We only have 132 lines, including comments. We will go through all parts of it. And I will talk a little about how Rust's basic syntax works, while I use it. Not too much, since it is not good Rust code, yet, but to help you start. This will be a longer entry. Continue reading It looks so weird \u00b6 Now, that you have seen some code, I might have to explain a bit again. Depends, on where you are coming from, I guess. kratenko \u00b7 kratenko 2022-07-10 \u00b7 Entry #10 \u00b7 4 min read So, did you take a look at the code, yet? In case you've forgotten, this is my \"initial commit\": Continue reading Let there be source code \u00b6 Finally, I will be showing some source code. Not directly in the journal, but I will link you to GitHub, for a start. kratenko \u00b7 kratenko 2022-07-08 \u00b7 Entry #9 \u00b7 2 min read I have written code. And this time, I (re-)started lovem in a public git repository, so you can see what I do, if you are interested. And I hope it puts enough pressure on me, to keep on the project for a while. Continue reading Making virtual a reality \u00b6 So I have been talking a lot about VMs without doing anything concrete. Well that is not true, I have done quite a bit already, but I am still describing earlier steps. We will get there. kratenko \u00b7 kratenko 2022-07-06 \u00b7 Entry #8 \u00b7 3 min read Registers? \u00b6 When I was looking around for a scripting language to use inside our embedded devices, I came across an article I mentioned in an earlier post: [Creating a Virtual Machine/Register VM in C][register-book]. Continue reading What is a Virtual Machine anyway? \u00b6 kratenko \u00b7 kratenko 2022-07-04 \u00b7 Entry #7 \u00b7 5 min read So, how do you build a Virtual Machine. There are actually two quite different approaches: Continue reading All new once more \u00b6 Reality strikes again, and code will be written from scratch once more. And the reason is this site. kratenko \u00b7 kratenko 2022-07-03 \u00b7 Entry #6 \u00b7 < 1 min read You want me to get to the code. And I really should. I have written so much already, and I want to show it, but there is so much around it. And after I had written up a long text on how I started, I realised that I had no commits during the early state. So I had to write it all again, slower, and with code to be presentable in this journal. Continue reading State of the Journal \u00b6 Since I am always focused on my work on lovem, I will never get sidetracked. Unrelated: I spent a few days on reworking the journal on this site. kratenko \u00b7 kratenko 2022-07-01 \u00b7 Entry #5 \u00b7 3 min read So, no update on the core project today, sorry. I was very unhappy with my first solution, on how the Journal entries where created. Way too much to do by hand \u2013 that is not what I learned programming for. But mkdocs is python, and python I can do. So did. And now I can write my Journal entries (like this one) as plain Markdown files with very few metadata entries. And I get entries in the navigation and pages listing the whole month. I even included a whole month in single page version of the journal. I feel it is quite fancy. I will need to do a bit of work on the static content of the site, but one step at a time. Continue reading","title":"Journal entries from July 2022"},{"location":"2022-07/index.html#journal-entries-from-july-2022","text":"Read all in single page","title":"Journal entries from July 2022"},{"location":"2022-07/index.html#parsing-the-source","text":"kratenko \u00b7 kratenko 2022-07-27 \u00b7 Entry #22 \u00b7 4 min read \u00b7 v0.0.8-journey So far we have read an assembly source file into a string, and we got to know some new data structures. It is time we use the one to fill the other. Let us start parsing. Continue reading","title":"Parsing the source"},{"location":"2022-07/index.html#assemble","text":"We introduce an API for assembly to our lovem library. kratenko \u00b7 kratenko 2022-07-26 \u00b7 Entry #21 \u00b7 5 min read \u00b7 v0.0.8-journey Last time, we built the frame of a command line program, that will become our new assembler, lovas . It is time that we give that program the power to assemble. Continue reading","title":"Assemble!"},{"location":"2022-07/index.html#dont-byte-me","text":"I have had it with these motherloving bytes in this motherloving bytecode! kratenko \u00b7 kratenko 2022-07-25 \u00b7 Entry #20 \u00b7 5 min read \u00b7 v0.0.7-journey By now you should have come to a realisation: writing bytecode sucks! It wasn't fun to begin with, but now that we introduce jumps in our code, we need to count how many bytes the jump takes \u2013 and that with instructions that have different numbers of bytes as opargs. Encoding negative numbers in bytes is also no fun. And just think about it: if you change your program (e.g. add a few instructions), you have to adjust those relative jumps! How horrible is that? Can't someone else do it? Well, yeah, of course. We invented a machine that can do annoying and monotone tasks that require accuracy and that must be done over and over again. That machine is, of course, the computer. Continue reading","title":"Don't byte me!"},{"location":"2022-07/index.html#go-ahead-and-jump","text":"All our programs have been linear so far. Let's build the base for jumping around. kratenko \u00b7 kratenko 2022-07-22 \u00b7 Entry #19 \u00b7 5 min read \u00b7 v0.0.6-journey In every program we have written so far, each instruction just advances the PC[^pc], until we reach the end. That is very linear. We will now introduce a new opcode, that jumps to a different position in the program. Continue reading","title":"Go ahead and jump!"},{"location":"2022-07/index.html#reverse-polish-notation","text":"We are using the design of a stack machine to efficiently execute some calculations. kratenko \u00b7 kratenko 2022-07-21 \u00b7 Entry #18 \u00b7 4 min read \u00b7 v0.0.5-journey The way stack machines work can be used in programs that execute calculations. We will look at it by implementing an example from the Wikipedia page about stack machines. Continue reading","title":"Reverse polish notation"},{"location":"2022-07/index.html#more-operations","text":"The basic operation of the VM is working. Let us add a few more opcodes, so that we can do calculations. kratenko \u00b7 kratenko 2022-07-20 \u00b7 Entry #17 \u00b7 4 min read \u00b7 v0.0.4-journey We have created a rust library that holds our virtual register machine. We can now add multiple executables to it, so that makes it easier, to write different programs and keep them (to mess around with the VM). We will add a few more opcodes to our repertoire, because only adding numbers is just plain boring. Continue reading","title":"More operations"},{"location":"2022-07/index.html#early-vm-decisions","text":"Many design decisions must be made for lovem. Here I talk about some of those in the current state. kratenko \u00b7 kratenko 2022-07-19 \u00b7 Entry #16 \u00b7 3 min read \u00b7 v0.0.3-journey I have shared and discussed source code in the recent posts. Now it is time again, to write about design decisions. I made a few of them for the code you saw. So far I have not been reasoning about those here, and some of you might have wondered already. Let's talk about them. Continue reading","title":"Early VM decisions"},{"location":"2022-07/index.html#to-the-library","text":"We turn our project from a binary project into a library project. kratenko \u00b7 kratenko 2022-07-18 \u00b7 Entry #15 \u00b7 5 min read \u00b7 v0.0.3-journey So far, our lovem cargo project holds a single binary. That is not very useful for something that should be integrated into other projects. What we need is a library . How is that done? Simple: we rename our main.rs to lib.rs . Continue reading","title":"To the library!"},{"location":"2022-07/index.html#becoming-social","text":"A new way for you to participate in my journey. kratenko \u00b7 kratenko 2022-07-15 \u00b7 Entry #14 \u00b7 < 1 min read After a few days of progress on the project itself, I spent a bit of time on the site again. We have the fancy link to our GitHub repo in the upper right corner now. But more important, I added support for comments on my entries. You can now react and ask questions or share your thought. Continue reading","title":"Becoming social"},{"location":"2022-07/index.html#turn-fragile-into-rusty","text":"After we got our Proof of Concept running, we clean up our code and make it look like a respectable Rust program. kratenko \u00b7 kratenko 2022-07-14 \u00b7 Entry #13 \u00b7 2 min read Did you play around with the program from the previous post? If you are new to Rust, you really should! At least mess around with our bytecode. You should find, that our VM does not react well to errors, yet. It simply panics! That is no behaviour for a respectable rust program. Continue reading","title":"Turn \"fragile\" into \"rusty\""},{"location":"2022-07/index.html#running-our-first-program","text":"Now, that we have a VM, we will run a program on it. kratenko \u00b7 kratenko 2022-07-12 \u00b7 Entry #12 \u00b7 3 min read So we built our very first VM and studied the code in detail. It is time to execute a program on it and look at it's output. We will look at every single step the program takes. Aren't we lucky, that our VM is so talkative during execution? Continue reading","title":"Running our first program"},{"location":"2022-07/index.html#a-vm","text":"The first draft of source code, that will be our VM, explained. kratenko \u00b7 kratenko 2022-07-11 \u00b7 Entry #11 \u00b7 8 min read I dumped some source code in front of you, and then I started to talk about programming languages. Time now, to explain what I did and why. We only have 132 lines, including comments. We will go through all parts of it. And I will talk a little about how Rust's basic syntax works, while I use it. Not too much, since it is not good Rust code, yet, but to help you start. This will be a longer entry. Continue reading","title":"A VM"},{"location":"2022-07/index.html#it-looks-so-weird","text":"Now, that you have seen some code, I might have to explain a bit again. Depends, on where you are coming from, I guess. kratenko \u00b7 kratenko 2022-07-10 \u00b7 Entry #10 \u00b7 4 min read So, did you take a look at the code, yet? In case you've forgotten, this is my \"initial commit\": Continue reading","title":"It looks so weird"},{"location":"2022-07/index.html#let-there-be-source-code","text":"Finally, I will be showing some source code. Not directly in the journal, but I will link you to GitHub, for a start. kratenko \u00b7 kratenko 2022-07-08 \u00b7 Entry #9 \u00b7 2 min read I have written code. And this time, I (re-)started lovem in a public git repository, so you can see what I do, if you are interested. And I hope it puts enough pressure on me, to keep on the project for a while. Continue reading","title":"Let there be source code"},{"location":"2022-07/index.html#making-virtual-a-reality","text":"So I have been talking a lot about VMs without doing anything concrete. Well that is not true, I have done quite a bit already, but I am still describing earlier steps. We will get there. kratenko \u00b7 kratenko 2022-07-06 \u00b7 Entry #8 \u00b7 3 min read","title":"Making virtual a reality"},{"location":"2022-07/index.html#registers","text":"When I was looking around for a scripting language to use inside our embedded devices, I came across an article I mentioned in an earlier post: [Creating a Virtual Machine/Register VM in C][register-book]. Continue reading","title":"Registers?"},{"location":"2022-07/index.html#what-is-a-virtual-machine-anyway","text":"kratenko \u00b7 kratenko 2022-07-04 \u00b7 Entry #7 \u00b7 5 min read So, how do you build a Virtual Machine. There are actually two quite different approaches: Continue reading","title":"What is a Virtual Machine anyway?"},{"location":"2022-07/index.html#all-new-once-more","text":"Reality strikes again, and code will be written from scratch once more. And the reason is this site. kratenko \u00b7 kratenko 2022-07-03 \u00b7 Entry #6 \u00b7 < 1 min read You want me to get to the code. And I really should. I have written so much already, and I want to show it, but there is so much around it. And after I had written up a long text on how I started, I realised that I had no commits during the early state. So I had to write it all again, slower, and with code to be presentable in this journal. Continue reading","title":"All new once more"},{"location":"2022-07/index.html#state-of-the-journal","text":"Since I am always focused on my work on lovem, I will never get sidetracked. Unrelated: I spent a few days on reworking the journal on this site. kratenko \u00b7 kratenko 2022-07-01 \u00b7 Entry #5 \u00b7 3 min read So, no update on the core project today, sorry. I was very unhappy with my first solution, on how the Journal entries where created. Way too much to do by hand \u2013 that is not what I learned programming for. But mkdocs is python, and python I can do. So did. And now I can write my Journal entries (like this one) as plain Markdown files with very few metadata entries. And I get entries in the navigation and pages listing the whole month. I even included a whole month in single page version of the journal. I feel it is quite fancy. I will need to do a bit of work on the static content of the site, but one step at a time. Continue reading","title":"State of the Journal"},{"location":"2022-07/ALL.html","text":"Complete month of July 2022 \u00b6 State of the Journal \u00b6 Since I am always focused on my work on lovem, I will never get sidetracked. Unrelated: I spent a few days on reworking the journal on this site. kratenko \u00b7 kratenko 2022-07-01 \u00b7 Entry #5 \u00b7 3 min read So, no update on the core project today, sorry. I was very unhappy with my first solution, on how the Journal entries where created. Way too much to do by hand \u2013 that is not what I learned programming for. But mkdocs is python, and python I can do. So did. And now I can write my Journal entries (like this one) as plain Markdown files with very few metadata entries. And I get entries in the navigation and pages listing the whole month. I even included a whole month in single page version of the journal. I feel it is quite fancy. I will need to do a bit of work on the static content of the site, but one step at a time. What I want \u00b6 I want to write my Journal entries (aka blog posts) as a nice standalone markdown file, one file per entry. I will need to add include a bit of metadata, at least the release date/time. And I want the entries to look fancy without adding the fanciness to each file. Maybe I will be changing the layout later, hmm? And create those teaser pages for me, thank you very much. And I have all that, now! Just look at the source that is used to generate this entry . How it works \u00b6 I use a plugin called mkdocs-gen-files , by @oprypin , that creates additional mkdocs source files on the fly. It does not really put the files on disk, but they are parsed by mkdocs, as if they were in the docs directory. I have a directory journal next to my docs directory, where I put all my posts in a single markdown file each. My script walks through that directory, and processes each file. The content is modified a bit (to put in the card with the author's name and other metadata), and then put in a virtual file inside docs , so that the pages with the entries are created by mkdocs, as if I hat them inside docs . The script also generates two pages for each month: one that shows that month's posts as teasers, with a \"continue reading\" link, and a second one that shows all posts from a month on a single page, so that you can read them without changing pages all the time. The remaining part is adding all the pages, that the script creates, to the navigation in a way that makes sense. The order is a critical part, being a central aspect of a journal or a log. For that I use another plugin by @oprypin : mkdocs-literate-nav . With it, you can control your navigation (completely or in parts) by adding markdown source files with lists of links. This goes together well with the gen-files plugin, because I can just create that navigation files with it in my script. The plugins are a bit light on the documentation side. It took me a while to understand, that you cannot do multiple layers of nested navigation in those files. That is not a problem, because you can always just add another nesting layer by adding more of those nav files as children. Also, what you can do in those files is very limited. I wanted to do some fancy things in the navigation (adding a second link in a single line with alternative representation). I would guess that those limitations come from the ways mkdocs itself handles the navigation, so that is okay. But a word on that would have been nice. And the error messages popping up did not help at all, because the actual error happens way later in the process inside mkdocs itself and is some weird side effect problem. The script \u00b6 If you want to take a look, see blogem.py . That will be the script in its current state. For the version of the script at the time of writing, see the permalink, the original blogem.py . TODOs \u00b6 Automated reload in mkdocs serve when I edit entry sources. just add parameter -w journal to mkdocs serve Exclude journal overview and full month pages from search. Exclude NAV.md from generating NAV.html . Maybe add tags and/or categories for posts? Maybe enable comments, as in material's blog. Add links to source in github repo. Add links to entry's history in github repo. Support multiple posts per day (by adding time to \"released\"). All new once more \u00b6 Reality strikes again, and code will be written from scratch once more. And the reason is this site. kratenko \u00b7 kratenko 2022-07-03 \u00b7 Entry #6 \u00b7 < 1 min read You want me to get to the code. And I really should. I have written so much already, and I want to show it, but there is so much around it. And after I had written up a long text on how I started, I realised that I had no commits during the early state. So I had to write it all again, slower, and with code to be presentable in this journal. If you are reading this live (and no-one is, because I did not even tell anyone I am doing this), you can of course look at the code I was writing earlier, it exists. I put it in a branch too-early . But I will not give explanations to that. I am rewriting it on the master branch, and that will be showed and discussed in the journal. I advise you to wait for that. Yes, it will take a while. As it looks now, it will be slow. But I have written some new posts on the new code already, and I think it is worth it. There will be more background before we get there. Next entry will be a longer one, so there is that. What is a Virtual Machine anyway? \u00b6 kratenko \u00b7 kratenko 2022-07-04 \u00b7 Entry #7 \u00b7 5 min read So, how do you build a Virtual Machine. There are actually two quite different approaches: Register Machine vs. Stack Machine Let's take a look at those concepts first. This will be very brief and basic. You can, of course, also have some combination of those concepts, and not everything I say here is true for every implementation of virtual machine, but it will be close enough for this article. Register Machines \u00b6 Most physical computers are register machines. At least those you will be thinking of. You are most likely using one right now to read this article. Virtual register machines use the same concepts, but not in physical hardware, instead inside another computer as software. This allows them to do some things a bit more flexible than a real hardware machine would. A register is nothing more than a dedicated place to store a portion of data where it can be accessed for direct manipulation. They are more or less a variable of the machine's basic data type that have a fixed address, and that can be accessed and manipulated directly by the processing unit. Register machines use those to actually compute and change data. All other storage places are only that: places where data is put when it is not needed at the moment. Register machines have a multitude of registers, from a very few (maybe 4 or 8 in simplistic designs) to hundreds or more in modern computers. The size of the registers often gives the architecture its name. E.g. in the x86-x64 architecture, that most current CPUs by Intel and AMD are of, a register is 64 bits long. The instructions for a register machine are encoded in code words . A code word is a bunch of bytes that tell the machine what to do in the next program step. For simple designs, code words are of a fixed length. This code word length is often longer than the register size. So a 16 bit architecture could have 32 bit instructions. The reason for this is, that instructions consist of an operation code that defines what operation should be executed in the next step, but they also contain the arguments passed to that operation. Because the number and size of arguments needed for an operation differ for different operations, decoding the instruction can be quite complicated. When you put multiple instructions together, you end up with a program. This representation of a computer program is called machine code . For a virtual machine it is also called bytecode , although I think this term fits better for stack machines (more on that later). If you want to understand what I tried to describe here, read this really short article: Creating a Virtual Machine/Register VM in C . It builds a simplistic register VM in C (the whole thing is 87 lines long). It demonstrates the principles used in a register machine (fetch, decode, execute), and shows you what a register is and how it is used. You will understand, how machine code is decoded and executed. The article only uses 16 bit code words and 16 bit data words (register size). If you know C, you should be able to understand what I am talking about in about an hour of reading and coding. If you ever wanted to understand how a computer works on the inside, this might be a nice place to start, before you read about an actual physical computer. A register machine normally has multiple stacks it uses. This does not make it a stack machine, those are just needed to store data when it is not currently used. So a typical operations would be: * \"Take the number from register 0, take the number from register 1, add those two numbers together, write the result in register 0.\" * \"Take the lower 16 bits of this instruction and write them in register 2.\" Lua and Neko are virtual register machines (at least in current versions). Stack Machines \u00b6 And then there are Stack Machines . They are, I think, easier to understand than register machines, but following a program during execution is more confusing, since the manipulated data is more complicated to follow. A stack is just a pile of data. Data is portioned in fixed sizes, a portion is called a word. All you can normally do is put a word on top of the stack - we will call that operation a push , or you can take the word that is currently on top of the stack (if there is one) - we will call that a pop . No other direct manipulations of the stack are allowed (I say \"direct manipulations\", because indirectly there often are ways that this is done, but that is a detail for later). Manipulation of data is done this way by the machine. If you want to add two numbers, say 5 and 23, you would write a program that does this: Push the first number to the stack. Push the second number to the stack. Execute the \"ADD\" operation. That operation will pop the two numbers from the stack, add them, and push their sum back on the stack (so that after the operation there will be one word less on the stack). A stack machine will also typically have some additional place to store words when you do not need them on the stack. These places can relate to variables inside a program. As you can see from the example above, instructions in a stack machine often do not need to have arguments. If data is to be manipulated, it is always on top of the stack. There is no need to address its location, as you would do in a register machine. Because of this, the instructions for a stack machine are typically encoded in a single byte. This byte holds a number we will call opcode (short for operation code), that simply identifies the operation to execute. If your operation does need additional arguments, you write them to the bytes following your opcode byte (the oparg ), so that the operation can read them from your program. This structure of single bytes encoding our program is why we call this representation bytecode . The concept of a stack machine is easy to implement in software, but it is not so easy to do so in hardware. That is why your typical computer is a register machine. There are, however, a lot of historical examples of important physical stack machines. The most famous example of a virtual stack machine is the Java VM . Java source code is compiled to bytecode that is executed inside a virtual machine, the JVM. This vm is so common, that many newer programming languages compile to Java bytecode. It makes it possible to run programs written in that languages on any system that has a JVM; and that includes just about every major and many minor computer systems. A second example for a stack machine is the Python VM. Some random thought on register and stack machines \u00b6 While writing this down, describing the two kinds of machines I couldn't help but notice a curious fact: A register machine manipulates data inside addressable registers. When the data is not need, it can be stored away in some kind of stack. A stack machine manipulates data inside a stack. When the data is not needed, it can be stored away in some kind of addressable spaces, not unlike registers. It looks as if you just need both concepts to work efficiently. Making virtual a reality \u00b6 So I have been talking a lot about VMs without doing anything concrete. Well that is not true, I have done quite a bit already, but I am still describing earlier steps. We will get there. kratenko \u00b7 kratenko 2022-07-06 \u00b7 Entry #8 \u00b7 3 min read Registers? \u00b6 When I was looking around for a scripting language to use inside our embedded devices, I came across an article I mentioned in an earlier post: Creating a Virtual Machine/Register VM in C . Reading it made me want to try working with a register machine, mainly because I have not been stuff like this since my early semesters. Never hurts to refresh rusty knowledge. So I started designing a register VM, starting from that code, but more complex, with longer data words and longer instruction words, more registers, and so forth. For this project I came up with lovem as a working title. It still stuck to now, two approaches and a year later. I also started implementing some concepts I still want to add to lovem in my current approach, but that is for a later post to discuss. I was experimenting with a quite complicated instruction word encoding. I was trying to fit everything in a few bits (32 of them if I recall correctly) with varying instruction code length and quite long arguments. I wanted to include instructions on three registers, which takes up quite some bits to address. Of course, you can get away with two-register operations only - or if you are fancy you can even use a single address or even no address for most instructions. You will just end up with a lot of register swapping. I guess my rational for having three addresses in an instruction was code size. For what I want to do, 32 bit instruction words feel quite long (4 bytes per instruction!). And every swap would mean another 4 bytes of program size. So trying to optimise for fewer operations by having more flexible instructions. I do not even know if that rational makes sense. I guess I would have needed to try different layouts to find out. Or maybe read more about that topic, other people have done similar things I assume. But I never got that far. The experiment showed me, that I do not want to build lovem as a register machine. I think building a clever register based architecture for my goals would make it too complicated. I want simple. To reduce the VM's overhead, but also on principle. Complexity is the enemy. I'm pretty sure, that code still exists somewhere, but there is no sense in publishing it or even in me reading it again, so you will never see it. I think of it as a pre-study with a very useful conclusion: not a register machine. Stacks! \u00b6 So a stack machine it is! I have looked at a few during my research for lovem, looking at instruction sets and design ideas. It is not the first time, I have been working with those. In a different project (around the same time I started work on the register based machine), I was starting to implement a stack machine. That one had a different aim and therefore very different challenges. It was more of an object-oriented approach with dynamic program loading and calling code in different programs. It could do quite a few things already, but it will never be continued. I learned a bit about calling conventions and found out that it is not so simple, when you want to switch between multiple programs and objects. That is where the project got too frustrating for me (and some external events made it obsolete, so that is okay). But I take it for a pre-study on stack machines and calling conventions. Not that I have developed a proven concept for it, but I know about the problems there... I had a PoC for lovem as a stack machine back then, too (right after I ditched the register approach). That code won't be published either, but the attempt showed me, that I want to take that road for a serious approach on creating lovem. Onwards \u00b6 I guess this concludes the prehistory of the lovem story. I am, for whatever reason, back on the project, currently with a decent amount of motivation. You never know how long that lasts, but right now I like the idea of continuing the development, while talking about the development process, sharing my thoughts on decisions I make. Next post should start on sharing newer thoughts. Let there be source code \u00b6 Finally, I will be showing some source code. Not directly in the journal, but I will link you to GitHub, for a start. kratenko \u00b7 kratenko 2022-07-08 \u00b7 Entry #9 \u00b7 2 min read I have written code. And this time, I (re-)started lovem in a public git repository, so you can see what I do, if you are interested. And I hope it puts enough pressure on me, to keep on the project for a while. In fact, there is quite a bit of code there already. I started coding, before writing any of this, and it went so well. I like how it feels. I was working any hour I could spare. When a friend asked me what I was doing, I started a somewhat complex backstory why I was doing it, instead of actually explaining anything of the stuff I was doing \u2013 and was interrupted quite early, so there was more to tell in me still. The next day, I sat down and started to write all of that down as a little story. I wanted to put it somewhere, so I started this journal to publish it. And I decided to do it in blog form, so I am publishing that background story bit by bit. So, as of writing this, there is a lot of work completed on the VM. Tt is amazing what things it can do for how little code there is. When this post goes public, there should be quite lot more done... But where is the code? \u00b6 Well, if you read this journal, you will know where it lives. Anyway, this is the repo: https://github.com/kratenko/lovem I plan to continue sharing my thoughts while I work on the VM. So you will be able to follow my failures and see the attempts that I will be ditching later. I think the format of this journal can work out, but we will see how I like it over time. It will be behind on progress, as I want to take time to share things as they unfold. And this should help to produce a somewhat continuous publication stream. Git being what git is, should support me in showing you the things I do back in time, using the power of commits. As things are with blogs, my entries will be very different, depending on what I want to tell and on what I did. So far most blogs where conceptional thinking, some research, and a lot of blabla, which I tell because it interests me myself. In the future, there should be concrete problems I find and solve in source code - or which I fail to solve. Back in time \u00b6 Me original first commit was way too late and contained way too much code. Also, I did not plan to show it to you like this, back then. So, as mentioned before, I rolled back and started again, with more commits. And I am keeping tags now, so that I have well-defined versions for my blog posts. That should make it easy for you to follow up, if you want to. The new, artificial \"first commit\" is now a tag/release: v0.0.1-journey . You can view the code for any tag online, this one you will find under: https://github.com/kratenko/lovem/tree/v0.0.1-journey I think this will be a theme of this journal: linking you to what I did, when I am writing about it. And I will try to share my trails of thoughts, leading to my decisions (and errors, as it will be). I will do that, for that v0.0.1-journey, soon, don't worry, I will explain everything I did. But the next journal entry will be about some decisions again; mainly about the language I am using. It looks so weird \u00b6 Now, that you have seen some code, I might have to explain a bit again. Depends, on where you are coming from, I guess. kratenko \u00b7 kratenko 2022-07-10 \u00b7 Entry #10 \u00b7 4 min read So, did you take a look at the code, yet? In case you've forgotten, this is my \"initial commit\": https://github.com/kratenko/lovem/tree/v0.0.1-journey It is not the original initial commit, as I did commit way too late, and it was not suitable for writing a story about it. So I created a new, clean version, with just very simple concepts that I can explain in a single entry. In the next entry, that is. If you are thinking: \"What is that weird source code?\", then you are in for a real treat (and a lot of pain), should you chose to follow up. The code you are seeing is written in Rust . Once again: but why? \u00b6 Why Rust? Because Rust! Writing Rust can feel so good! And for something like a VM, it is such a good choice. If you have never heard of the language (or heard of it, but never looked into it), it is hard to understand why this is so. My advice: try it! use it! Or read along this journal, code along, you might like it. When you start, chances are high that you will not like Rust. The compiler is a pedantic pain in the ass. But at the same time it is incredibly polite, trying to help you find out, what you did wrong, and suggesting what you might want to do instead. And Rust really, really tries, to keep you from shooting yourself in the foot. It tries to make common mistakes impossible or at least hard to do \u2013 those mistakes that happen everywhere in C/C++ programs and their like. Yes, those mistakes that are the cause of the majority of all security problems and crashes. Buffer overruns, use after free, double free, memory leak \u2013 to name just some common ones from the top of my head. And Rust makes all it can to make those mistakes impossible during compilation! So it does not even add runtime overhead. That is so powerful! And it is so painful. Half of the things you do, when writing C/C++, you will not be able to do in Rust in the same way. Every piece of memory is owned. You can borrow it and return it, but it cannot be owned in two places at once. And if any part of the program has writing access to it, no other part may have any access. This makes some data structures complicated or impossible (there are ways around it), and you will have to think quite differently. But if you give in on that way of thinking, you can gain so much. Even peace of the mind, as the coding world will look a lot saner inside Rust source code. This will, of course, come with the price, that all code in other languages will start to feel dirty to you, but that is the way. Also, there are a lot of ways to write code, that you cannot add to a language that already exists. C and C++ will never be freed of their heritage; they will stay what they are, with all their pros and cons. Things are solved differently in Rust. Did I mention there is no NULL ? And I have never missed it for a moment. Rust solves the problems other languages solve with NULL by using enums. That comes with certainty and safety all the way. There are no exceptions either. That problem is also solved by using enums. The way the language embraces those, they are a really powerful feature! And there are lot more convenient ways of organising code, that I keep missing in my daily C/C++ life. I will not write an introduction into Rust here. At least not your typical \"how to get started in rust\" intro. There are a lot of those out there, and I am already 10 posts into my Journal without programming. Maybe the Journal will become a different kind of Rust introduction, as it will try to take you along a real project, as it develops, from the beginning on. I will run into problems along the way and try to solve them in Rusty ways. This might be a good way, to start thinking in Rust. But, to be honest, I did never finish a project in Rust, yet. I got quite a bit running and functional, and I think in some parts in a rust-like way. But this is for me as much as anyone else as a learning project. I will make weird things. But the basics, I have worked with, yeah. The initial learning curve will be steep! I try to not get too fancy in the first draft, so the code will not be good Rust there! So, if you are shocked at how bad my Rust is \u2013 it will be very different, soon. But I want to give everyone a fair chance to hop on without understanding all the concepts. The initial code should be not too hard to follow, if you know C/C++, I hope. Learning a new thing (writing a VM) in a new, quite different language is a mouth full, I know. Didn't you say, you use C/C++? \u00b6 Yes I did say that. And I do use those. It is not easy to change that, when you have a certain amount of legacy code (and not much experience with the new language, as we do not really have, yet). But we do have a saying these days. Often, after a debugging session that lasted for hours, when we find the bug, understand it and fix it, there is this realisation, that fits in the sentence: \"Mit Rust w\u00e4r' das nicht passiert.\" \u2014 \"This would not have happened with Rust.\" So, this will not happen to me with this project, because those things will not happen with Rust! A VM \u00b6 The first draft of source code, that will be our VM, explained. kratenko \u00b7 kratenko 2022-07-11 \u00b7 Entry #11 \u00b7 8 min read I dumped some source code in front of you, and then I started to talk about programming languages. Time now, to explain what I did and why. We only have 132 lines, including comments. We will go through all parts of it. And I will talk a little about how Rust's basic syntax works, while I use it. Not too much, since it is not good Rust code, yet, but to help you start. This will be a longer entry. I swear, if I do not see some code in this post... \u00b6 Alright, alright... We will start with our VM: # #[derive(Debug)] pub struct VM { stack : Vec < i64 > , pc : usize , op_cnt : usize , } Nothing fancy, just a struct that will represent our Virtual Machine. Only three fields for now: stack : Obviously our stack machine would need one of those. This will hold values during execution. I am using a Vector. That is nothing more than a chunk of memory, that knows how much capacity it has and how many values are in it at the moment. It does support resizing, but I do not want to use that. pc will be our program counter . That is a register 1 holding the progress in the program during execution. It will always point at the instruction that is to be executed next. op_cnt will be counting the number of operations executed. For now, I want that information out of curiosity, but later it will be useful for limiting execution time for programs. usize and i64 are Rust's names for integer types. The language is very explicit in those terms (and very strict, as in every aspect). I will not give a real introduction to Rust for you (there are pages that do that), but I will try to start slowly and give you hints on the important things I introduce, so that you get the chance to learn about them parallel to this journal. I hope, that makes it easier to follow for Rust beginners. To readers that know Rust: please excuse the crude code here! I will make it more rusty, soon. Skip to the next post, if you cannot handle it. We will also need a program that we will run in our VM. For the start, a crude array of bytes will do. The VM will be running bytecode after all. And that really is only that: a bunch of bytes, that you will soon be able to understand. // assign `pgm` to hold a program: let pgm = [ 0x00 as u8 , 0x01 , 100 , 0xff ]; We will use a program that is a bit longer, but right now I wanted you to see a program, that is actually nothing but a collection of bytes in Rust code. let declares and assigns a variable here, named pgm . It is an array of 4 bytes ( u8 is an unsigned 8bit integer - you might know it as uint8_t from other languages). And that variable will not be variable at all. By default, all variables in Rust are immutable. If you want to change it, later, you would have to declare it using the modifier mut . There is no need to modify the program after creation, we just want to read it for execution. But our VM will have to be mutable, as it has changing internal state. Here is our complete main function, creating the (immutable) program and the (mutable) VM, and running the program. Of course, the run(...) method is still missing. And you will see the program, we will be using (with some constants that I did not define, yet). fn main () { // Create a program in bytecode. // We just hardcode the bytes in an array here: let pgm = [ op :: NOP , op :: PUSH_U8 , 100 , op :: PUSH_U8 , 77 , op :: ADD , op :: POP , 0xff ]; // Crate our VM instance. let mut vm = VM { stack : Vec :: with_capacity ( 100 ), pc : 0 , op_cnt : 0 }; // Execute the program in our VM: vm . run ( & pgm ); } Behaviour for our VM \u00b6 So far we only have an initialized data structure and some bytes. Let's do something with it. Rust does not really use objects (and I think that is good). But it has associated functions that work on types, and methods that work on instances of types. We will write some methods for our VM struct. Let's start with the one for reading our program: impl VM { /// Fetch the next byte from the bytecode, increase program counter, and return value. fn fetch_u8 ( & mut self , pgm : & [ u8 ]) -> u8 { if self . pc >= pgm . len () { panic! ( \"End of program exceeded\" ); } let v = pgm [ self . pc ]; self . pc += 1 ; v } } The fetch method will work on our VM instance. The first parameter is &mut self \u2013 that tells us it works on an instance of the type VM . It will work on a reference to the instance (indicated by the & ), and it can modify the data (indicated by the mut ). It will also take the reference to an array of u8 s, but that it will not be able to modify (no mut ). It returns a u8 . What it does is simply read and return a byte from the program, and increase the VMs internal program counter by one, so that the next call to fetch will return the next byte. Simple. So, what is that panic!() you might ask? Well, if we reach that instruction, it will start to panic, and then it will die. That is not a nice way to act. Do not worry, we will change that to something more reasonable, when we start writing better Rust. And what about the naked v in the last line? It will have the function return the value of v . Now, let's look at that run method, we were calling in main : impl VM { /// Executes a program (encoded in bytecode). pub fn run ( & mut self , pgm : & [ u8 ]) { // initialise the VM to be in a clean start state: self . stack . clear (); self . pc = 0 ; self . op_cnt = 0 ; // Loop going through the whole program, one instruction at a time. loop { // Log the vm's complete state, so we can follow what happens in console: println! ( \"{:?}\" , self ); // Fetch next opcode from program (increases program counter): let opcode = self . fetch_u8 ( pgm ); // We count the number of instructions we execute: self . op_cnt += 1 ; // If we are done, break loop and stop execution: if opcode == op :: FIN { break ; } // Execute the current instruction (with the opcode we loaded already): self . execute_op ( pgm , opcode ); } // Execution terminated. Output the final state of the VM: println! ( \"Terminated!\" ); println! ( \"{:?}\" , self ); } } The comments should explain, what is going on there. Initialise VM, then loop over the program, fetching one instruction at a time and executing it, until we reach the end. And you might have noticed, that our program will be very talkative. I added a lot of println s, that tell just about everything that happens, during execution. I guess it is time to look at those op:: constants I keep using. /// Module holding the constants defining the opcodes for the VM. pub mod op { /// opcode: Do nothing. No oparg. /// /// pop: 0, push: 0 /// oparg: 0 pub const NOP : u8 = 0x00 ; /// opcode: Pop value from stack and discard it. /// /// pop: 1, push: 0 /// oparg: 0 pub const POP : u8 = 0x01 ; /// opcode: Push immediate value to stack. /// /// pop: 0, push: 1 /// oparg: 1B, u8 value to push pub const PUSH_U8 : u8 = 0x02 ; /// opcode: Add top two values on stack. /// /// pop: 2, push: 1 /// oparg: 0 pub const ADD : u8 = 0x10 ; /// opcode: Terminate program. /// /// pop: 0, push: 0 /// oparg: 0 pub const FIN : u8 = 0xff ; } Just 5 u8 constants there, grouped in a module as a namespace. And a lot of comments to explain them. We have 5 different operations for our VM. The only thing missing is some code, that actually executes those instructions: impl VM { /// Executes an instruction, using the opcode passed. /// /// This might load more data from the program (opargs) and /// manipulate the stack (push, pop). fn execute_op ( & mut self , pgm : & [ u8 ], opcode : u8 ) { println! ( \"Executing op 0x{:02x}\" , opcode ); match opcode { op :: NOP => { println! ( \" NOP\" ); // do nothing }, op :: POP => { println! ( \" POP\" ); let v = self . stack . pop (). unwrap (); println! ( \" dropping value {}\" , v ); }, op :: PUSH_U8 => { println! ( \" PUSH_U8\" ); let v = self . fetch_u8 ( pgm ); println! ( \" value: {}\" , v ); self . stack . push ( v as i64 ); }, op :: ADD => { println! ( \" ADD\" ); let a = self . stack . pop (). unwrap (); let b = self . stack . pop (). unwrap (); self . stack . push ( a + b ); }, _ => { panic! ( \"unknown opcode!\" ); } } } } You can think of the match as a switch statement. It is much more than that, but here we use it as one. Each of our opcodes is handled individually. And we log a lot, so that we can read what is happening, when we run it. Ignore the unwrap() thingies for the time being. They are just there to try and ignore potential runtime errors. Again, not good Rust style, but, you know: later. The four operations get more complex in what they do. Let's go through them one by one: NOP \u2013 this does nothing, it just wastes bytecode and execution time. I have included it simply to be the most basic operation possible. POP \u2013 this is our first modification of the stack. It simply discards the topmost value, decreasing the stack's size by one. PUSH_U8 \u2013 this is the only operation that reads additional data from the program. It only reads a single byte (increasing the program counter by one), and puts it on top of the stack, increasing the stack's size by one. This is how you can get data from your program into the VM, to work with them. It is how numeric literals in your program are handled. ADD \u2013 the only operation that works on data. It pops its two operands from the stack, adds them, and pushes the sum back on the stack. This is how data is manipulated in a stack machine. The operation reduces the stack's size by one effectively, but there need to be at least 2 values on it for it to be executed. That is the out complete VM so far, and it will execute a program, if you compile and run it (which we will do in the next post). You can find the complete program here: https://github.com/kratenko/lovem/blob/v0.0.1-journey/src/main.rs You can access the repo at this state under (there is also a zip file containing all files): https://github.com/kratenko/lovem/releases/tag/v0.0.1-journey How do I work with the code? \u00b6 The easy way, to get the code and play with it, would be to clone the git repository and check out the tag v0.0.1-journey . If you did not understand any of that, you might want to do a tutorial on git, before you continue reading. Anyways, here is some copy&paste commands, you can hack into your bash prompt, to do, what I just told you to do. Use at your own risk, I'm not responsible for what you do to your system. you@host:~$ git clone https://github.com/kratenko/lovem.git you@host:~$ cd lovem you@host:~/lovem$ git checkout v0.0.1-journey you@host:~/lovam$ cargo run lovem This will copy all source code from GitHub and its history to your computer, and it will roll the source code to the state we are looking at in this entry. The last command cargo run lovem will compile and execute the program - that is, if Rust is installed and ready to run (and in the correct version). cargo is Rust's package manager, that handles dependencies and compiles your projects. I will not explain those things further, but now you know what to look for. Running our first program \u00b6 Now, that we have a VM, we will run a program on it. kratenko \u00b7 kratenko 2022-07-12 \u00b7 Entry #12 \u00b7 3 min read So we built our very first VM and studied the code in detail. It is time to execute a program on it and look at it's output. We will look at every single step the program takes. Aren't we lucky, that our VM is so talkative during execution? If you missed the code, look at the previous post, A VM . Let's go! \u00b6 /home/kratenko/.cargo/bin/cargo run --color=always --package lovem --bin lovem Finished dev [unoptimized + debuginfo] target(s) in 0.00s Running `target/debug/lovem` VM { stack: [], pc: 0, op_cnt: 0 } Executing op 0x00 NOP VM { stack: [], pc: 1, op_cnt: 1 } Executing op 0x02 PUSH_U8 value: 100 VM { stack: [100], pc: 3, op_cnt: 2 } Executing op 0x02 PUSH_U8 value: 77 VM { stack: [100, 77], pc: 5, op_cnt: 3 } Executing op 0x10 ADD VM { stack: [177], pc: 6, op_cnt: 4 } Executing op 0x01 POP dropping value 177 VM { stack: [], pc: 7, op_cnt: 5 } Terminated! VM { stack: [], pc: 8, op_cnt: 6 } Process finished with exit code 0 What just happened? \u00b6 It is quite talkative. And isn't it nice, how easy it is, to print the complete state of our VM in Rust? And it costs no overhead during runtime, as it is generated during compilation for us. Isn't that something? So, what is happening there? Our program pgm looks like this: let pgm = [ op :: NOP , op :: PUSH_U8 , 100 , op :: PUSH_U8 , 77 , op :: ADD , op :: POP , 0xff ]; That are 8 bytes that consist of 6 instructions. Each instruction has a 1 byte opcode. Two of those instructions (the PUSH_U8 ) have one byte of argument each, making up the remaining two bytes of our program. Here they are listed: NOP PUSH_U8 [100] PUSH_U8 [77] ADD POP FIN The NOP does not do anything. I just put it in front of the program to let you see fetching, decoding, and executing without any effects: VM { stack: [], pc: 0, op_cnt: 0 } Executing op 0x00 NOP VM { stack: [], pc: 1, op_cnt: 1 } We just increased the program counter by one (we advance one byte in the bytecode), and the operation counter counts this executed instruction. Let's look at the next instruction, that is more interesting: VM { stack: [], pc: 1, op_cnt: 1 } Executing op 0x02 PUSH_U8 value: 100 VM { stack: [100], pc: 3, op_cnt: 2 } Here the PC is increased by two. That happens, because we fetch an additional value from the bytecode. The op_cnt is only increased by one. And we now have our first value on the stack! It is the byte we read from the bytecode. Let's do that again: VM { stack: [100], pc: 3, op_cnt: 2 } Executing op 0x02 PUSH_U8 value: 77 VM { stack: [100, 77], pc: 5, op_cnt: 3 } Now there are two values on the stack! Time to do something with them. Let's add them up: VM { stack: [100, 77], pc: 5, op_cnt: 3 } Executing op 0x10 ADD VM { stack: [177], pc: 6, op_cnt: 4 } Now there is only one value left on the stack, and it is the sum of the two values we had. There happened quite a lot here. The two values we had before where both popped from the stack (so it was shortly empty). The add operation adds them, and pushes their sum back on the stack. So now there is one value on the stack, and it is the result of our adding operation. What's next? VM { stack: [177], pc: 6, op_cnt: 4 } Executing op 0x01 POP dropping value 177 VM { stack: [], pc: 7, op_cnt: 5 } It is always nice to leave your workplace all tidied up, when you are done. We can do that by popping our result back from the stack, leaving it empty. And besides, our POP operation prints the value it drops. One more instruction to go: VM { stack: [], pc: 7, op_cnt: 5 } Terminated! VM { stack: [], pc: 8, op_cnt: 6 } Well, not much happening there. Just stopping the VM, because we are done. Success! \u00b6 So, we ran a program in a VM. Hooray, we are done. Only 132 lines of code, including excessive comments and logging. That was easy. Well yeah - it doesn't do much. But you can understand the root principle that makes up a stack machine. It's that simple. Go play around with it a bit. It is the best way to learn and to understand. I mean it! Write a longer program. What happens to the stack? Add another opcode \u2013 how about subtraction? Will your program execute at all? What happens, if it does not? Turn \"fragile\" into \"rusty\" \u00b6 After we got our Proof of Concept running, we clean up our code and make it look like a respectable Rust program. kratenko \u00b7 kratenko 2022-07-14 \u00b7 Entry #13 \u00b7 2 min read Did you play around with the program from the previous post? If you are new to Rust, you really should! At least mess around with our bytecode. You should find, that our VM does not react well to errors, yet. It simply panics! That is no behaviour for a respectable rust program. We will make it more rusty, look at the enhanced version: Repo: https://github.com/kratenko/lovem/tree/v0.0.2-journey main.rs: https://github.com/kratenko/lovem/blob/v0.0.2-journey/src/main.rs If you do not know your way around Rust, some of those things will be difficult to understand. It might be time to read up on some Rust, if you intend to follow my journey onwards. I will not explain everything here, but I will give you some leads right now, if you want to understand the things I did in that change. It is all in the enums \u00b6 The most important thing to understand for you will be Enums . Yeah, I know. That is what I thought at first learning Rust. \"I know enums. Yeah, they are handy and useful, but what could be so interesting about them?\" Well, in fact, enums in Rust completely change the way you are writing code. They are such an important part of the language that they have an impact on just about every part of it. I introduced an enum to the code: # #[derive(Debug, Clone, PartialEq)] pub enum RuntimeError { EndOfProgram , InvalidOperation ( u8 ), StackUnderflow , StackOverflow , } It is obviously a datatype to communicate runtime errors of different nature. And I use it a bit like you would exceptions in some other languages. Nevermind the #[derive...] part for now. That is just for fancy debug output (and a bit more). Once you understand line 33 : InvalidOperation(u8), , you are on the right track! To put it into easy terms: values of enums in Rust can hold additional values. And, as you see in our RuntimeError , not all values have to hold the same kind of additional value, or a value at all. This is, what makes enums really powerful. If you know what happens in the return type of fn push in line 70 , you are golden. The Result type can communicate a value on success or an error condition on failure. The great difference to typical exceptions form other languages is, that there is no special way to pass on the errors, as with exceptions that are thrown. It is just your normal return statement used. And this is done, you guessed it, with enums. If you want to read up on Result , try understanding Option first. I am using that in my code, even though you cannot see it. If you are wondering now about the return of fn push , that does not have a return statement to be seen, you should find out, while some of my lines do not have a semicolon ; at the end, while most do. And then there is that tiny ? in line 101 . Also find out what happens in the match in [line 166][line166]. It might help if you start with the if let statement. Bonus points: line 66 . If that is clear to you, you need have no worries, you are into enums and how to use them Homework \u00b6 So, this is what will get you through a lot here. Try to understand those in the given order: Option Some(v) vs. None Result<v, e> Ok(v) vs. Err(e) if let Some(v) = match Result<(), e> Ok(()) unwrap() ? Bonus: ok() , ok_or() , and their likes If you understand for each of those, and why I put them in the list, you are prepared to handle most Rust things I will be doing in the next time. If you have problems with parts of it, still, move on. It gets better after a while, when you use them. Becoming social \u00b6 A new way for you to participate in my journey. kratenko \u00b7 kratenko 2022-07-15 \u00b7 Entry #14 \u00b7 < 1 min read After a few days of progress on the project itself, I spent a bit of time on the site again. We have the fancy link to our GitHub repo in the upper right corner now. But more important, I added support for comments on my entries. You can now react and ask questions or share your thought. I am using giscus.app (and, again, I copied that idea from @squidfunk and their site on mkdocs-material , which is what I did for this complete site, more or less). Giscus is an open source app that stores the comments completely inside GitHub discussions, so the content is stored along the lovem repository and at the one place where everything is stored already anyway. If you want to participate in the comments, you need to log in using your GitHub account. That is great, because I don't need to care about user management, nor about any database. Feel free to use this entry to try out the new feature, because that is what I am gonna do! To the library! \u00b6 We turn our project from a binary project into a library project. kratenko \u00b7 kratenko 2022-07-18 \u00b7 Entry #15 \u00b7 5 min read \u00b7 v0.0.3-journey So far, our lovem cargo project holds a single binary. That is not very useful for something that should be integrated into other projects. What we need is a library . How is that done? Simple: we rename our main.rs to lib.rs . No main? \u00b6 But wait? What about fn main() ? We do not need that inside a library. But it would be nice to still have some code that we can execute, right? Well, no problem. Your cargo project can only hold a single library, but it can hold even multiple binaries, each with its own fn main() . Just stuff them in the bin subdir. Project layout \u00b6 While we are at it, I split the project up into multiple source files, to get it organised. It is small, still, but we will have it grow, soon. Here is, what we are at now: lovem/ src/ bin/ test-run.rs lib.rs op.rs vm.rs .gitignore Cargo.toml We skip .gitignore . If you don't know what it is, google .gitignore . Cargo.toml \u00b6 So Cargo.toml holds information about our cargo project. There is not much of interest there currently: [package] name = \"lovem\" version = \"0.0.3\" edition = \"2021\" authors = [ \"kratenko\" ] [dependencies] The only real configuration in that file is edition = \"2021\" . Rust has a major edition release every three years. These are used to introduce braking changes. You have to specify the edition you use explicitly, and there are migration guides. We use the most recent one, 2021 . lib.rs \u00b6 Rust manages projects by using default project layouts. That is why we need not write a lot into the Cargo.toml . The src directory holds our source code. The fact that it holds a lib.rs makes it a library, and lib.rs is the entry point. This is what is in it: pub mod op ; pub mod vm ; // re-export main types pub use crate :: vm :: VM ; Really not a lot. It declares the two modules op and vm and makes them public. So, whatever rust project will be using our library will have access to those modules. The modules will be in the files op.rs and vm.rs . What a coincidence, that are exactly the remaining two source files in this directory! The last line just re-exports a symbol from one of those submodules, so that programs using our library can access more easily. Will will be doing that in our binary. op.rs \u00b6 Back in v0.0.2-journey , we already had a module called op to hold the opcodes. We had it stuffed in our main.rs . Now it lives in a separate file, so we do not have to scroll over it every time. vm.rs \u00b6 This holds the rest of our source code (except for fn main() which has no place in a lib). The only new thing, compared with our former main.rs is the first line: use crate :: op ; This simply pulls the module op into the namespace of this module, so that we can access our opcode constants as we did before. The rest remains the way we already know. bin/test-run.rs \u00b6 So how do we use our lib in a project? That is best illustrated by doing it. And we can do so inside our project itself, because we can add binaries. Just put a Rust source file with a fn main() inside the bin subdir. There we can write a binary as we would in a separate project, that can use the lib. We did that in the file test-run.rs : use lovem :: { op , VM }; fn main () { // Create a program in bytecode. // We just hardcode the bytes in an array here: let pgm = [ op :: NOP , op :: PUSH_U8 , 100 , op :: PUSH_U8 , 77 , op :: ADD , op :: POP , 0xff ]; // Crate our VM instance. let mut vm = VM :: new ( 100 ); // Execute the program in our VM: match vm . run ( & pgm ) { Ok ( _ ) => { println! ( \"Execution successful.\" ) } Err ( e ) => { println! ( \"Error during execution: {:?}\" , e ); } } } This is the fn main() function from our former main.rs . Instead of having all the functions and definitions, it just has this single line at the top: use lovem :: { op , VM }; Nothing too complicated. It tells the compiler, that our program uses the library called lovem (which is, of course, the one we are writing ourselves here). It also tells it to bring the two symbols op and VM from it into our namespace. The op one is simply the module op defined in op.rs . Because lib.rs declares the module public, we can access it from here. VM does not refer to the module in vm.rs , as that module is called vm (in lower case). VM is actually the struct we defined in vm , that we use to hold the state of our Virtual Machine. We could include the struct as lovem::vm::VM , which is its full path. But I find that a bit anoying, as VM is the main type of our whole library. We will always be using that. So I re-exported it in lib.rs . Remember the line pub use crate::vm::VM; ? That's what it did. Running the binary \u00b6 So, how do we run our program now? Back in v0.0.2-journey we simply called cargo run . That actually still works, as long as we have exactly one binary. But we can have multiple binaries inside our project. If we do, we need to tell cargo which it should run. That can easily be done: cargo run --bin test-run The parameter to --bin is the name of the file inside bin , without the .rs . And no configuration is needed anywhere, it works by convention of project layout. Homework \u00b6 What, homework again? Yeah, why not. If it fits, I might keep adding ideas for you to play around with. Doing things yourself is understanding. Stuff we just read, we tend to forget. So here is what might help you understand the project layout stuff I was writing about: Add a second binary, that runs a different program in the VM (with different bytecode). You have all the knowledge to do so. And then run it with cargo. Source code \u00b6 In earlier posts I included explicit links to the source code at the time of writing. That got annoying to do really fast. So I added a new feature to my blogem.py that I use to write this journal. Entries like this, that are explaining a specific state of the source of lovem will have a tag from now on. This corresponds to a tag inside the git repository, as it did in earlier posts. You will find it in the card at the top of the post (where you see the publishing date and the author). It is prefixed with a little tag image. For this post it looks like this: v0.0.3-journey At the bottom of the entry (if you view it in the entry page, not in the \"whole month\" page), you will find it again with a list of links that help you access the source in different ways. The best way to work with the code, is to clone the repository and simply check out the tag. I also added a page on this site, explaining how you do that. You can find it under Source Code . So, in future I will not be adding explicit links, only this implicit ones. And there will be a link to the explaining page at the bottom. This should be convenient for both, you and me. Early VM decisions \u00b6 Many design decisions must be made for lovem. Here I talk about some of those in the current state. kratenko \u00b7 kratenko 2022-07-19 \u00b7 Entry #16 \u00b7 3 min read \u00b7 v0.0.3-journey I have shared and discussed source code in the recent posts. Now it is time again, to write about design decisions. I made a few of them for the code you saw. So far I have not been reasoning about those here, and some of you might have wondered already. Let's talk about them. Let me remind you: lovem is a research project for myself. And an education project for myself as well. None of my choices at this stage are set into stone. I will make lots of mistakes that I will be changing later. I even choose some paths, that I know I will be leaving again. I might just take any solution for a problem, at this stage, as I do not know, what is the right choice. So start somewhere, see where it goes. Some of those are deliberately weird or bad choices, but they make things clearer or simpler at this stage. Let us address two of those choices you can find in the current source code. Word size \u00b6 I talked about register sizes defining architecture, back in What is a Virtual Machine anyway? . And then I went totally silent about that topic and just used i64 as type for my stack. Is that a good idea? I used it for simplicity. The idea goes back to when I was experimenting with using a register machine for lovem. Having a simple datatype that can handle big values seems simple. After all, other languages/VMs use some version of float as their single numeric datatype: JavaScript JavaScript Numbers are Always 64-bit Floating Point Unlike many other programming languages, JavaScript does not define different types of numbers, like integers, short, long, floating-point etc. JavaScript numbers are always stored as double precision floating point numbers, following the international IEEE 754 standard. \u2014 w3schools.com - retrieved 2022-07-11 Lua 2.3 - Numbers The number type represents real (double-precision floating-point) numbers. Lua has no integer type, as it does not need it. \u2014 Programming in Lua - retrieved 2022-07-11 Well, reducing complexity is good. But having each little number you use in your programs eat up 8 bytes of memory does not sound low overhead to me. And that is, after all, the goal. So I guess, that will change in the future. But let's keep it for the time being. There will be some interesting things we will be doing in the near future; even if we might dump those features later. I already implemented them during the early phase (when I was not writing a public journal), so not adding them here would be insincere. Having 64 bit values is a part of our journey. Opargs \u00b6 I have no glossary, yet, so you have to live with me inventing terms on the spot. I used that word in the source code already. What I mean by it, are the arguments to an instruction inside the bytecode, that follow the opcode and influence the operation. They are the arguments you give inside your program's code. As of v0.0.3-journey we only have a single opcode that takes an oparg, and that is push_u8 . You can see how there is a fetch_u8() instruction in the code that handles that operation, and none in the other operations. See execute_op . So we have different behaviour depending on the opcode. push_u8 fetches an additional byte from the bytecode, the other opcodes do not. Existing VMs handle this differently. The Java VM, for example, has a dynamic number of opargs, too. They call them operands : 2.11. Instruction Set Summary A Java Virtual Machine instruction consists of a one-byte opcode specifying the operation to be performed, followed by zero or more operands supplying arguments or data that are used by the operation. Many instructions have no operands and consist only of an opcode. \u2014 The Java\u00ae Virtual Machine Specification - Java SE 8 Edition - retrieved 2022-07-11 The Python VM on the other hand, uses exactly one byte as oparg on all instructions The bytecode can be thought of as a series of instructions or a low-level program for the Python interpreter. After version 3.6, Python uses 2 bytes for each instruction. One byte is for the code of that instruction which is called an opcode , and one byte is reserved for its argument which is called the oparg . [...] Some instructions do not need an argument, so they ignore the byte after the opcode. The opcodes which have a value below a certain number ignore their argument. This value is stored in dis.HAVE_ARGUMENT and is currently equal to 90. So the opcodes >= dis.HAVE_ARGUMENT have an argument, and the opcodes < dis.HAVE_ARGUMENT ignore it. \u2014 Reza Bagheri - Understanding Python Bytecode - in Towards Data Science - retrieved 2022-07-11 That does remove some complexity. And adds new complexity - for opcodes with more than one oparg byte - they exist in python and are handled with a special opcode, that adds an additional oparg byte. I think it will make execution faster, as fetching can be done it advance. If you do not know, how many bytes you need, before your read your opcode, you cannot prefetch the next instructions. For our goal, keeping the bytecode small is much more important than execution time. So I am pretty sure we will stick with the dynamic number of oparg bytes in lovem. More operations \u00b6 The basic operation of the VM is working. Let us add a few more opcodes, so that we can do calculations. kratenko \u00b7 kratenko 2022-07-20 \u00b7 Entry #17 \u00b7 4 min read \u00b7 v0.0.4-journey We have created a rust library that holds our virtual register machine. We can now add multiple executables to it, so that makes it easier, to write different programs and keep them (to mess around with the VM). We will add a few more opcodes to our repertoire, because only adding numbers is just plain boring. I put some sort into what opcodes to introduce; but be advised, that none of them are final. Not only is the VM experimental and in a very early state, I introduce codes that I do not intend to keep on purpose. This is also a demonstration/introduction. So I add codes that are helpful at the time of writing, for experimenting. FIN is an example of a code, that will most likely be removed at some point. But for now it is nice to have a simple way to explicitly terminate the program. It gives some confidence, when we reach that point, that our program works as intended, and that we did not mess up the bytecode. Arithmetics \u00b6 Baby steps. No rush here. We had adding as a first example. We will introduce subtraction , multiplication , division , and modulo . Sounds like not much, but we will run in some complications, anyways... Here is our addtion to op.rs . /// opcode: Subtract top two values on stack. /// /// pop: 2, push: 1 /// oparg: 0 pub const SUB : u8 = 0x11 ; /// opcode: Multiply top two values on stack. /// /// pop: 2, push: 1 /// oparg: 0 pub const MUL : u8 = 0x12 ; /// opcode: Divide top two values on stack. /// /// pop: 2, push: 1 /// oparg: 0 pub const DIV : u8 = 0x13 ; /// opcode: Calculate modulo of top two values on stack. /// /// pop: 2, push: 1 /// oparg: 0 pub const MOD : u8 = 0x14 ; The order of things \u00b6 Simple enough those new codes, just copy and paste from ADD . But it turns out, subtraction is not as easy as addition. Here is the handling code we used for ADD : op :: ADD => { println! ( \" ADD\" ); let a = self . pop () ? ; let b = self . pop () ? ; self . push ( a + b ) }, Works. But if we copy and use that for SUB : op :: SUB => { println! ( \" SUB\" ); let a = self . pop () ? ; let b = self . pop () ? ; self . push ( a - b ) }, It turns out, that I messed up the order of the operands. That does not matter for addition, but subtraction is not commutative. So let's change that: op :: ADD => { println! ( \" ADD\" ); let b = self . pop () ? ; let a = self . pop () ? ; self . push ( a + b ) }, op :: SUB => { println! ( \" SUB\" ); let b = self . pop () ? ; let a = self . pop () ? ; self . push ( a - b ) }, op :: MUL => { println! ( \" MUL\" ); let b = self . pop () ? ; let a = self . pop () ? ; self . push ( a * b ) }, op :: DIV => { println! ( \" DIV\" ); let b = self . pop () ? ; let a = self . pop () ? ; self . push ( a / b ) }, op :: MOD => { println! ( \" MOD\" ); let b = self . pop () ? ; let a = self . pop () ? ; self . push ( a % b ) }, So, we learned something. I put the other operators there, as well. But this is too naive. You might already see the problem. Blowing up the school \u00b6 As my math teacher liked to say: \"... dann fliegt die Schule in die Luft!\" \u2013 If we do that the school building will blow up. It is his way of dealing with the issue, that pupils are told \"you must never divide by zero\", but that they are never given an understandable reason for it. So just own it, and provide a completely absurde one. What happens, is we keep it like this? Well, not much - until you write a program that divides by zero. Then, this will happen: [...] VM { stack: [4, 0], pc: 4, op_cnt: 2 } Executing op 0x13 DIV thread 'main' panicked at 'attempt to divide by zero', src/vm.rs:142:31 stack backtrace: 0: rust_begin_unwind at /rustc/fe5b13d681f25ee6474be29d748c65adcd91f69e/library/std/src/panicking.rs:584:5 1: core::panicking::panic_fmt at /rustc/fe5b13d681f25ee6474be29d748c65adcd91f69e/library/core/src/panicking.rs:143:14 2: core::panicking::panic at /rustc/fe5b13d681f25ee6474be29d748c65adcd91f69e/library/core/src/panicking.rs:48:5 3: lovem::vm::VM::execute_op at ./src/vm.rs:142:31 4: lovem::vm::VM::run at ./src/vm.rs:85:13 5: modulo::main at ./src/bin/modulo.rs:10:11 6: core::ops::function::FnOnce::call_once at /rustc/fe5b13d681f25ee6474be29d748c65adcd91f69e/library/core/src/ops/function.rs:227:5 note: Some details are omitted, run with `RUST_BACKTRACE=full` for a verbose backtrace. Process finished with exit code 101 Our program panics! I told you earlier, that this is not good behaviour. I introduced you to a lot of weird Rust stuff, just to avoid those. So, let us not re-introduce them now. So, what can we do instead? Division by zero is a runtime error, for sure (at least in this numerical domain we are working with). But it should not be a runtime error in our virtual machine, it should be a runtime error in the program it is running. Luckily, we already have that mechanism in our VM. So let us add a new runtime error: /// An error that happens during execution of a program inside the VM. # #[derive(Debug, Clone, PartialEq)] pub enum RuntimeError { EndOfProgram , UnknownOpcode ( u8 ), StackUnderflow , StackOverflow , DivisionByZero , } And adjust our opcode handlers: op :: DIV => { println! ( \" DIV\" ); let b = self . pop () ? ; let a = self . pop () ? ; if b == 0 { Err ( RuntimeError :: DivisionByZero ) } else { self . push ( a / b ) } }, op :: MOD => { println! ( \" MOD\" ); let b = self . pop () ? ; let a = self . pop () ? ; if b == 0 { Err ( RuntimeError :: DivisionByZero ) } else { self . push ( a % b ) } }, We add a check for the DIV and MOD handlers (modulo is a division as well). If we run that program dividing by zero again, we now get this: [...] VM { stack: [4, 0], pc: 4, op_cnt: 2 } Executing op 0x13 DIV Error during execution: DivisionByZero Process finished with exit code 0 Yes, it still fails. But only the execution of the bytecode fails, not the execution of our virtual machine. You can now handle the problem inside your Rust program in a way that fits your needs. Much better. In the next post, we will be using our new instructions in a fancy way, that works well with a stack machine. Homework \u00b6 Oh, not sure. Play around with it, I guess? As always. Feel free to write a calculation into a program and compare the results. It should work, unless I messed up again. You should have at least, at some point, write a program in bytecode yourself, so that you know how that feels. Reverse polish notation \u00b6 We are using the design of a stack machine to efficiently execute some calculations. kratenko \u00b7 kratenko 2022-07-21 \u00b7 Entry #18 \u00b7 4 min read \u00b7 v0.0.5-journey The way stack machines work can be used in programs that execute calculations. We will look at it by implementing an example from the Wikipedia page about stack machines. I will quote a lot of it here. You can see the full text of the article and its authors when you follow the Wikipedia permalink to the article . Design Most or all stack machine instructions assume that operands will be from the stack, and results placed in the stack. The stack easily holds more than two inputs or more than one result, so a rich set of operations can be computed. In stack machine code (sometimes called p-code), instructions will frequently have only an opcode commanding an operation, with no additional fields identifying a constant, register or memory cell, known as a zero address format. 2 This greatly simplifies instruction decoding. Branches, load immediates, and load/store instructions require an argument field, but stack machines often arrange that the frequent cases of these still fit together with the opcode into a compact group of bits. \u2014 Wikipedia - retrieved 2022-07-15 So far nothing new - I wrote about all that in my earlier posts. The selection of operands from prior results is done implicitly by ordering the instructions. [...] \u2014 ibid. Now, here it gets interesting. [...] The instruction set carries out most ALU actions with postfix ( reverse Polish notation ) operations that work only on the expression stack, not on data registers or main memory cells. This can be very convenient for executing high-level languages, because most arithmetic expressions can be easily translated into postfix notation. For example, consider the expression A*(B-C)+(D+E), written in reverse Polish notation as A B C - * D E + +. Compiling and running this on a simple imaginary stack machine would take the form: # stack contents (leftmost = top = most recent): push A # A push B # B A push C # C B A subtract # B-C A multiply # A*(B-C) push D # D A*(B-C) push E # E D A*(B-C) add # D+E A*(B-C) add # A*(B-C)+(D+E) \u2014 ibid. Well, I don't know about a \"simple imaginary stack machine\" - but as it happens to be, we have a very real simple stack machine at our disposal. You know where we will be going next! Porting the code to lovem \u00b6 The program from the Wikipedia article uses 5 variables A to E . We do not support any kind of variables, yet, but that isn't important here. We use immediates (literals from your program) to put some concrete values into the calculation. Let's just take some numbers, totally at random: A = 5, B = 7, C = 11, D = 13, E = 17 And we add a new binary to the project: reverse-polish.rs //! A small program demonstrating execution of arithmetics in our VM. //! //! For an explanation of what we are doing here, look at this wikipedia article: //! https://en.wikipedia.org/w/index.php?title=Stack_machine&oldid=1097292883#Design use lovem :: { op , VM }; // A*(B-C)+(D+E) // A B C - * D E + + // A = 5, B = 7, C = 11, D = 13, E = 17 // 5 * (7 - 11) + (13 + 17) = 10 fn main () { // Create a program in bytecode. // We just hardcode the bytes in an array here: let pgm = [ op :: PUSH_U8 , 5 , op :: PUSH_U8 , 7 , op :: PUSH_U8 , 11 , op :: SUB , op :: MUL , op :: PUSH_U8 , 13 , op :: PUSH_U8 , 17 , op :: ADD , op :: ADD , op :: POP , op :: FIN ]; // Create our VM instance. let mut vm = VM :: new ( 100 ); // Execute the program in our VM: match vm . run ( & pgm ) { Ok ( _ ) => { println! ( \"Execution successful.\" ) } Err ( e ) => { println! ( \"Error during execution: {:?}\" , e ); } } } The comments spoil the result, but we want to check it calculates correctly, so that is okay. The program is the same as before: create a VM and run some hardcoded bytecode on it. Since the VM logs excessively, we will see what happens, when we run it. So the only new thing here is the bytecode program. I'll write it down in a more readable form: push_u8 5 push_u8 7 push_u8 11 sub mul push_u8 13 push_u8 17 add add pop fin To no-ones surprise, this code is the same as in the article - only with the variables replaced by numbers, and I added a pop and a fin at the end, to keep our program clean. Execution \u00b6 VM { stack: [], pc: 0, op_cnt: 0 } Executing op 0x02 PUSH_U8 value: 5 VM { stack: [5], pc: 2, op_cnt: 1 } Executing op 0x02 PUSH_U8 value: 7 VM { stack: [5, 7], pc: 4, op_cnt: 2 } Executing op 0x02 PUSH_U8 value: 11 VM { stack: [5, 7, 11], pc: 6, op_cnt: 3 } Executing op 0x11 SUB VM { stack: [5, -4], pc: 7, op_cnt: 4 } Executing op 0x12 MUL VM { stack: [-20], pc: 8, op_cnt: 5 } Executing op 0x02 PUSH_U8 value: 13 VM { stack: [-20, 13], pc: 10, op_cnt: 6 } Executing op 0x02 PUSH_U8 value: 17 VM { stack: [-20, 13, 17], pc: 12, op_cnt: 7 } Executing op 0x10 ADD VM { stack: [-20, 30], pc: 13, op_cnt: 8 } Executing op 0x10 ADD VM { stack: [10], pc: 14, op_cnt: 9 } Executing op 0x01 POP dropping value 10 VM { stack: [], pc: 15, op_cnt: 10 } Terminated! VM { stack: [], pc: 16, op_cnt: 11 } Execution successful. The output shows you the stack after every instruction. You can compare it to the stack contents in the Wikipedia listing, and you will find them identical (the order of the stack listing is switched, and of course you have numbers instead of arithmetic expressions with variables \u2013 but if you insert our numbers on the Wikipedia listing they should match). Our PoC stack machine really can do what the imaginary one is claimed to do. That's nice. Homework \u00b6 You should really read the article on Reverse Polish Notation ( permalink to article at time of writing ) . It will give some background on why it is important, not at least historically. The Z3, for example, arguably the first computer built by mankind 3 , was using it. Go ahead and jump! \u00b6 All our programs have been linear so far. Let's build the base for jumping around. kratenko \u00b7 kratenko 2022-07-22 \u00b7 Entry #19 \u00b7 5 min read \u00b7 v0.0.6-journey In every program we have written so far, each instruction just advances the PC 4 , until we reach the end. That is very linear. We will now introduce a new opcode, that jumps to a different position in the program. A new opcode \u00b6 How do we implement that? That is actually quite easy. Do you remember what I said about the PC? It is a special register, that always points to the instruction in the bytecode, that is executed next. So all our operation needs to do is modify the PC. We will give that opcode an oparg of two bytes, so we can tell it, where to jump to. Here is our new opcode in op.rs : /// opcode: Relative jump. /// /// pop: 0, push: 0 /// oparg: 2B, i16 relative jump pub const GOTO : u8 = 0x20 ; Now we have the dreaded goto . Don't be scared - on bytecode level, that is all well. We are not designing a high level language here, there will be gotos. But how do we fetch an i16 from our bytecode? So far we can only fetch u8 . So we add some more fetching: Fetch more than a byte \u00b6 /// Reads the next byte from the bytecode, increase programm counter, and return byte. fn fetch_u8 ( & mut self , pgm : & [ u8 ]) -> Result < u8 , RuntimeError > { if let Some ( v ) = pgm . get ( self . pc ) { self . pc += 1 ; Ok ( * v ) } else { Err ( RuntimeError :: EndOfProgram ) } } /// Reads the next byte from the bytecode, increase programm counter, and return byte. fn fetch_i8 ( & mut self , pgm : & [ u8 ]) -> Result < i8 , RuntimeError > { if let Some ( v ) = pgm . get ( self . pc ) { self . pc += 1 ; Ok ( * v as i8 ) } else { Err ( RuntimeError :: EndOfProgram ) } } /// Reads the next two bytes from the bytecode, increase programm counter by two, and return as i16. fn fetch_i16 ( & mut self , pgm : & [ u8 ]) -> Result < i16 , RuntimeError > { let hi = self . fetch_i8 ( pgm ) ? as i16 ; let lo = self . fetch_u8 ( pgm ) ? as i16 ; Ok ( hi << 8 | lo ) } We already know fn fetch_u8() . fn fetch_i8() does almost the exact thing, only that it casts that byte from u8 to i8 . Simple enough. Casting in Rust has the beautiful syntax <value> as <type> . So why do we need i8 ? Because we are building an i16 from an i8 and a u8 . Just a bit of bit arithmetic. We can pass on potential EndOfProgram runtime errors easily with ? and Result . It allows us to write some short but still easy-to-read code, I think. So now we can fetch the value, we need for our jump. So let us write the handler for the opcode in fn execute_op() of vm.rs . Goto \u00b6 op :: GOTO => { println! ( \" GOTO\" ); let d = self . fetch_i16 ( pgm ) ? ; self . pc += d ; Ok (()) } So, is that all? No, because we made a Rust-beginner-mistake. If we try and compile the code, we get an error: error[E0308]: mismatched types --> src/vm.rs:174:28 | 174 | self.pc += d; | ^ expected `usize`, found `i16` Yeah - Rust does not allow us to do calculations with different types of integers. We need to explicitly cast everything. Rust tries to avoid ambiguity, so no implicit conversions. And, to be honest, the compiler has a good point. We should care even more about that calculation; we want our VM to be robust. We change the handler to: op :: GOTO => { println! ( \" GOTO\" ); let d = self . fetch_i16 ( pgm ) ? ; self . relative_jump ( pgm , d ) } Safe goto \u00b6 And we add a new method (and we add a new RuntimeError): /// Executes a checked relative jump; Runtime error, if jump leaves program. fn relative_jump ( & mut self , pgm : & [ u8 ], delta : i16 ) -> Result < (), RuntimeError > { println! ( \" Jump from {} by {}\" , self . pc , delta ); if delta < 0 { let d = - delta as usize ; if self . pc >= d { self . pc -= d ; Ok (()) } else { Err ( RuntimeError :: InvalidJump ) } } else { let d = delta as usize ; if self . pc + d < pgm . len () { self . pc += d ; Ok (()) } else { Err ( RuntimeError :: InvalidJump ) } } } Enter the loop \u00b6 Now, let us write a new program that uses the goto opcode: //! Create a VM and run a small bytecode program in it. //! //! This demonstrates the goto operation with an endless loop. use lovem :: { op , VM }; fn main () { // Create a program in bytecode. // We just hardcode the bytes in an array here: let pgm = [ op :: PUSH_U8 , 123 , op :: GOTO , 0xff , 0xfb , op :: FIN ]; // Create our VM instance. let mut vm = VM :: new ( 100 ); // Execute the program in our VM: match vm . run ( & pgm ) { Ok ( _ ) => { println! ( \"Execution successful.\" ) } Err ( e ) => { println! ( \"Error during execution: {:?}\" , e ); } } } I will write that bytecode down in a more readable format again: push_u8 123 goto -5 fin Only 3 instructions. And the fin will never be reached. That 0xff, 0xfb after the op::GOTO is the 2 byte oparg: an i16 with the value -5 . But why -5 ? When the goto executed, we have read both oparg bytes, so the PC points to the fin at index 5. So adding -5 to it will set the PC to 0 . The next executed instruction will be the push_u8 once again. This is an endless loop. So will the program run forever? What do you think will happen? Let's try: VM { stack: [], pc: 0, op_cnt: 0 } Executing op 0x02 PUSH_U8 value: 123 VM { stack: [123], pc: 2, op_cnt: 1 } Executing op 0x20 GOTO Jump from 5 by -5 VM { stack: [123], pc: 0, op_cnt: 2 } Executing op 0x02 PUSH_U8 value: 123 VM { stack: [123, 123], pc: 2, op_cnt: 3 } Executing op 0x20 GOTO [...] VM { stack: [123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123], pc: 0, op_cnt: 200 } Executing op 0x02 PUSH_U8 value: 123 Error during execution: StackOverflow Process finished with exit code 0 There is a push_u8 operation in our endless loop. So it will fill our stack until it is full! The program hits a runtime error after 200 executed instructions. Great, now we tested that, too. NOPE \u00b6 That is not very dynamic. We want to make decisions! We want to choose our path. What we want is branching . We will introduce a new opcode, that will decide, which branch the execution of our program will take, based on a value during runtime. If this sounds unfamiliar to you, let me tell you, what statement we want to introduce: it is the if statement. So, how does that work? As mentioned, normally the PC is incremented on each byte we fetch from the bytecode. And the PC always points to the next instruction, that will be executed. So if we want to change the path of execution, what we have to do is change the value of the PC. An operation, that simply changes the PC statically, would be a GOTO statement. But there is no branching involved in that, the path that will be executed is always clear. The if statement on the other hand only alters the PC, if a certain condition is met. A new opcode \u00b6 /// opcode: Branch if top value is equal to zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFEQ : u8 = 0x20 ; Our new operation pops only one value. So what does it get compared to? That's easy: zero. If you need to compare two values to each other, just subtract them instead, and then you can compare with zero. That gives the same result. And what kind of oparg does this operation take? A signed integer. That is the value that should be added to the PC, if our condition is met. This will result in a relative jump. Homework \u00b6 Same as always. Write some bytecode. Try some jumping around. Run into troubles! You can write a program, that has a fin in the middle, but executes code that lies behind that instruction. Don't byte me! \u00b6 I have had it with these motherloving bytes in this motherloving bytecode! kratenko \u00b7 kratenko 2022-07-25 \u00b7 Entry #20 \u00b7 5 min read \u00b7 v0.0.7-journey By now you should have come to a realisation: writing bytecode sucks! It wasn't fun to begin with, but now that we introduce jumps in our code, we need to count how many bytes the jump takes \u2013 and that with instructions that have different numbers of bytes as opargs. Encoding negative numbers in bytes is also no fun. And just think about it: if you change your program (e.g. add a few instructions), you have to adjust those relative jumps! How horrible is that? Can't someone else do it? Well, yeah, of course. We invented a machine that can do annoying and monotone tasks that require accuracy and that must be done over and over again. That machine is, of course, the computer. Well, lucky us, that we know how to tell a computer what it should do. So let's write a program, that writes bytecode for us. I am not talking about compiling a programming language into our VM; at least not yet, not for a long time. But something that lets us write those instructions in a way that is at least a bit more human friendly. Maybe you remember that I already tried to write some of the bytecode programs I showed you in a more readable way, like this: push_u8 5 push_u8 7 push_u8 11 sub mul push_u8 13 push_u8 17 add add pop fin If that did remind you of something, that might be no coincidence. Assembler \u00b6 The listing up there looks a bit like assembler code. And on the earlier draft of lovem I did already write a program that could translate those listings into bytecode. We will do that again, together. But this will take us some time (that is, multiple journal entries). We need to acquire some additional Rust skills for that. And there is so much to explain inside that assembler program itself. Once again, I am making this up along the way. Yes, I have a plan, but I will just start to introduce syntax for the assembler, and it might not be ideal. That means, I might change it all again later. As the VM itself, our assembler will be experimental. You are welcome to give me ideas for the syntax; we do have the comments now, unter each post, feel free to use them. There is the whole GitHub discussions page as well. And you can still find me on Twitter. Find the link at the bottom of this page. Command line tool \u00b6 The assembler will be a binary that you call with parameters. A typical command line tool, just like gcc or rustc are. So what we need to do, is to learn how one writes a command line tool in Rust. One that can read files, because I plan to write assembly programs in text files. And I have no desire to start parsing command line arguments myself. Neither do I want to write an introduction on writing command line tools in Rust. All this has been done. So I kindly direct you to an online book: Command Line Applications in Rust . That is where I got what I will be using here. They use a crate called clap , which seems to be the most used lib for building command line tools in Rust. It takes about 10 minutes to read. Finding out how to use the options of clap that I want took longer, but that will not be a thing for you, as I will just be using those options. This is the first time we are using external crates in Rust. We need to add our dependencies to Cargo.toml , before we can use them: [dependencies] clap = { version = \"3.2.12\" , features = [ \"derive\" ] } anyhow = \"1.0.58\" Introducing lovas \u00b6 Now let us start with the assembler. We create a new binary that will become our assembler: lovas.rs //! An experimental assembler for lovem use clap :: Parser ; use anyhow :: { Context , Result }; /// Struct used to declare the command line tool behaviour using clap. /// /// This defines the arguments and options the tool provides. It is also used to /// generate the instructions you get when calling it with `--help`. # #[derive(Parser, Debug)] # #[clap(name = \"lovas\" , long_about = \"An experimental assembler for lovem, the Low Overhead Virtual Embedded Machine.\" , )] struct Cli { #[clap(parse(from_os_str), help = \"Path to assembler source file.\" )] source : std :: path :: PathBuf , } fn main () -> Result < () > { // read, validate, and evaluate command line parameters: let args = Cli :: parse (); // read complete source file into String: let content = std :: fs :: read_to_string ( & args . source ) . with_context ( || format! ( \"could not read file `{}`\" , args . source . as_path (). display (). to_string ()) ) ? ; // For now, just print our all the lines in the file: for ( n , line ) in content . lines (). enumerate () { println! ( \"{:4}: '{}'\" , n + 1 , line ); } // We succeeded in our work, so return Ok() as a Result: Ok (()) } As it happens with Rust, the code is very dense. I try to explain what I do inside the code using comments. This does not look like it does too much. Yet it does. You can call it using cargo run --bin lovas , as we learned earlier: kratenko@jotun:~/git/lovem$ cargo run --bin lovas Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas` error: The following required arguments were not provided: <SOURCE> USAGE: lovas <SOURCE> For more information try --help That is already a lot! It finds out that you did not supply a required argument and tells you in a somewhat understandable error message. We did not write any of that. And it even directs you how to get help: add --help to your call. Now if we use cargo to run our binary, we need to add an extra bit to the call, because we need to tell cargo where its own arguments end, end where the arguments to the called binary begin. This is done (as it is custom) by adding -- , to indicate the end of cargo's arguments. So if we want to pass --help to lovas, we can do it like this: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- --help Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas --help` lovas An experimental assembler for lovem, the Low Overhead Virtual Embedded Machine. USAGE: lovas <SOURCE> ARGS: <SOURCE> Path to assembler source file. OPTIONS: -h, --help Print help information How helpful! Also, now you can see why I added those two strings to our Cli struct; they show up in the help message. Run it \u00b6 It looks like we need to give it a file to read, if we want the program to succeed and not exit with an error. I did write a little assembly program that we can use: hallo-stack.lass . Our assembler will not so anything too useful with it, because we did not write an assembler, yet. It will simply print out the lines of the file, prefixed with the line number (the call to .enumerate() is what I use to count the lines, while iterating over them). kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- pgm/hallo-stack.lass Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas pgm/hallo-stack.lass` 1: 'push_u8 123' 2: 'push_u8 200' 3: 'add' 4: 'pop' 5: 'fin' Neat! I feel this is a lot for such a small program! It is also enough for this journal entry. We will be working on lovas for a bit, now. Homework \u00b6 Well - if you have not done so, read the book I linked. At least up until chapter 1.4, I guess, that is what we need for now. And try to trigger some errors when calling lovas . What if the file you tell it to open does not exist? What if it cannot be read? Do you understand how those error messages propagate through the program and end up as a readable message in your console? Assemble! \u00b6 We introduce an API for assembly to our lovem library. kratenko \u00b7 kratenko 2022-07-26 \u00b7 Entry #21 \u00b7 5 min read \u00b7 v0.0.8-journey Last time, we built the frame of a command line program, that will become our new assembler, lovas . It is time that we give that program the power to assemble. Calling the real assembler \u00b6 lovas.rs is just the executable wrapper around the actual assembler, that will live inside the library. All lovas.rs does, is supply the command line interface. And that CLI-part does not belong in a library function. We got it nicely separated. And programs using the library can assemble source to bytecode themselves, without calling an external binary. We alter lovas.rs a bit. The part that just printed out the source lines is gone. We replace it with a call to a new library function, that can transfer assembly code into bytecode: fn main () -> Result < () > { .. . the same as before .. . // run the assembler: match asm :: assemble ( & name , & content ) { Ok ( pgm ) => { // we succeeded and now have a program with bytecode: println! ( \"{:?}\" , pgm ); Ok (()) }, Err ( e ) => { // Something went wrong during assembly. // Convert the error report, so that `anyhow` can do its magic // and display some helpful error message: Err ( Error :: from ( e )) }, } } The important part is the call to asm::assemble(&name, &constent) . We created a new module asm inside our lib. It exposes only a single function assemble and a few types for error handling. There will be a lot to unpack inside that module. The good news for us is: we do not need to restrain ourselves as much as we do in the VM itself. Resource usage is not really an issue here, because the assembler is not meant to run in a restricted environment. The idea of lovem is, that you write your programs elsewhere, outside the restricted environment, and only run the compiled bytecode in the VM on the restricted device. And since the scope handled by the assembler will still be defined by that restricted device, we expect to only write relatively small and simple programs. With modern computers used for assembling, we can use as much memory as we want. Oh, by the way... Yeah, I seem to stick to these short, cryptic names for the parts of lovem . VM , Pgm , op , asm - I kinda like it that way, and it goes well with the register names etc. That feels right for something as low-lever as a VM. And I give my best to always document those things properly, so that your IDE of choice will always show you, what each thing is. ASM \u00b6 I wrote a very basic assembler inside asm.rs , and it is already over 250 lines long. Quite a lot to unpack. As before, I try to explain as much as possible inside the source code itself, using comments. This makes it easier to follow, and you can even do so inside the source in the repo, without reading this blog. There are four types that I introduce inside the mod: /// Errors that can happen during assembly. # #[derive(Debug, Clone)] pub enum AsmError { InvalidLine , UnknownInstruction ( String ), UnexpectedArgument , MissingArgument , InvalidArgument , } /// Report of failed assembly attempt. /// /// Wraps the error that occurred during assembly and supplied information where it did. # #[derive(Debug)] pub struct AsmErrorReport { /// Name of the program that failed to assemble. name : String , /// Line the error occurred during assembly. line : usize , /// Error that occurred. error : AsmError , } /// A single instruction parsed from the line of an assembly program. # #[derive(Debug)] struct AsmInstruction { /// Number of line the instruction was read from. /// /// The number of the line the instruction was taken from, most likely /// from a source file. Line counting starts at 1. line_number : usize , /// Opcode defining which operation is to be executed. opcode : u8 , /// Arguments used for execution of the operation. /// /// Zero or more bytes. oparg : Vec < u8 > , /// Position inside bytecode (starting at 0). /// /// Number of bytes that come before this instruction in the program. pos : usize , } /// A assembler program during parsing/assembling. # #[derive(Debug)] struct AsmPgm { /// Name of the program (just a string supplied by caller). name : String , /// Vector of parsed assembler instructions, in the order they are in the source file. instructions : Vec < AsmInstruction > , /// Current line number during parsing. /// /// Used for error reporting. line_number : usize , /// Current position inside bytecode during parsing. /// /// Used to calculate the exact position an instruction will be in the bytecode. text_pos : usize , /// The error that happened during parsing/assembling, if any. error : Option < AsmError > , } AsmError is easy enough to understand. We used the same idea for the RuntimeError inside the VM. When we run into an Error while trying to assemble the program, we return Err<AsmError> instead of Ok(()) , so that we can propagate what happened back to the caller. The nice thing is, that with speaking names for the enum values, and with the occasional embedded value (as in UnknownInstruction(String) ), the debug representation of the AsmError alone is enough to make the user understand what error was detected. AsmErrorReport is a little wrapper we use to add the information where we ran into an error. InvalidArgument is nice hint how to fix your program - but if that program is 2000 lines long, then good luck. When you know the InvalidArgument happened in line 1337, then you will find it much faster. Especially in an assembly language, that has never more than one single instruction per line. AsmInstruction is used to represent a single instruction inside a program. So each instance of this type will be linked to a specific line in the source file. If you don't remember, what counts as an instruction in lovem (at least at the time of writing), let me repeat: an instruction consists of exactly one operation that is to be executed, which is identified by its opcode (which is a number from 0x00 to 0xff stored in a single byte). Each instruction has zero or more bytes used as an argument, defining how the operation is to be executed. This argument is called oparg . We will also store the number of the line we found our instruction inside the source code, and the position inside the bytecode where the instruction will be. AsmPgm will represent the complete program during the assembly process. We will collect the instructions we parse from the source in there in a Vector. And we will hold the progress during parsing/assembling. This is not the type that will be returned to the caller, it is only used internally (as you can guess by the fact that it is not defined pub ). Where does the program come from? \u00b6 The only function the mod exports it assemble : /// Parse assembly source code and turn it into a runnable program (or create report). pub fn assemble ( name : & str , content : & str ) -> Result < Pgm , AsmErrorReport > { let asm_pgm = AsmPgm :: parse ( name , content ); asm_pgm . to_program () } It will return an AsmErrorReport , if anything goes wrong and the assembling fails. If the assembler succeeds, it returns an instance of Pgm . Now where does that come from? Our VM takes programs in form of a &[u8] . That will be changed soon, and then it will run programs from a special type Pgm that might have a bit more than just bytecode. I added another new module to the library: pgm.rs . That one is tiny and only holds the new struct Pgm \u2013 which itself is basic. But we have a type that holds a program, now. I believe that will be beneficial to us later. /// Holds a program to be executed in VM. # #[derive(Debug)] pub struct Pgm { /// Some name identifying the program. pub name : String , /// Bytecode holding the programs instructions. pub text : Vec < u8 > , } What is it, that the assembler does, to create such a Pgm . We will start to go through that in the next entry. This has been enough for today. Parsing the source \u00b6 kratenko \u00b7 kratenko 2022-07-27 \u00b7 Entry #22 \u00b7 4 min read \u00b7 v0.0.8-journey So far we have read an assembly source file into a string, and we got to know some new data structures. It is time we use the one to fill the other. Let us start parsing. What we know so far is this: /// Parse assembly source code and turn it into a runnable program (or create report). pub fn assemble ( name : & str , content : & str ) -> Result < Pgm , AsmErrorReport > { let asm_pgm = AsmPgm :: parse ( name , content ); asm_pgm . to_program () } Assembler syntax \u00b6 Our experimental assembler will begin using a simple syntax. Only one instruction per line, short opnames to identify the operation to be executed, optionally a single argument. I have written a short program: hallo-stack.lass . push_u8 123 push_u8 200 add pop fin Straightforward. And you know the syntax already from my human friendly listings of bytecode. Parsing that looks simple. We do want to allow adding whitespaces, though. And we want to allow comments, for sure. Our assembler needs to handle a bit of noise, as in noice.lass . ## This is an awesome program! push_u8 123 push_u8 200 # What are we using the # 200 for? add pop ## let's end it here! fin Those two programs should be identical and produce the same bytecode. One line at a time \u00b6 The parse() function we call creates an empty instance of AsmPgm and then processes the source file line after line, filling the AsmPgm on the way. /// Parse an assembly program from source into `AsmPgm` struct. fn parse ( name : & str , content : & str ) -> AsmPgm { // create a new, clean instance to fill during parsing: let mut p = AsmPgm { name : String :: from ( name ), instructions : vec ! [], line_number : 0 , text_pos : 0 , error : None , }; // read the source, one line at a time, adding instructions: for ( n , line ) in content . lines (). enumerate () { p . line_number = n + 1 ; let line = AsmPgm :: clean_line ( line ); if let Err ( e ) = p . parse_line ( line ) { // Store error in program and abort parsing: p . error = Some ( e ); break ; } } p } content.lines() gives us an iterator that we can use to handle each line of the String content in a for loop. We extend the iterator by calling enumerate() on it; that gives us a different iterator, which counts the values returned by the first iterator, and adds the number to it. So n will hold the line number and line will hold the line's content. We always keep track of where we are in the source. Because the enumerate() starts counting at 0 (as things should be), we need to add 1 . File lines start counting at 1 . The first thing we do with the line is cleaning it. Then it gets processed by parse_line(line) . If this produces an error, we will store that error and abort parsing. All our errors are fatal. The final line p returns the AsmPgm . We do not use a Result this time, but the AsmPgm can contain an error. Only if its error field is None , the parsing was successful. Cleaning the noise \u00b6 /// Removes all noise from an assembler program's line. fn clean_line ( line : & str ) -> String { // Remove comments: let line = if let Some ( pair ) = line . split_once ( \"#\" ) { pair . 0 } else { & line }; // Trim start and end: let line = line . trim (); // Reduce all whitespaces to a single space (0x20): ANY_WHITESPACES . replace_all ( line , \" \" ). to_string () } We use multiple techniques to clean our input: splitting, trimming, regular expressions. When we are done, we only have lines as they look in hallo-stack.lass . The cleaned line can also be completely empty. I want to add a word about that regexp in ANY_WHITESPACES . Where does it come from? I am using some more Rust magic there, and the crate lazy_static : use lazy_static :: lazy_static ; use regex :: Regex ; // Regular expressions used by the assembler. // lazy static takes care that they are compiled only once and then reused. lazy_static ! { static ref ANY_WHITESPACES : Regex = regex :: Regex :: new ( r\"\\s+\" ). unwrap (); static ref OP_LINE_RE : Regex = regex :: Regex :: new ( r\"^(\\S+)(?: (.+))?$\" ). unwrap (); } I do not pretend to understand the macro magic that happens here. But what happens, is that the regular expressions are compiled only once and then kept as some sort of global static immutable variable, that we can than use again and again all over the program as a reference. Static references are a convenient thing in Rust, if you remember what I told you about ownership. You can always have as many references to immutable static variables, because there is nothing that can happen to them, and they exist throughout the complete runtime of the program. Parsing a clean line \u00b6 /// Handles a single cleaned line from an Assembly program. fn parse_line ( & mut self , line : String ) -> Result < (), AsmError > { if line == \"\" { // empty line (or comment only) - skip return Ok (()); } if let Some ( caps ) = OP_LINE_RE . captures ( & line ) { let opname = caps . get ( 1 ). unwrap (). as_str (); let parm = caps . get ( 2 ). map ( | m | m . as_str ()); return self . parse_instruction ( opname , parm ); } Err ( AsmError :: InvalidLine ) } parse_line() processes each line. Empty ones are just skipped. We use another regular expression, to find out if they match our schema. Because we cleaned it the expression can be rather simple: r\"^(\\S+)(?: (.+))?$\" . We look for one or more non-empty chars for our opname . It can be followed by a single argument, which must consist of one or more chars, separated by a single space. That is our optional oparg . If the line fits, we found an introduction we can try to parse. That is the job of parse_instruction() . Everything that is neither empty nor an instruction, is an error, that we can simply return. It will abort the parsing and the caller will know, that there was an invalid line. parse_instruction() can also run into an error. We use our tried pattern of returning a Result where the successful outcome does not carry any additional information (which is why we return Ok(()) ). The error case will return an AsmError, that carries the reason for the error. And because of our the Result type and because of Rust's might enum system, we can simply return what parse_instruction() returns to us. Handling the instruction itself will be handled in the next entry. Don't let yourself be confused by fancy terms like register . You can think of it as a kind of snobbish variable with a special meaning. In computers sometimes stuff magically happens when you write to a register \u2013 but it should always be documented somewhere. \u21a9 Beard, Bob (Autumn 1997). \"The KDF9 Computer - 30 Years On\" . Computer RESURRECTION. \u21a9 Yeah, I know. The answer to the question \"What was the first machine to qualify as a computer?\", differs, depending on whom you ask \u2013 and also on the country you ask the question in. But the Z3 is a prominent candidate. \u21a9 PC: the Program Counter, a special register that points to the next instruction to be executed. \u21a9","title":"July 2022 complete"},{"location":"2022-07/ALL.html#complete-month-of-july-2022","text":"","title":"Complete month of July 2022"},{"location":"2022-07/ALL.html#state-of-the-journal","text":"Since I am always focused on my work on lovem, I will never get sidetracked. Unrelated: I spent a few days on reworking the journal on this site. kratenko \u00b7 kratenko 2022-07-01 \u00b7 Entry #5 \u00b7 3 min read So, no update on the core project today, sorry. I was very unhappy with my first solution, on how the Journal entries where created. Way too much to do by hand \u2013 that is not what I learned programming for. But mkdocs is python, and python I can do. So did. And now I can write my Journal entries (like this one) as plain Markdown files with very few metadata entries. And I get entries in the navigation and pages listing the whole month. I even included a whole month in single page version of the journal. I feel it is quite fancy. I will need to do a bit of work on the static content of the site, but one step at a time.","title":"State of the Journal"},{"location":"2022-07/ALL.html#what-i-want","text":"I want to write my Journal entries (aka blog posts) as a nice standalone markdown file, one file per entry. I will need to add include a bit of metadata, at least the release date/time. And I want the entries to look fancy without adding the fanciness to each file. Maybe I will be changing the layout later, hmm? And create those teaser pages for me, thank you very much. And I have all that, now! Just look at the source that is used to generate this entry .","title":"What I want"},{"location":"2022-07/ALL.html#how-it-works","text":"I use a plugin called mkdocs-gen-files , by @oprypin , that creates additional mkdocs source files on the fly. It does not really put the files on disk, but they are parsed by mkdocs, as if they were in the docs directory. I have a directory journal next to my docs directory, where I put all my posts in a single markdown file each. My script walks through that directory, and processes each file. The content is modified a bit (to put in the card with the author's name and other metadata), and then put in a virtual file inside docs , so that the pages with the entries are created by mkdocs, as if I hat them inside docs . The script also generates two pages for each month: one that shows that month's posts as teasers, with a \"continue reading\" link, and a second one that shows all posts from a month on a single page, so that you can read them without changing pages all the time. The remaining part is adding all the pages, that the script creates, to the navigation in a way that makes sense. The order is a critical part, being a central aspect of a journal or a log. For that I use another plugin by @oprypin : mkdocs-literate-nav . With it, you can control your navigation (completely or in parts) by adding markdown source files with lists of links. This goes together well with the gen-files plugin, because I can just create that navigation files with it in my script. The plugins are a bit light on the documentation side. It took me a while to understand, that you cannot do multiple layers of nested navigation in those files. That is not a problem, because you can always just add another nesting layer by adding more of those nav files as children. Also, what you can do in those files is very limited. I wanted to do some fancy things in the navigation (adding a second link in a single line with alternative representation). I would guess that those limitations come from the ways mkdocs itself handles the navigation, so that is okay. But a word on that would have been nice. And the error messages popping up did not help at all, because the actual error happens way later in the process inside mkdocs itself and is some weird side effect problem.","title":"How it works"},{"location":"2022-07/ALL.html#the-script","text":"If you want to take a look, see blogem.py . That will be the script in its current state. For the version of the script at the time of writing, see the permalink, the original blogem.py .","title":"The script"},{"location":"2022-07/ALL.html#todos","text":"Automated reload in mkdocs serve when I edit entry sources. just add parameter -w journal to mkdocs serve Exclude journal overview and full month pages from search. Exclude NAV.md from generating NAV.html . Maybe add tags and/or categories for posts? Maybe enable comments, as in material's blog. Add links to source in github repo. Add links to entry's history in github repo. Support multiple posts per day (by adding time to \"released\").","title":"TODOs"},{"location":"2022-07/ALL.html#all-new-once-more","text":"Reality strikes again, and code will be written from scratch once more. And the reason is this site. kratenko \u00b7 kratenko 2022-07-03 \u00b7 Entry #6 \u00b7 < 1 min read You want me to get to the code. And I really should. I have written so much already, and I want to show it, but there is so much around it. And after I had written up a long text on how I started, I realised that I had no commits during the early state. So I had to write it all again, slower, and with code to be presentable in this journal. If you are reading this live (and no-one is, because I did not even tell anyone I am doing this), you can of course look at the code I was writing earlier, it exists. I put it in a branch too-early . But I will not give explanations to that. I am rewriting it on the master branch, and that will be showed and discussed in the journal. I advise you to wait for that. Yes, it will take a while. As it looks now, it will be slow. But I have written some new posts on the new code already, and I think it is worth it. There will be more background before we get there. Next entry will be a longer one, so there is that.","title":"All new once more"},{"location":"2022-07/ALL.html#what-is-a-virtual-machine-anyway","text":"kratenko \u00b7 kratenko 2022-07-04 \u00b7 Entry #7 \u00b7 5 min read So, how do you build a Virtual Machine. There are actually two quite different approaches: Register Machine vs. Stack Machine Let's take a look at those concepts first. This will be very brief and basic. You can, of course, also have some combination of those concepts, and not everything I say here is true for every implementation of virtual machine, but it will be close enough for this article.","title":"What is a Virtual Machine anyway?"},{"location":"2022-07/ALL.html#register-machines","text":"Most physical computers are register machines. At least those you will be thinking of. You are most likely using one right now to read this article. Virtual register machines use the same concepts, but not in physical hardware, instead inside another computer as software. This allows them to do some things a bit more flexible than a real hardware machine would. A register is nothing more than a dedicated place to store a portion of data where it can be accessed for direct manipulation. They are more or less a variable of the machine's basic data type that have a fixed address, and that can be accessed and manipulated directly by the processing unit. Register machines use those to actually compute and change data. All other storage places are only that: places where data is put when it is not needed at the moment. Register machines have a multitude of registers, from a very few (maybe 4 or 8 in simplistic designs) to hundreds or more in modern computers. The size of the registers often gives the architecture its name. E.g. in the x86-x64 architecture, that most current CPUs by Intel and AMD are of, a register is 64 bits long. The instructions for a register machine are encoded in code words . A code word is a bunch of bytes that tell the machine what to do in the next program step. For simple designs, code words are of a fixed length. This code word length is often longer than the register size. So a 16 bit architecture could have 32 bit instructions. The reason for this is, that instructions consist of an operation code that defines what operation should be executed in the next step, but they also contain the arguments passed to that operation. Because the number and size of arguments needed for an operation differ for different operations, decoding the instruction can be quite complicated. When you put multiple instructions together, you end up with a program. This representation of a computer program is called machine code . For a virtual machine it is also called bytecode , although I think this term fits better for stack machines (more on that later). If you want to understand what I tried to describe here, read this really short article: Creating a Virtual Machine/Register VM in C . It builds a simplistic register VM in C (the whole thing is 87 lines long). It demonstrates the principles used in a register machine (fetch, decode, execute), and shows you what a register is and how it is used. You will understand, how machine code is decoded and executed. The article only uses 16 bit code words and 16 bit data words (register size). If you know C, you should be able to understand what I am talking about in about an hour of reading and coding. If you ever wanted to understand how a computer works on the inside, this might be a nice place to start, before you read about an actual physical computer. A register machine normally has multiple stacks it uses. This does not make it a stack machine, those are just needed to store data when it is not currently used. So a typical operations would be: * \"Take the number from register 0, take the number from register 1, add those two numbers together, write the result in register 0.\" * \"Take the lower 16 bits of this instruction and write them in register 2.\" Lua and Neko are virtual register machines (at least in current versions).","title":"Register Machines"},{"location":"2022-07/ALL.html#stack-machines","text":"And then there are Stack Machines . They are, I think, easier to understand than register machines, but following a program during execution is more confusing, since the manipulated data is more complicated to follow. A stack is just a pile of data. Data is portioned in fixed sizes, a portion is called a word. All you can normally do is put a word on top of the stack - we will call that operation a push , or you can take the word that is currently on top of the stack (if there is one) - we will call that a pop . No other direct manipulations of the stack are allowed (I say \"direct manipulations\", because indirectly there often are ways that this is done, but that is a detail for later). Manipulation of data is done this way by the machine. If you want to add two numbers, say 5 and 23, you would write a program that does this: Push the first number to the stack. Push the second number to the stack. Execute the \"ADD\" operation. That operation will pop the two numbers from the stack, add them, and push their sum back on the stack (so that after the operation there will be one word less on the stack). A stack machine will also typically have some additional place to store words when you do not need them on the stack. These places can relate to variables inside a program. As you can see from the example above, instructions in a stack machine often do not need to have arguments. If data is to be manipulated, it is always on top of the stack. There is no need to address its location, as you would do in a register machine. Because of this, the instructions for a stack machine are typically encoded in a single byte. This byte holds a number we will call opcode (short for operation code), that simply identifies the operation to execute. If your operation does need additional arguments, you write them to the bytes following your opcode byte (the oparg ), so that the operation can read them from your program. This structure of single bytes encoding our program is why we call this representation bytecode . The concept of a stack machine is easy to implement in software, but it is not so easy to do so in hardware. That is why your typical computer is a register machine. There are, however, a lot of historical examples of important physical stack machines. The most famous example of a virtual stack machine is the Java VM . Java source code is compiled to bytecode that is executed inside a virtual machine, the JVM. This vm is so common, that many newer programming languages compile to Java bytecode. It makes it possible to run programs written in that languages on any system that has a JVM; and that includes just about every major and many minor computer systems. A second example for a stack machine is the Python VM.","title":"Stack Machines"},{"location":"2022-07/ALL.html#some-random-thought-on-register-and-stack-machines","text":"While writing this down, describing the two kinds of machines I couldn't help but notice a curious fact: A register machine manipulates data inside addressable registers. When the data is not need, it can be stored away in some kind of stack. A stack machine manipulates data inside a stack. When the data is not needed, it can be stored away in some kind of addressable spaces, not unlike registers. It looks as if you just need both concepts to work efficiently.","title":"Some random thought on register and stack machines"},{"location":"2022-07/ALL.html#making-virtual-a-reality","text":"So I have been talking a lot about VMs without doing anything concrete. Well that is not true, I have done quite a bit already, but I am still describing earlier steps. We will get there. kratenko \u00b7 kratenko 2022-07-06 \u00b7 Entry #8 \u00b7 3 min read","title":"Making virtual a reality"},{"location":"2022-07/ALL.html#registers","text":"When I was looking around for a scripting language to use inside our embedded devices, I came across an article I mentioned in an earlier post: Creating a Virtual Machine/Register VM in C . Reading it made me want to try working with a register machine, mainly because I have not been stuff like this since my early semesters. Never hurts to refresh rusty knowledge. So I started designing a register VM, starting from that code, but more complex, with longer data words and longer instruction words, more registers, and so forth. For this project I came up with lovem as a working title. It still stuck to now, two approaches and a year later. I also started implementing some concepts I still want to add to lovem in my current approach, but that is for a later post to discuss. I was experimenting with a quite complicated instruction word encoding. I was trying to fit everything in a few bits (32 of them if I recall correctly) with varying instruction code length and quite long arguments. I wanted to include instructions on three registers, which takes up quite some bits to address. Of course, you can get away with two-register operations only - or if you are fancy you can even use a single address or even no address for most instructions. You will just end up with a lot of register swapping. I guess my rational for having three addresses in an instruction was code size. For what I want to do, 32 bit instruction words feel quite long (4 bytes per instruction!). And every swap would mean another 4 bytes of program size. So trying to optimise for fewer operations by having more flexible instructions. I do not even know if that rational makes sense. I guess I would have needed to try different layouts to find out. Or maybe read more about that topic, other people have done similar things I assume. But I never got that far. The experiment showed me, that I do not want to build lovem as a register machine. I think building a clever register based architecture for my goals would make it too complicated. I want simple. To reduce the VM's overhead, but also on principle. Complexity is the enemy. I'm pretty sure, that code still exists somewhere, but there is no sense in publishing it or even in me reading it again, so you will never see it. I think of it as a pre-study with a very useful conclusion: not a register machine.","title":"Registers?"},{"location":"2022-07/ALL.html#stacks","text":"So a stack machine it is! I have looked at a few during my research for lovem, looking at instruction sets and design ideas. It is not the first time, I have been working with those. In a different project (around the same time I started work on the register based machine), I was starting to implement a stack machine. That one had a different aim and therefore very different challenges. It was more of an object-oriented approach with dynamic program loading and calling code in different programs. It could do quite a few things already, but it will never be continued. I learned a bit about calling conventions and found out that it is not so simple, when you want to switch between multiple programs and objects. That is where the project got too frustrating for me (and some external events made it obsolete, so that is okay). But I take it for a pre-study on stack machines and calling conventions. Not that I have developed a proven concept for it, but I know about the problems there... I had a PoC for lovem as a stack machine back then, too (right after I ditched the register approach). That code won't be published either, but the attempt showed me, that I want to take that road for a serious approach on creating lovem.","title":"Stacks!"},{"location":"2022-07/ALL.html#onwards","text":"I guess this concludes the prehistory of the lovem story. I am, for whatever reason, back on the project, currently with a decent amount of motivation. You never know how long that lasts, but right now I like the idea of continuing the development, while talking about the development process, sharing my thoughts on decisions I make. Next post should start on sharing newer thoughts.","title":"Onwards"},{"location":"2022-07/ALL.html#let-there-be-source-code","text":"Finally, I will be showing some source code. Not directly in the journal, but I will link you to GitHub, for a start. kratenko \u00b7 kratenko 2022-07-08 \u00b7 Entry #9 \u00b7 2 min read I have written code. And this time, I (re-)started lovem in a public git repository, so you can see what I do, if you are interested. And I hope it puts enough pressure on me, to keep on the project for a while. In fact, there is quite a bit of code there already. I started coding, before writing any of this, and it went so well. I like how it feels. I was working any hour I could spare. When a friend asked me what I was doing, I started a somewhat complex backstory why I was doing it, instead of actually explaining anything of the stuff I was doing \u2013 and was interrupted quite early, so there was more to tell in me still. The next day, I sat down and started to write all of that down as a little story. I wanted to put it somewhere, so I started this journal to publish it. And I decided to do it in blog form, so I am publishing that background story bit by bit. So, as of writing this, there is a lot of work completed on the VM. Tt is amazing what things it can do for how little code there is. When this post goes public, there should be quite lot more done...","title":"Let there be source code"},{"location":"2022-07/ALL.html#but-where-is-the-code","text":"Well, if you read this journal, you will know where it lives. Anyway, this is the repo: https://github.com/kratenko/lovem I plan to continue sharing my thoughts while I work on the VM. So you will be able to follow my failures and see the attempts that I will be ditching later. I think the format of this journal can work out, but we will see how I like it over time. It will be behind on progress, as I want to take time to share things as they unfold. And this should help to produce a somewhat continuous publication stream. Git being what git is, should support me in showing you the things I do back in time, using the power of commits. As things are with blogs, my entries will be very different, depending on what I want to tell and on what I did. So far most blogs where conceptional thinking, some research, and a lot of blabla, which I tell because it interests me myself. In the future, there should be concrete problems I find and solve in source code - or which I fail to solve.","title":"But where is the code?"},{"location":"2022-07/ALL.html#back-in-time","text":"Me original first commit was way too late and contained way too much code. Also, I did not plan to show it to you like this, back then. So, as mentioned before, I rolled back and started again, with more commits. And I am keeping tags now, so that I have well-defined versions for my blog posts. That should make it easy for you to follow up, if you want to. The new, artificial \"first commit\" is now a tag/release: v0.0.1-journey . You can view the code for any tag online, this one you will find under: https://github.com/kratenko/lovem/tree/v0.0.1-journey I think this will be a theme of this journal: linking you to what I did, when I am writing about it. And I will try to share my trails of thoughts, leading to my decisions (and errors, as it will be). I will do that, for that v0.0.1-journey, soon, don't worry, I will explain everything I did. But the next journal entry will be about some decisions again; mainly about the language I am using.","title":"Back in time"},{"location":"2022-07/ALL.html#it-looks-so-weird","text":"Now, that you have seen some code, I might have to explain a bit again. Depends, on where you are coming from, I guess. kratenko \u00b7 kratenko 2022-07-10 \u00b7 Entry #10 \u00b7 4 min read So, did you take a look at the code, yet? In case you've forgotten, this is my \"initial commit\": https://github.com/kratenko/lovem/tree/v0.0.1-journey It is not the original initial commit, as I did commit way too late, and it was not suitable for writing a story about it. So I created a new, clean version, with just very simple concepts that I can explain in a single entry. In the next entry, that is. If you are thinking: \"What is that weird source code?\", then you are in for a real treat (and a lot of pain), should you chose to follow up. The code you are seeing is written in Rust .","title":"It looks so weird"},{"location":"2022-07/ALL.html#once-again-but-why","text":"Why Rust? Because Rust! Writing Rust can feel so good! And for something like a VM, it is such a good choice. If you have never heard of the language (or heard of it, but never looked into it), it is hard to understand why this is so. My advice: try it! use it! Or read along this journal, code along, you might like it. When you start, chances are high that you will not like Rust. The compiler is a pedantic pain in the ass. But at the same time it is incredibly polite, trying to help you find out, what you did wrong, and suggesting what you might want to do instead. And Rust really, really tries, to keep you from shooting yourself in the foot. It tries to make common mistakes impossible or at least hard to do \u2013 those mistakes that happen everywhere in C/C++ programs and their like. Yes, those mistakes that are the cause of the majority of all security problems and crashes. Buffer overruns, use after free, double free, memory leak \u2013 to name just some common ones from the top of my head. And Rust makes all it can to make those mistakes impossible during compilation! So it does not even add runtime overhead. That is so powerful! And it is so painful. Half of the things you do, when writing C/C++, you will not be able to do in Rust in the same way. Every piece of memory is owned. You can borrow it and return it, but it cannot be owned in two places at once. And if any part of the program has writing access to it, no other part may have any access. This makes some data structures complicated or impossible (there are ways around it), and you will have to think quite differently. But if you give in on that way of thinking, you can gain so much. Even peace of the mind, as the coding world will look a lot saner inside Rust source code. This will, of course, come with the price, that all code in other languages will start to feel dirty to you, but that is the way. Also, there are a lot of ways to write code, that you cannot add to a language that already exists. C and C++ will never be freed of their heritage; they will stay what they are, with all their pros and cons. Things are solved differently in Rust. Did I mention there is no NULL ? And I have never missed it for a moment. Rust solves the problems other languages solve with NULL by using enums. That comes with certainty and safety all the way. There are no exceptions either. That problem is also solved by using enums. The way the language embraces those, they are a really powerful feature! And there are lot more convenient ways of organising code, that I keep missing in my daily C/C++ life. I will not write an introduction into Rust here. At least not your typical \"how to get started in rust\" intro. There are a lot of those out there, and I am already 10 posts into my Journal without programming. Maybe the Journal will become a different kind of Rust introduction, as it will try to take you along a real project, as it develops, from the beginning on. I will run into problems along the way and try to solve them in Rusty ways. This might be a good way, to start thinking in Rust. But, to be honest, I did never finish a project in Rust, yet. I got quite a bit running and functional, and I think in some parts in a rust-like way. But this is for me as much as anyone else as a learning project. I will make weird things. But the basics, I have worked with, yeah. The initial learning curve will be steep! I try to not get too fancy in the first draft, so the code will not be good Rust there! So, if you are shocked at how bad my Rust is \u2013 it will be very different, soon. But I want to give everyone a fair chance to hop on without understanding all the concepts. The initial code should be not too hard to follow, if you know C/C++, I hope. Learning a new thing (writing a VM) in a new, quite different language is a mouth full, I know.","title":"Once again: but why?"},{"location":"2022-07/ALL.html#didnt-you-say-you-use-cc","text":"Yes I did say that. And I do use those. It is not easy to change that, when you have a certain amount of legacy code (and not much experience with the new language, as we do not really have, yet). But we do have a saying these days. Often, after a debugging session that lasted for hours, when we find the bug, understand it and fix it, there is this realisation, that fits in the sentence: \"Mit Rust w\u00e4r' das nicht passiert.\" \u2014 \"This would not have happened with Rust.\" So, this will not happen to me with this project, because those things will not happen with Rust!","title":"Didn't you say, you use C/C++?"},{"location":"2022-07/ALL.html#a-vm","text":"The first draft of source code, that will be our VM, explained. kratenko \u00b7 kratenko 2022-07-11 \u00b7 Entry #11 \u00b7 8 min read I dumped some source code in front of you, and then I started to talk about programming languages. Time now, to explain what I did and why. We only have 132 lines, including comments. We will go through all parts of it. And I will talk a little about how Rust's basic syntax works, while I use it. Not too much, since it is not good Rust code, yet, but to help you start. This will be a longer entry.","title":"A VM"},{"location":"2022-07/ALL.html#i-swear-if-i-do-not-see-some-code-in-this-post","text":"Alright, alright... We will start with our VM: # #[derive(Debug)] pub struct VM { stack : Vec < i64 > , pc : usize , op_cnt : usize , } Nothing fancy, just a struct that will represent our Virtual Machine. Only three fields for now: stack : Obviously our stack machine would need one of those. This will hold values during execution. I am using a Vector. That is nothing more than a chunk of memory, that knows how much capacity it has and how many values are in it at the moment. It does support resizing, but I do not want to use that. pc will be our program counter . That is a register 1 holding the progress in the program during execution. It will always point at the instruction that is to be executed next. op_cnt will be counting the number of operations executed. For now, I want that information out of curiosity, but later it will be useful for limiting execution time for programs. usize and i64 are Rust's names for integer types. The language is very explicit in those terms (and very strict, as in every aspect). I will not give a real introduction to Rust for you (there are pages that do that), but I will try to start slowly and give you hints on the important things I introduce, so that you get the chance to learn about them parallel to this journal. I hope, that makes it easier to follow for Rust beginners. To readers that know Rust: please excuse the crude code here! I will make it more rusty, soon. Skip to the next post, if you cannot handle it. We will also need a program that we will run in our VM. For the start, a crude array of bytes will do. The VM will be running bytecode after all. And that really is only that: a bunch of bytes, that you will soon be able to understand. // assign `pgm` to hold a program: let pgm = [ 0x00 as u8 , 0x01 , 100 , 0xff ]; We will use a program that is a bit longer, but right now I wanted you to see a program, that is actually nothing but a collection of bytes in Rust code. let declares and assigns a variable here, named pgm . It is an array of 4 bytes ( u8 is an unsigned 8bit integer - you might know it as uint8_t from other languages). And that variable will not be variable at all. By default, all variables in Rust are immutable. If you want to change it, later, you would have to declare it using the modifier mut . There is no need to modify the program after creation, we just want to read it for execution. But our VM will have to be mutable, as it has changing internal state. Here is our complete main function, creating the (immutable) program and the (mutable) VM, and running the program. Of course, the run(...) method is still missing. And you will see the program, we will be using (with some constants that I did not define, yet). fn main () { // Create a program in bytecode. // We just hardcode the bytes in an array here: let pgm = [ op :: NOP , op :: PUSH_U8 , 100 , op :: PUSH_U8 , 77 , op :: ADD , op :: POP , 0xff ]; // Crate our VM instance. let mut vm = VM { stack : Vec :: with_capacity ( 100 ), pc : 0 , op_cnt : 0 }; // Execute the program in our VM: vm . run ( & pgm ); }","title":"I swear, if I do not see some code in this post..."},{"location":"2022-07/ALL.html#behaviour-for-our-vm","text":"So far we only have an initialized data structure and some bytes. Let's do something with it. Rust does not really use objects (and I think that is good). But it has associated functions that work on types, and methods that work on instances of types. We will write some methods for our VM struct. Let's start with the one for reading our program: impl VM { /// Fetch the next byte from the bytecode, increase program counter, and return value. fn fetch_u8 ( & mut self , pgm : & [ u8 ]) -> u8 { if self . pc >= pgm . len () { panic! ( \"End of program exceeded\" ); } let v = pgm [ self . pc ]; self . pc += 1 ; v } } The fetch method will work on our VM instance. The first parameter is &mut self \u2013 that tells us it works on an instance of the type VM . It will work on a reference to the instance (indicated by the & ), and it can modify the data (indicated by the mut ). It will also take the reference to an array of u8 s, but that it will not be able to modify (no mut ). It returns a u8 . What it does is simply read and return a byte from the program, and increase the VMs internal program counter by one, so that the next call to fetch will return the next byte. Simple. So, what is that panic!() you might ask? Well, if we reach that instruction, it will start to panic, and then it will die. That is not a nice way to act. Do not worry, we will change that to something more reasonable, when we start writing better Rust. And what about the naked v in the last line? It will have the function return the value of v . Now, let's look at that run method, we were calling in main : impl VM { /// Executes a program (encoded in bytecode). pub fn run ( & mut self , pgm : & [ u8 ]) { // initialise the VM to be in a clean start state: self . stack . clear (); self . pc = 0 ; self . op_cnt = 0 ; // Loop going through the whole program, one instruction at a time. loop { // Log the vm's complete state, so we can follow what happens in console: println! ( \"{:?}\" , self ); // Fetch next opcode from program (increases program counter): let opcode = self . fetch_u8 ( pgm ); // We count the number of instructions we execute: self . op_cnt += 1 ; // If we are done, break loop and stop execution: if opcode == op :: FIN { break ; } // Execute the current instruction (with the opcode we loaded already): self . execute_op ( pgm , opcode ); } // Execution terminated. Output the final state of the VM: println! ( \"Terminated!\" ); println! ( \"{:?}\" , self ); } } The comments should explain, what is going on there. Initialise VM, then loop over the program, fetching one instruction at a time and executing it, until we reach the end. And you might have noticed, that our program will be very talkative. I added a lot of println s, that tell just about everything that happens, during execution. I guess it is time to look at those op:: constants I keep using. /// Module holding the constants defining the opcodes for the VM. pub mod op { /// opcode: Do nothing. No oparg. /// /// pop: 0, push: 0 /// oparg: 0 pub const NOP : u8 = 0x00 ; /// opcode: Pop value from stack and discard it. /// /// pop: 1, push: 0 /// oparg: 0 pub const POP : u8 = 0x01 ; /// opcode: Push immediate value to stack. /// /// pop: 0, push: 1 /// oparg: 1B, u8 value to push pub const PUSH_U8 : u8 = 0x02 ; /// opcode: Add top two values on stack. /// /// pop: 2, push: 1 /// oparg: 0 pub const ADD : u8 = 0x10 ; /// opcode: Terminate program. /// /// pop: 0, push: 0 /// oparg: 0 pub const FIN : u8 = 0xff ; } Just 5 u8 constants there, grouped in a module as a namespace. And a lot of comments to explain them. We have 5 different operations for our VM. The only thing missing is some code, that actually executes those instructions: impl VM { /// Executes an instruction, using the opcode passed. /// /// This might load more data from the program (opargs) and /// manipulate the stack (push, pop). fn execute_op ( & mut self , pgm : & [ u8 ], opcode : u8 ) { println! ( \"Executing op 0x{:02x}\" , opcode ); match opcode { op :: NOP => { println! ( \" NOP\" ); // do nothing }, op :: POP => { println! ( \" POP\" ); let v = self . stack . pop (). unwrap (); println! ( \" dropping value {}\" , v ); }, op :: PUSH_U8 => { println! ( \" PUSH_U8\" ); let v = self . fetch_u8 ( pgm ); println! ( \" value: {}\" , v ); self . stack . push ( v as i64 ); }, op :: ADD => { println! ( \" ADD\" ); let a = self . stack . pop (). unwrap (); let b = self . stack . pop (). unwrap (); self . stack . push ( a + b ); }, _ => { panic! ( \"unknown opcode!\" ); } } } } You can think of the match as a switch statement. It is much more than that, but here we use it as one. Each of our opcodes is handled individually. And we log a lot, so that we can read what is happening, when we run it. Ignore the unwrap() thingies for the time being. They are just there to try and ignore potential runtime errors. Again, not good Rust style, but, you know: later. The four operations get more complex in what they do. Let's go through them one by one: NOP \u2013 this does nothing, it just wastes bytecode and execution time. I have included it simply to be the most basic operation possible. POP \u2013 this is our first modification of the stack. It simply discards the topmost value, decreasing the stack's size by one. PUSH_U8 \u2013 this is the only operation that reads additional data from the program. It only reads a single byte (increasing the program counter by one), and puts it on top of the stack, increasing the stack's size by one. This is how you can get data from your program into the VM, to work with them. It is how numeric literals in your program are handled. ADD \u2013 the only operation that works on data. It pops its two operands from the stack, adds them, and pushes the sum back on the stack. This is how data is manipulated in a stack machine. The operation reduces the stack's size by one effectively, but there need to be at least 2 values on it for it to be executed. That is the out complete VM so far, and it will execute a program, if you compile and run it (which we will do in the next post). You can find the complete program here: https://github.com/kratenko/lovem/blob/v0.0.1-journey/src/main.rs You can access the repo at this state under (there is also a zip file containing all files): https://github.com/kratenko/lovem/releases/tag/v0.0.1-journey","title":"Behaviour for our VM"},{"location":"2022-07/ALL.html#how-do-i-work-with-the-code","text":"The easy way, to get the code and play with it, would be to clone the git repository and check out the tag v0.0.1-journey . If you did not understand any of that, you might want to do a tutorial on git, before you continue reading. Anyways, here is some copy&paste commands, you can hack into your bash prompt, to do, what I just told you to do. Use at your own risk, I'm not responsible for what you do to your system. you@host:~$ git clone https://github.com/kratenko/lovem.git you@host:~$ cd lovem you@host:~/lovem$ git checkout v0.0.1-journey you@host:~/lovam$ cargo run lovem This will copy all source code from GitHub and its history to your computer, and it will roll the source code to the state we are looking at in this entry. The last command cargo run lovem will compile and execute the program - that is, if Rust is installed and ready to run (and in the correct version). cargo is Rust's package manager, that handles dependencies and compiles your projects. I will not explain those things further, but now you know what to look for.","title":"How do I work with the code?"},{"location":"2022-07/ALL.html#running-our-first-program","text":"Now, that we have a VM, we will run a program on it. kratenko \u00b7 kratenko 2022-07-12 \u00b7 Entry #12 \u00b7 3 min read So we built our very first VM and studied the code in detail. It is time to execute a program on it and look at it's output. We will look at every single step the program takes. Aren't we lucky, that our VM is so talkative during execution? If you missed the code, look at the previous post, A VM .","title":"Running our first program"},{"location":"2022-07/ALL.html#lets-go","text":"/home/kratenko/.cargo/bin/cargo run --color=always --package lovem --bin lovem Finished dev [unoptimized + debuginfo] target(s) in 0.00s Running `target/debug/lovem` VM { stack: [], pc: 0, op_cnt: 0 } Executing op 0x00 NOP VM { stack: [], pc: 1, op_cnt: 1 } Executing op 0x02 PUSH_U8 value: 100 VM { stack: [100], pc: 3, op_cnt: 2 } Executing op 0x02 PUSH_U8 value: 77 VM { stack: [100, 77], pc: 5, op_cnt: 3 } Executing op 0x10 ADD VM { stack: [177], pc: 6, op_cnt: 4 } Executing op 0x01 POP dropping value 177 VM { stack: [], pc: 7, op_cnt: 5 } Terminated! VM { stack: [], pc: 8, op_cnt: 6 } Process finished with exit code 0","title":"Let's go!"},{"location":"2022-07/ALL.html#what-just-happened","text":"It is quite talkative. And isn't it nice, how easy it is, to print the complete state of our VM in Rust? And it costs no overhead during runtime, as it is generated during compilation for us. Isn't that something? So, what is happening there? Our program pgm looks like this: let pgm = [ op :: NOP , op :: PUSH_U8 , 100 , op :: PUSH_U8 , 77 , op :: ADD , op :: POP , 0xff ]; That are 8 bytes that consist of 6 instructions. Each instruction has a 1 byte opcode. Two of those instructions (the PUSH_U8 ) have one byte of argument each, making up the remaining two bytes of our program. Here they are listed: NOP PUSH_U8 [100] PUSH_U8 [77] ADD POP FIN The NOP does not do anything. I just put it in front of the program to let you see fetching, decoding, and executing without any effects: VM { stack: [], pc: 0, op_cnt: 0 } Executing op 0x00 NOP VM { stack: [], pc: 1, op_cnt: 1 } We just increased the program counter by one (we advance one byte in the bytecode), and the operation counter counts this executed instruction. Let's look at the next instruction, that is more interesting: VM { stack: [], pc: 1, op_cnt: 1 } Executing op 0x02 PUSH_U8 value: 100 VM { stack: [100], pc: 3, op_cnt: 2 } Here the PC is increased by two. That happens, because we fetch an additional value from the bytecode. The op_cnt is only increased by one. And we now have our first value on the stack! It is the byte we read from the bytecode. Let's do that again: VM { stack: [100], pc: 3, op_cnt: 2 } Executing op 0x02 PUSH_U8 value: 77 VM { stack: [100, 77], pc: 5, op_cnt: 3 } Now there are two values on the stack! Time to do something with them. Let's add them up: VM { stack: [100, 77], pc: 5, op_cnt: 3 } Executing op 0x10 ADD VM { stack: [177], pc: 6, op_cnt: 4 } Now there is only one value left on the stack, and it is the sum of the two values we had. There happened quite a lot here. The two values we had before where both popped from the stack (so it was shortly empty). The add operation adds them, and pushes their sum back on the stack. So now there is one value on the stack, and it is the result of our adding operation. What's next? VM { stack: [177], pc: 6, op_cnt: 4 } Executing op 0x01 POP dropping value 177 VM { stack: [], pc: 7, op_cnt: 5 } It is always nice to leave your workplace all tidied up, when you are done. We can do that by popping our result back from the stack, leaving it empty. And besides, our POP operation prints the value it drops. One more instruction to go: VM { stack: [], pc: 7, op_cnt: 5 } Terminated! VM { stack: [], pc: 8, op_cnt: 6 } Well, not much happening there. Just stopping the VM, because we are done.","title":"What just happened?"},{"location":"2022-07/ALL.html#success","text":"So, we ran a program in a VM. Hooray, we are done. Only 132 lines of code, including excessive comments and logging. That was easy. Well yeah - it doesn't do much. But you can understand the root principle that makes up a stack machine. It's that simple. Go play around with it a bit. It is the best way to learn and to understand. I mean it! Write a longer program. What happens to the stack? Add another opcode \u2013 how about subtraction? Will your program execute at all? What happens, if it does not?","title":"Success!"},{"location":"2022-07/ALL.html#turn-fragile-into-rusty","text":"After we got our Proof of Concept running, we clean up our code and make it look like a respectable Rust program. kratenko \u00b7 kratenko 2022-07-14 \u00b7 Entry #13 \u00b7 2 min read Did you play around with the program from the previous post? If you are new to Rust, you really should! At least mess around with our bytecode. You should find, that our VM does not react well to errors, yet. It simply panics! That is no behaviour for a respectable rust program. We will make it more rusty, look at the enhanced version: Repo: https://github.com/kratenko/lovem/tree/v0.0.2-journey main.rs: https://github.com/kratenko/lovem/blob/v0.0.2-journey/src/main.rs If you do not know your way around Rust, some of those things will be difficult to understand. It might be time to read up on some Rust, if you intend to follow my journey onwards. I will not explain everything here, but I will give you some leads right now, if you want to understand the things I did in that change.","title":"Turn \"fragile\" into \"rusty\""},{"location":"2022-07/ALL.html#it-is-all-in-the-enums","text":"The most important thing to understand for you will be Enums . Yeah, I know. That is what I thought at first learning Rust. \"I know enums. Yeah, they are handy and useful, but what could be so interesting about them?\" Well, in fact, enums in Rust completely change the way you are writing code. They are such an important part of the language that they have an impact on just about every part of it. I introduced an enum to the code: # #[derive(Debug, Clone, PartialEq)] pub enum RuntimeError { EndOfProgram , InvalidOperation ( u8 ), StackUnderflow , StackOverflow , } It is obviously a datatype to communicate runtime errors of different nature. And I use it a bit like you would exceptions in some other languages. Nevermind the #[derive...] part for now. That is just for fancy debug output (and a bit more). Once you understand line 33 : InvalidOperation(u8), , you are on the right track! To put it into easy terms: values of enums in Rust can hold additional values. And, as you see in our RuntimeError , not all values have to hold the same kind of additional value, or a value at all. This is, what makes enums really powerful. If you know what happens in the return type of fn push in line 70 , you are golden. The Result type can communicate a value on success or an error condition on failure. The great difference to typical exceptions form other languages is, that there is no special way to pass on the errors, as with exceptions that are thrown. It is just your normal return statement used. And this is done, you guessed it, with enums. If you want to read up on Result , try understanding Option first. I am using that in my code, even though you cannot see it. If you are wondering now about the return of fn push , that does not have a return statement to be seen, you should find out, while some of my lines do not have a semicolon ; at the end, while most do. And then there is that tiny ? in line 101 . Also find out what happens in the match in [line 166][line166]. It might help if you start with the if let statement. Bonus points: line 66 . If that is clear to you, you need have no worries, you are into enums and how to use them","title":"It is all in the enums"},{"location":"2022-07/ALL.html#homework","text":"So, this is what will get you through a lot here. Try to understand those in the given order: Option Some(v) vs. None Result<v, e> Ok(v) vs. Err(e) if let Some(v) = match Result<(), e> Ok(()) unwrap() ? Bonus: ok() , ok_or() , and their likes If you understand for each of those, and why I put them in the list, you are prepared to handle most Rust things I will be doing in the next time. If you have problems with parts of it, still, move on. It gets better after a while, when you use them.","title":"Homework"},{"location":"2022-07/ALL.html#becoming-social","text":"A new way for you to participate in my journey. kratenko \u00b7 kratenko 2022-07-15 \u00b7 Entry #14 \u00b7 < 1 min read After a few days of progress on the project itself, I spent a bit of time on the site again. We have the fancy link to our GitHub repo in the upper right corner now. But more important, I added support for comments on my entries. You can now react and ask questions or share your thought. I am using giscus.app (and, again, I copied that idea from @squidfunk and their site on mkdocs-material , which is what I did for this complete site, more or less). Giscus is an open source app that stores the comments completely inside GitHub discussions, so the content is stored along the lovem repository and at the one place where everything is stored already anyway. If you want to participate in the comments, you need to log in using your GitHub account. That is great, because I don't need to care about user management, nor about any database. Feel free to use this entry to try out the new feature, because that is what I am gonna do!","title":"Becoming social"},{"location":"2022-07/ALL.html#to-the-library","text":"We turn our project from a binary project into a library project. kratenko \u00b7 kratenko 2022-07-18 \u00b7 Entry #15 \u00b7 5 min read \u00b7 v0.0.3-journey So far, our lovem cargo project holds a single binary. That is not very useful for something that should be integrated into other projects. What we need is a library . How is that done? Simple: we rename our main.rs to lib.rs .","title":"To the library!"},{"location":"2022-07/ALL.html#no-main","text":"But wait? What about fn main() ? We do not need that inside a library. But it would be nice to still have some code that we can execute, right? Well, no problem. Your cargo project can only hold a single library, but it can hold even multiple binaries, each with its own fn main() . Just stuff them in the bin subdir.","title":"No main?"},{"location":"2022-07/ALL.html#project-layout","text":"While we are at it, I split the project up into multiple source files, to get it organised. It is small, still, but we will have it grow, soon. Here is, what we are at now: lovem/ src/ bin/ test-run.rs lib.rs op.rs vm.rs .gitignore Cargo.toml We skip .gitignore . If you don't know what it is, google .gitignore .","title":"Project layout"},{"location":"2022-07/ALL.html#cargotoml","text":"So Cargo.toml holds information about our cargo project. There is not much of interest there currently: [package] name = \"lovem\" version = \"0.0.3\" edition = \"2021\" authors = [ \"kratenko\" ] [dependencies] The only real configuration in that file is edition = \"2021\" . Rust has a major edition release every three years. These are used to introduce braking changes. You have to specify the edition you use explicitly, and there are migration guides. We use the most recent one, 2021 .","title":"Cargo.toml"},{"location":"2022-07/ALL.html#librs","text":"Rust manages projects by using default project layouts. That is why we need not write a lot into the Cargo.toml . The src directory holds our source code. The fact that it holds a lib.rs makes it a library, and lib.rs is the entry point. This is what is in it: pub mod op ; pub mod vm ; // re-export main types pub use crate :: vm :: VM ; Really not a lot. It declares the two modules op and vm and makes them public. So, whatever rust project will be using our library will have access to those modules. The modules will be in the files op.rs and vm.rs . What a coincidence, that are exactly the remaining two source files in this directory! The last line just re-exports a symbol from one of those submodules, so that programs using our library can access more easily. Will will be doing that in our binary.","title":"lib.rs"},{"location":"2022-07/ALL.html#oprs","text":"Back in v0.0.2-journey , we already had a module called op to hold the opcodes. We had it stuffed in our main.rs . Now it lives in a separate file, so we do not have to scroll over it every time.","title":"op.rs"},{"location":"2022-07/ALL.html#vmrs","text":"This holds the rest of our source code (except for fn main() which has no place in a lib). The only new thing, compared with our former main.rs is the first line: use crate :: op ; This simply pulls the module op into the namespace of this module, so that we can access our opcode constants as we did before. The rest remains the way we already know.","title":"vm.rs"},{"location":"2022-07/ALL.html#bintest-runrs","text":"So how do we use our lib in a project? That is best illustrated by doing it. And we can do so inside our project itself, because we can add binaries. Just put a Rust source file with a fn main() inside the bin subdir. There we can write a binary as we would in a separate project, that can use the lib. We did that in the file test-run.rs : use lovem :: { op , VM }; fn main () { // Create a program in bytecode. // We just hardcode the bytes in an array here: let pgm = [ op :: NOP , op :: PUSH_U8 , 100 , op :: PUSH_U8 , 77 , op :: ADD , op :: POP , 0xff ]; // Crate our VM instance. let mut vm = VM :: new ( 100 ); // Execute the program in our VM: match vm . run ( & pgm ) { Ok ( _ ) => { println! ( \"Execution successful.\" ) } Err ( e ) => { println! ( \"Error during execution: {:?}\" , e ); } } } This is the fn main() function from our former main.rs . Instead of having all the functions and definitions, it just has this single line at the top: use lovem :: { op , VM }; Nothing too complicated. It tells the compiler, that our program uses the library called lovem (which is, of course, the one we are writing ourselves here). It also tells it to bring the two symbols op and VM from it into our namespace. The op one is simply the module op defined in op.rs . Because lib.rs declares the module public, we can access it from here. VM does not refer to the module in vm.rs , as that module is called vm (in lower case). VM is actually the struct we defined in vm , that we use to hold the state of our Virtual Machine. We could include the struct as lovem::vm::VM , which is its full path. But I find that a bit anoying, as VM is the main type of our whole library. We will always be using that. So I re-exported it in lib.rs . Remember the line pub use crate::vm::VM; ? That's what it did.","title":"bin/test-run.rs"},{"location":"2022-07/ALL.html#running-the-binary","text":"So, how do we run our program now? Back in v0.0.2-journey we simply called cargo run . That actually still works, as long as we have exactly one binary. But we can have multiple binaries inside our project. If we do, we need to tell cargo which it should run. That can easily be done: cargo run --bin test-run The parameter to --bin is the name of the file inside bin , without the .rs . And no configuration is needed anywhere, it works by convention of project layout.","title":"Running the binary"},{"location":"2022-07/ALL.html#homework_1","text":"What, homework again? Yeah, why not. If it fits, I might keep adding ideas for you to play around with. Doing things yourself is understanding. Stuff we just read, we tend to forget. So here is what might help you understand the project layout stuff I was writing about: Add a second binary, that runs a different program in the VM (with different bytecode). You have all the knowledge to do so. And then run it with cargo.","title":"Homework"},{"location":"2022-07/ALL.html#source-code","text":"In earlier posts I included explicit links to the source code at the time of writing. That got annoying to do really fast. So I added a new feature to my blogem.py that I use to write this journal. Entries like this, that are explaining a specific state of the source of lovem will have a tag from now on. This corresponds to a tag inside the git repository, as it did in earlier posts. You will find it in the card at the top of the post (where you see the publishing date and the author). It is prefixed with a little tag image. For this post it looks like this: v0.0.3-journey At the bottom of the entry (if you view it in the entry page, not in the \"whole month\" page), you will find it again with a list of links that help you access the source in different ways. The best way to work with the code, is to clone the repository and simply check out the tag. I also added a page on this site, explaining how you do that. You can find it under Source Code . So, in future I will not be adding explicit links, only this implicit ones. And there will be a link to the explaining page at the bottom. This should be convenient for both, you and me.","title":"Source code"},{"location":"2022-07/ALL.html#early-vm-decisions","text":"Many design decisions must be made for lovem. Here I talk about some of those in the current state. kratenko \u00b7 kratenko 2022-07-19 \u00b7 Entry #16 \u00b7 3 min read \u00b7 v0.0.3-journey I have shared and discussed source code in the recent posts. Now it is time again, to write about design decisions. I made a few of them for the code you saw. So far I have not been reasoning about those here, and some of you might have wondered already. Let's talk about them. Let me remind you: lovem is a research project for myself. And an education project for myself as well. None of my choices at this stage are set into stone. I will make lots of mistakes that I will be changing later. I even choose some paths, that I know I will be leaving again. I might just take any solution for a problem, at this stage, as I do not know, what is the right choice. So start somewhere, see where it goes. Some of those are deliberately weird or bad choices, but they make things clearer or simpler at this stage. Let us address two of those choices you can find in the current source code.","title":"Early VM decisions"},{"location":"2022-07/ALL.html#word-size","text":"I talked about register sizes defining architecture, back in What is a Virtual Machine anyway? . And then I went totally silent about that topic and just used i64 as type for my stack. Is that a good idea? I used it for simplicity. The idea goes back to when I was experimenting with using a register machine for lovem. Having a simple datatype that can handle big values seems simple. After all, other languages/VMs use some version of float as their single numeric datatype: JavaScript JavaScript Numbers are Always 64-bit Floating Point Unlike many other programming languages, JavaScript does not define different types of numbers, like integers, short, long, floating-point etc. JavaScript numbers are always stored as double precision floating point numbers, following the international IEEE 754 standard. \u2014 w3schools.com - retrieved 2022-07-11 Lua 2.3 - Numbers The number type represents real (double-precision floating-point) numbers. Lua has no integer type, as it does not need it. \u2014 Programming in Lua - retrieved 2022-07-11 Well, reducing complexity is good. But having each little number you use in your programs eat up 8 bytes of memory does not sound low overhead to me. And that is, after all, the goal. So I guess, that will change in the future. But let's keep it for the time being. There will be some interesting things we will be doing in the near future; even if we might dump those features later. I already implemented them during the early phase (when I was not writing a public journal), so not adding them here would be insincere. Having 64 bit values is a part of our journey.","title":"Word size"},{"location":"2022-07/ALL.html#opargs","text":"I have no glossary, yet, so you have to live with me inventing terms on the spot. I used that word in the source code already. What I mean by it, are the arguments to an instruction inside the bytecode, that follow the opcode and influence the operation. They are the arguments you give inside your program's code. As of v0.0.3-journey we only have a single opcode that takes an oparg, and that is push_u8 . You can see how there is a fetch_u8() instruction in the code that handles that operation, and none in the other operations. See execute_op . So we have different behaviour depending on the opcode. push_u8 fetches an additional byte from the bytecode, the other opcodes do not. Existing VMs handle this differently. The Java VM, for example, has a dynamic number of opargs, too. They call them operands : 2.11. Instruction Set Summary A Java Virtual Machine instruction consists of a one-byte opcode specifying the operation to be performed, followed by zero or more operands supplying arguments or data that are used by the operation. Many instructions have no operands and consist only of an opcode. \u2014 The Java\u00ae Virtual Machine Specification - Java SE 8 Edition - retrieved 2022-07-11 The Python VM on the other hand, uses exactly one byte as oparg on all instructions The bytecode can be thought of as a series of instructions or a low-level program for the Python interpreter. After version 3.6, Python uses 2 bytes for each instruction. One byte is for the code of that instruction which is called an opcode , and one byte is reserved for its argument which is called the oparg . [...] Some instructions do not need an argument, so they ignore the byte after the opcode. The opcodes which have a value below a certain number ignore their argument. This value is stored in dis.HAVE_ARGUMENT and is currently equal to 90. So the opcodes >= dis.HAVE_ARGUMENT have an argument, and the opcodes < dis.HAVE_ARGUMENT ignore it. \u2014 Reza Bagheri - Understanding Python Bytecode - in Towards Data Science - retrieved 2022-07-11 That does remove some complexity. And adds new complexity - for opcodes with more than one oparg byte - they exist in python and are handled with a special opcode, that adds an additional oparg byte. I think it will make execution faster, as fetching can be done it advance. If you do not know, how many bytes you need, before your read your opcode, you cannot prefetch the next instructions. For our goal, keeping the bytecode small is much more important than execution time. So I am pretty sure we will stick with the dynamic number of oparg bytes in lovem.","title":"Opargs"},{"location":"2022-07/ALL.html#more-operations","text":"The basic operation of the VM is working. Let us add a few more opcodes, so that we can do calculations. kratenko \u00b7 kratenko 2022-07-20 \u00b7 Entry #17 \u00b7 4 min read \u00b7 v0.0.4-journey We have created a rust library that holds our virtual register machine. We can now add multiple executables to it, so that makes it easier, to write different programs and keep them (to mess around with the VM). We will add a few more opcodes to our repertoire, because only adding numbers is just plain boring. I put some sort into what opcodes to introduce; but be advised, that none of them are final. Not only is the VM experimental and in a very early state, I introduce codes that I do not intend to keep on purpose. This is also a demonstration/introduction. So I add codes that are helpful at the time of writing, for experimenting. FIN is an example of a code, that will most likely be removed at some point. But for now it is nice to have a simple way to explicitly terminate the program. It gives some confidence, when we reach that point, that our program works as intended, and that we did not mess up the bytecode.","title":"More operations"},{"location":"2022-07/ALL.html#arithmetics","text":"Baby steps. No rush here. We had adding as a first example. We will introduce subtraction , multiplication , division , and modulo . Sounds like not much, but we will run in some complications, anyways... Here is our addtion to op.rs . /// opcode: Subtract top two values on stack. /// /// pop: 2, push: 1 /// oparg: 0 pub const SUB : u8 = 0x11 ; /// opcode: Multiply top two values on stack. /// /// pop: 2, push: 1 /// oparg: 0 pub const MUL : u8 = 0x12 ; /// opcode: Divide top two values on stack. /// /// pop: 2, push: 1 /// oparg: 0 pub const DIV : u8 = 0x13 ; /// opcode: Calculate modulo of top two values on stack. /// /// pop: 2, push: 1 /// oparg: 0 pub const MOD : u8 = 0x14 ;","title":"Arithmetics"},{"location":"2022-07/ALL.html#the-order-of-things","text":"Simple enough those new codes, just copy and paste from ADD . But it turns out, subtraction is not as easy as addition. Here is the handling code we used for ADD : op :: ADD => { println! ( \" ADD\" ); let a = self . pop () ? ; let b = self . pop () ? ; self . push ( a + b ) }, Works. But if we copy and use that for SUB : op :: SUB => { println! ( \" SUB\" ); let a = self . pop () ? ; let b = self . pop () ? ; self . push ( a - b ) }, It turns out, that I messed up the order of the operands. That does not matter for addition, but subtraction is not commutative. So let's change that: op :: ADD => { println! ( \" ADD\" ); let b = self . pop () ? ; let a = self . pop () ? ; self . push ( a + b ) }, op :: SUB => { println! ( \" SUB\" ); let b = self . pop () ? ; let a = self . pop () ? ; self . push ( a - b ) }, op :: MUL => { println! ( \" MUL\" ); let b = self . pop () ? ; let a = self . pop () ? ; self . push ( a * b ) }, op :: DIV => { println! ( \" DIV\" ); let b = self . pop () ? ; let a = self . pop () ? ; self . push ( a / b ) }, op :: MOD => { println! ( \" MOD\" ); let b = self . pop () ? ; let a = self . pop () ? ; self . push ( a % b ) }, So, we learned something. I put the other operators there, as well. But this is too naive. You might already see the problem.","title":"The order of things"},{"location":"2022-07/ALL.html#blowing-up-the-school","text":"As my math teacher liked to say: \"... dann fliegt die Schule in die Luft!\" \u2013 If we do that the school building will blow up. It is his way of dealing with the issue, that pupils are told \"you must never divide by zero\", but that they are never given an understandable reason for it. So just own it, and provide a completely absurde one. What happens, is we keep it like this? Well, not much - until you write a program that divides by zero. Then, this will happen: [...] VM { stack: [4, 0], pc: 4, op_cnt: 2 } Executing op 0x13 DIV thread 'main' panicked at 'attempt to divide by zero', src/vm.rs:142:31 stack backtrace: 0: rust_begin_unwind at /rustc/fe5b13d681f25ee6474be29d748c65adcd91f69e/library/std/src/panicking.rs:584:5 1: core::panicking::panic_fmt at /rustc/fe5b13d681f25ee6474be29d748c65adcd91f69e/library/core/src/panicking.rs:143:14 2: core::panicking::panic at /rustc/fe5b13d681f25ee6474be29d748c65adcd91f69e/library/core/src/panicking.rs:48:5 3: lovem::vm::VM::execute_op at ./src/vm.rs:142:31 4: lovem::vm::VM::run at ./src/vm.rs:85:13 5: modulo::main at ./src/bin/modulo.rs:10:11 6: core::ops::function::FnOnce::call_once at /rustc/fe5b13d681f25ee6474be29d748c65adcd91f69e/library/core/src/ops/function.rs:227:5 note: Some details are omitted, run with `RUST_BACKTRACE=full` for a verbose backtrace. Process finished with exit code 101 Our program panics! I told you earlier, that this is not good behaviour. I introduced you to a lot of weird Rust stuff, just to avoid those. So, let us not re-introduce them now. So, what can we do instead? Division by zero is a runtime error, for sure (at least in this numerical domain we are working with). But it should not be a runtime error in our virtual machine, it should be a runtime error in the program it is running. Luckily, we already have that mechanism in our VM. So let us add a new runtime error: /// An error that happens during execution of a program inside the VM. # #[derive(Debug, Clone, PartialEq)] pub enum RuntimeError { EndOfProgram , UnknownOpcode ( u8 ), StackUnderflow , StackOverflow , DivisionByZero , } And adjust our opcode handlers: op :: DIV => { println! ( \" DIV\" ); let b = self . pop () ? ; let a = self . pop () ? ; if b == 0 { Err ( RuntimeError :: DivisionByZero ) } else { self . push ( a / b ) } }, op :: MOD => { println! ( \" MOD\" ); let b = self . pop () ? ; let a = self . pop () ? ; if b == 0 { Err ( RuntimeError :: DivisionByZero ) } else { self . push ( a % b ) } }, We add a check for the DIV and MOD handlers (modulo is a division as well). If we run that program dividing by zero again, we now get this: [...] VM { stack: [4, 0], pc: 4, op_cnt: 2 } Executing op 0x13 DIV Error during execution: DivisionByZero Process finished with exit code 0 Yes, it still fails. But only the execution of the bytecode fails, not the execution of our virtual machine. You can now handle the problem inside your Rust program in a way that fits your needs. Much better. In the next post, we will be using our new instructions in a fancy way, that works well with a stack machine.","title":"Blowing up the school"},{"location":"2022-07/ALL.html#homework_2","text":"Oh, not sure. Play around with it, I guess? As always. Feel free to write a calculation into a program and compare the results. It should work, unless I messed up again. You should have at least, at some point, write a program in bytecode yourself, so that you know how that feels.","title":"Homework"},{"location":"2022-07/ALL.html#reverse-polish-notation","text":"We are using the design of a stack machine to efficiently execute some calculations. kratenko \u00b7 kratenko 2022-07-21 \u00b7 Entry #18 \u00b7 4 min read \u00b7 v0.0.5-journey The way stack machines work can be used in programs that execute calculations. We will look at it by implementing an example from the Wikipedia page about stack machines. I will quote a lot of it here. You can see the full text of the article and its authors when you follow the Wikipedia permalink to the article . Design Most or all stack machine instructions assume that operands will be from the stack, and results placed in the stack. The stack easily holds more than two inputs or more than one result, so a rich set of operations can be computed. In stack machine code (sometimes called p-code), instructions will frequently have only an opcode commanding an operation, with no additional fields identifying a constant, register or memory cell, known as a zero address format. 2 This greatly simplifies instruction decoding. Branches, load immediates, and load/store instructions require an argument field, but stack machines often arrange that the frequent cases of these still fit together with the opcode into a compact group of bits. \u2014 Wikipedia - retrieved 2022-07-15 So far nothing new - I wrote about all that in my earlier posts. The selection of operands from prior results is done implicitly by ordering the instructions. [...] \u2014 ibid. Now, here it gets interesting. [...] The instruction set carries out most ALU actions with postfix ( reverse Polish notation ) operations that work only on the expression stack, not on data registers or main memory cells. This can be very convenient for executing high-level languages, because most arithmetic expressions can be easily translated into postfix notation. For example, consider the expression A*(B-C)+(D+E), written in reverse Polish notation as A B C - * D E + +. Compiling and running this on a simple imaginary stack machine would take the form: # stack contents (leftmost = top = most recent): push A # A push B # B A push C # C B A subtract # B-C A multiply # A*(B-C) push D # D A*(B-C) push E # E D A*(B-C) add # D+E A*(B-C) add # A*(B-C)+(D+E) \u2014 ibid. Well, I don't know about a \"simple imaginary stack machine\" - but as it happens to be, we have a very real simple stack machine at our disposal. You know where we will be going next!","title":"Reverse polish notation"},{"location":"2022-07/ALL.html#porting-the-code-to-lovem","text":"The program from the Wikipedia article uses 5 variables A to E . We do not support any kind of variables, yet, but that isn't important here. We use immediates (literals from your program) to put some concrete values into the calculation. Let's just take some numbers, totally at random: A = 5, B = 7, C = 11, D = 13, E = 17 And we add a new binary to the project: reverse-polish.rs //! A small program demonstrating execution of arithmetics in our VM. //! //! For an explanation of what we are doing here, look at this wikipedia article: //! https://en.wikipedia.org/w/index.php?title=Stack_machine&oldid=1097292883#Design use lovem :: { op , VM }; // A*(B-C)+(D+E) // A B C - * D E + + // A = 5, B = 7, C = 11, D = 13, E = 17 // 5 * (7 - 11) + (13 + 17) = 10 fn main () { // Create a program in bytecode. // We just hardcode the bytes in an array here: let pgm = [ op :: PUSH_U8 , 5 , op :: PUSH_U8 , 7 , op :: PUSH_U8 , 11 , op :: SUB , op :: MUL , op :: PUSH_U8 , 13 , op :: PUSH_U8 , 17 , op :: ADD , op :: ADD , op :: POP , op :: FIN ]; // Create our VM instance. let mut vm = VM :: new ( 100 ); // Execute the program in our VM: match vm . run ( & pgm ) { Ok ( _ ) => { println! ( \"Execution successful.\" ) } Err ( e ) => { println! ( \"Error during execution: {:?}\" , e ); } } } The comments spoil the result, but we want to check it calculates correctly, so that is okay. The program is the same as before: create a VM and run some hardcoded bytecode on it. Since the VM logs excessively, we will see what happens, when we run it. So the only new thing here is the bytecode program. I'll write it down in a more readable form: push_u8 5 push_u8 7 push_u8 11 sub mul push_u8 13 push_u8 17 add add pop fin To no-ones surprise, this code is the same as in the article - only with the variables replaced by numbers, and I added a pop and a fin at the end, to keep our program clean.","title":"Porting the code to lovem"},{"location":"2022-07/ALL.html#execution","text":"VM { stack: [], pc: 0, op_cnt: 0 } Executing op 0x02 PUSH_U8 value: 5 VM { stack: [5], pc: 2, op_cnt: 1 } Executing op 0x02 PUSH_U8 value: 7 VM { stack: [5, 7], pc: 4, op_cnt: 2 } Executing op 0x02 PUSH_U8 value: 11 VM { stack: [5, 7, 11], pc: 6, op_cnt: 3 } Executing op 0x11 SUB VM { stack: [5, -4], pc: 7, op_cnt: 4 } Executing op 0x12 MUL VM { stack: [-20], pc: 8, op_cnt: 5 } Executing op 0x02 PUSH_U8 value: 13 VM { stack: [-20, 13], pc: 10, op_cnt: 6 } Executing op 0x02 PUSH_U8 value: 17 VM { stack: [-20, 13, 17], pc: 12, op_cnt: 7 } Executing op 0x10 ADD VM { stack: [-20, 30], pc: 13, op_cnt: 8 } Executing op 0x10 ADD VM { stack: [10], pc: 14, op_cnt: 9 } Executing op 0x01 POP dropping value 10 VM { stack: [], pc: 15, op_cnt: 10 } Terminated! VM { stack: [], pc: 16, op_cnt: 11 } Execution successful. The output shows you the stack after every instruction. You can compare it to the stack contents in the Wikipedia listing, and you will find them identical (the order of the stack listing is switched, and of course you have numbers instead of arithmetic expressions with variables \u2013 but if you insert our numbers on the Wikipedia listing they should match). Our PoC stack machine really can do what the imaginary one is claimed to do. That's nice.","title":"Execution"},{"location":"2022-07/ALL.html#homework_3","text":"You should really read the article on Reverse Polish Notation ( permalink to article at time of writing ) . It will give some background on why it is important, not at least historically. The Z3, for example, arguably the first computer built by mankind 3 , was using it.","title":"Homework"},{"location":"2022-07/ALL.html#go-ahead-and-jump","text":"All our programs have been linear so far. Let's build the base for jumping around. kratenko \u00b7 kratenko 2022-07-22 \u00b7 Entry #19 \u00b7 5 min read \u00b7 v0.0.6-journey In every program we have written so far, each instruction just advances the PC 4 , until we reach the end. That is very linear. We will now introduce a new opcode, that jumps to a different position in the program.","title":"Go ahead and jump!"},{"location":"2022-07/ALL.html#a-new-opcode","text":"How do we implement that? That is actually quite easy. Do you remember what I said about the PC? It is a special register, that always points to the instruction in the bytecode, that is executed next. So all our operation needs to do is modify the PC. We will give that opcode an oparg of two bytes, so we can tell it, where to jump to. Here is our new opcode in op.rs : /// opcode: Relative jump. /// /// pop: 0, push: 0 /// oparg: 2B, i16 relative jump pub const GOTO : u8 = 0x20 ; Now we have the dreaded goto . Don't be scared - on bytecode level, that is all well. We are not designing a high level language here, there will be gotos. But how do we fetch an i16 from our bytecode? So far we can only fetch u8 . So we add some more fetching:","title":"A new opcode"},{"location":"2022-07/ALL.html#fetch-more-than-a-byte","text":"/// Reads the next byte from the bytecode, increase programm counter, and return byte. fn fetch_u8 ( & mut self , pgm : & [ u8 ]) -> Result < u8 , RuntimeError > { if let Some ( v ) = pgm . get ( self . pc ) { self . pc += 1 ; Ok ( * v ) } else { Err ( RuntimeError :: EndOfProgram ) } } /// Reads the next byte from the bytecode, increase programm counter, and return byte. fn fetch_i8 ( & mut self , pgm : & [ u8 ]) -> Result < i8 , RuntimeError > { if let Some ( v ) = pgm . get ( self . pc ) { self . pc += 1 ; Ok ( * v as i8 ) } else { Err ( RuntimeError :: EndOfProgram ) } } /// Reads the next two bytes from the bytecode, increase programm counter by two, and return as i16. fn fetch_i16 ( & mut self , pgm : & [ u8 ]) -> Result < i16 , RuntimeError > { let hi = self . fetch_i8 ( pgm ) ? as i16 ; let lo = self . fetch_u8 ( pgm ) ? as i16 ; Ok ( hi << 8 | lo ) } We already know fn fetch_u8() . fn fetch_i8() does almost the exact thing, only that it casts that byte from u8 to i8 . Simple enough. Casting in Rust has the beautiful syntax <value> as <type> . So why do we need i8 ? Because we are building an i16 from an i8 and a u8 . Just a bit of bit arithmetic. We can pass on potential EndOfProgram runtime errors easily with ? and Result . It allows us to write some short but still easy-to-read code, I think. So now we can fetch the value, we need for our jump. So let us write the handler for the opcode in fn execute_op() of vm.rs .","title":"Fetch more than a byte"},{"location":"2022-07/ALL.html#goto","text":"op :: GOTO => { println! ( \" GOTO\" ); let d = self . fetch_i16 ( pgm ) ? ; self . pc += d ; Ok (()) } So, is that all? No, because we made a Rust-beginner-mistake. If we try and compile the code, we get an error: error[E0308]: mismatched types --> src/vm.rs:174:28 | 174 | self.pc += d; | ^ expected `usize`, found `i16` Yeah - Rust does not allow us to do calculations with different types of integers. We need to explicitly cast everything. Rust tries to avoid ambiguity, so no implicit conversions. And, to be honest, the compiler has a good point. We should care even more about that calculation; we want our VM to be robust. We change the handler to: op :: GOTO => { println! ( \" GOTO\" ); let d = self . fetch_i16 ( pgm ) ? ; self . relative_jump ( pgm , d ) }","title":"Goto"},{"location":"2022-07/ALL.html#safe-goto","text":"And we add a new method (and we add a new RuntimeError): /// Executes a checked relative jump; Runtime error, if jump leaves program. fn relative_jump ( & mut self , pgm : & [ u8 ], delta : i16 ) -> Result < (), RuntimeError > { println! ( \" Jump from {} by {}\" , self . pc , delta ); if delta < 0 { let d = - delta as usize ; if self . pc >= d { self . pc -= d ; Ok (()) } else { Err ( RuntimeError :: InvalidJump ) } } else { let d = delta as usize ; if self . pc + d < pgm . len () { self . pc += d ; Ok (()) } else { Err ( RuntimeError :: InvalidJump ) } } }","title":"Safe goto"},{"location":"2022-07/ALL.html#enter-the-loop","text":"Now, let us write a new program that uses the goto opcode: //! Create a VM and run a small bytecode program in it. //! //! This demonstrates the goto operation with an endless loop. use lovem :: { op , VM }; fn main () { // Create a program in bytecode. // We just hardcode the bytes in an array here: let pgm = [ op :: PUSH_U8 , 123 , op :: GOTO , 0xff , 0xfb , op :: FIN ]; // Create our VM instance. let mut vm = VM :: new ( 100 ); // Execute the program in our VM: match vm . run ( & pgm ) { Ok ( _ ) => { println! ( \"Execution successful.\" ) } Err ( e ) => { println! ( \"Error during execution: {:?}\" , e ); } } } I will write that bytecode down in a more readable format again: push_u8 123 goto -5 fin Only 3 instructions. And the fin will never be reached. That 0xff, 0xfb after the op::GOTO is the 2 byte oparg: an i16 with the value -5 . But why -5 ? When the goto executed, we have read both oparg bytes, so the PC points to the fin at index 5. So adding -5 to it will set the PC to 0 . The next executed instruction will be the push_u8 once again. This is an endless loop. So will the program run forever? What do you think will happen? Let's try: VM { stack: [], pc: 0, op_cnt: 0 } Executing op 0x02 PUSH_U8 value: 123 VM { stack: [123], pc: 2, op_cnt: 1 } Executing op 0x20 GOTO Jump from 5 by -5 VM { stack: [123], pc: 0, op_cnt: 2 } Executing op 0x02 PUSH_U8 value: 123 VM { stack: [123, 123], pc: 2, op_cnt: 3 } Executing op 0x20 GOTO [...] VM { stack: [123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123], pc: 0, op_cnt: 200 } Executing op 0x02 PUSH_U8 value: 123 Error during execution: StackOverflow Process finished with exit code 0 There is a push_u8 operation in our endless loop. So it will fill our stack until it is full! The program hits a runtime error after 200 executed instructions. Great, now we tested that, too.","title":"Enter the loop"},{"location":"2022-07/ALL.html#nope","text":"That is not very dynamic. We want to make decisions! We want to choose our path. What we want is branching . We will introduce a new opcode, that will decide, which branch the execution of our program will take, based on a value during runtime. If this sounds unfamiliar to you, let me tell you, what statement we want to introduce: it is the if statement. So, how does that work? As mentioned, normally the PC is incremented on each byte we fetch from the bytecode. And the PC always points to the next instruction, that will be executed. So if we want to change the path of execution, what we have to do is change the value of the PC. An operation, that simply changes the PC statically, would be a GOTO statement. But there is no branching involved in that, the path that will be executed is always clear. The if statement on the other hand only alters the PC, if a certain condition is met.","title":"NOPE"},{"location":"2022-07/ALL.html#a-new-opcode_1","text":"/// opcode: Branch if top value is equal to zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFEQ : u8 = 0x20 ; Our new operation pops only one value. So what does it get compared to? That's easy: zero. If you need to compare two values to each other, just subtract them instead, and then you can compare with zero. That gives the same result. And what kind of oparg does this operation take? A signed integer. That is the value that should be added to the PC, if our condition is met. This will result in a relative jump.","title":"A new opcode"},{"location":"2022-07/ALL.html#homework_4","text":"Same as always. Write some bytecode. Try some jumping around. Run into troubles! You can write a program, that has a fin in the middle, but executes code that lies behind that instruction.","title":"Homework"},{"location":"2022-07/ALL.html#dont-byte-me","text":"I have had it with these motherloving bytes in this motherloving bytecode! kratenko \u00b7 kratenko 2022-07-25 \u00b7 Entry #20 \u00b7 5 min read \u00b7 v0.0.7-journey By now you should have come to a realisation: writing bytecode sucks! It wasn't fun to begin with, but now that we introduce jumps in our code, we need to count how many bytes the jump takes \u2013 and that with instructions that have different numbers of bytes as opargs. Encoding negative numbers in bytes is also no fun. And just think about it: if you change your program (e.g. add a few instructions), you have to adjust those relative jumps! How horrible is that? Can't someone else do it? Well, yeah, of course. We invented a machine that can do annoying and monotone tasks that require accuracy and that must be done over and over again. That machine is, of course, the computer. Well, lucky us, that we know how to tell a computer what it should do. So let's write a program, that writes bytecode for us. I am not talking about compiling a programming language into our VM; at least not yet, not for a long time. But something that lets us write those instructions in a way that is at least a bit more human friendly. Maybe you remember that I already tried to write some of the bytecode programs I showed you in a more readable way, like this: push_u8 5 push_u8 7 push_u8 11 sub mul push_u8 13 push_u8 17 add add pop fin If that did remind you of something, that might be no coincidence.","title":"Don't byte me!"},{"location":"2022-07/ALL.html#assembler","text":"The listing up there looks a bit like assembler code. And on the earlier draft of lovem I did already write a program that could translate those listings into bytecode. We will do that again, together. But this will take us some time (that is, multiple journal entries). We need to acquire some additional Rust skills for that. And there is so much to explain inside that assembler program itself. Once again, I am making this up along the way. Yes, I have a plan, but I will just start to introduce syntax for the assembler, and it might not be ideal. That means, I might change it all again later. As the VM itself, our assembler will be experimental. You are welcome to give me ideas for the syntax; we do have the comments now, unter each post, feel free to use them. There is the whole GitHub discussions page as well. And you can still find me on Twitter. Find the link at the bottom of this page.","title":"Assembler"},{"location":"2022-07/ALL.html#command-line-tool","text":"The assembler will be a binary that you call with parameters. A typical command line tool, just like gcc or rustc are. So what we need to do, is to learn how one writes a command line tool in Rust. One that can read files, because I plan to write assembly programs in text files. And I have no desire to start parsing command line arguments myself. Neither do I want to write an introduction on writing command line tools in Rust. All this has been done. So I kindly direct you to an online book: Command Line Applications in Rust . That is where I got what I will be using here. They use a crate called clap , which seems to be the most used lib for building command line tools in Rust. It takes about 10 minutes to read. Finding out how to use the options of clap that I want took longer, but that will not be a thing for you, as I will just be using those options. This is the first time we are using external crates in Rust. We need to add our dependencies to Cargo.toml , before we can use them: [dependencies] clap = { version = \"3.2.12\" , features = [ \"derive\" ] } anyhow = \"1.0.58\"","title":"Command line tool"},{"location":"2022-07/ALL.html#introducing-lovas","text":"Now let us start with the assembler. We create a new binary that will become our assembler: lovas.rs //! An experimental assembler for lovem use clap :: Parser ; use anyhow :: { Context , Result }; /// Struct used to declare the command line tool behaviour using clap. /// /// This defines the arguments and options the tool provides. It is also used to /// generate the instructions you get when calling it with `--help`. # #[derive(Parser, Debug)] # #[clap(name = \"lovas\" , long_about = \"An experimental assembler for lovem, the Low Overhead Virtual Embedded Machine.\" , )] struct Cli { #[clap(parse(from_os_str), help = \"Path to assembler source file.\" )] source : std :: path :: PathBuf , } fn main () -> Result < () > { // read, validate, and evaluate command line parameters: let args = Cli :: parse (); // read complete source file into String: let content = std :: fs :: read_to_string ( & args . source ) . with_context ( || format! ( \"could not read file `{}`\" , args . source . as_path (). display (). to_string ()) ) ? ; // For now, just print our all the lines in the file: for ( n , line ) in content . lines (). enumerate () { println! ( \"{:4}: '{}'\" , n + 1 , line ); } // We succeeded in our work, so return Ok() as a Result: Ok (()) } As it happens with Rust, the code is very dense. I try to explain what I do inside the code using comments. This does not look like it does too much. Yet it does. You can call it using cargo run --bin lovas , as we learned earlier: kratenko@jotun:~/git/lovem$ cargo run --bin lovas Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas` error: The following required arguments were not provided: <SOURCE> USAGE: lovas <SOURCE> For more information try --help That is already a lot! It finds out that you did not supply a required argument and tells you in a somewhat understandable error message. We did not write any of that. And it even directs you how to get help: add --help to your call. Now if we use cargo to run our binary, we need to add an extra bit to the call, because we need to tell cargo where its own arguments end, end where the arguments to the called binary begin. This is done (as it is custom) by adding -- , to indicate the end of cargo's arguments. So if we want to pass --help to lovas, we can do it like this: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- --help Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas --help` lovas An experimental assembler for lovem, the Low Overhead Virtual Embedded Machine. USAGE: lovas <SOURCE> ARGS: <SOURCE> Path to assembler source file. OPTIONS: -h, --help Print help information How helpful! Also, now you can see why I added those two strings to our Cli struct; they show up in the help message.","title":"Introducing lovas"},{"location":"2022-07/ALL.html#run-it","text":"It looks like we need to give it a file to read, if we want the program to succeed and not exit with an error. I did write a little assembly program that we can use: hallo-stack.lass . Our assembler will not so anything too useful with it, because we did not write an assembler, yet. It will simply print out the lines of the file, prefixed with the line number (the call to .enumerate() is what I use to count the lines, while iterating over them). kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- pgm/hallo-stack.lass Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas pgm/hallo-stack.lass` 1: 'push_u8 123' 2: 'push_u8 200' 3: 'add' 4: 'pop' 5: 'fin' Neat! I feel this is a lot for such a small program! It is also enough for this journal entry. We will be working on lovas for a bit, now.","title":"Run it"},{"location":"2022-07/ALL.html#homework_5","text":"Well - if you have not done so, read the book I linked. At least up until chapter 1.4, I guess, that is what we need for now. And try to trigger some errors when calling lovas . What if the file you tell it to open does not exist? What if it cannot be read? Do you understand how those error messages propagate through the program and end up as a readable message in your console?","title":"Homework"},{"location":"2022-07/ALL.html#assemble","text":"We introduce an API for assembly to our lovem library. kratenko \u00b7 kratenko 2022-07-26 \u00b7 Entry #21 \u00b7 5 min read \u00b7 v0.0.8-journey Last time, we built the frame of a command line program, that will become our new assembler, lovas . It is time that we give that program the power to assemble.","title":"Assemble!"},{"location":"2022-07/ALL.html#calling-the-real-assembler","text":"lovas.rs is just the executable wrapper around the actual assembler, that will live inside the library. All lovas.rs does, is supply the command line interface. And that CLI-part does not belong in a library function. We got it nicely separated. And programs using the library can assemble source to bytecode themselves, without calling an external binary. We alter lovas.rs a bit. The part that just printed out the source lines is gone. We replace it with a call to a new library function, that can transfer assembly code into bytecode: fn main () -> Result < () > { .. . the same as before .. . // run the assembler: match asm :: assemble ( & name , & content ) { Ok ( pgm ) => { // we succeeded and now have a program with bytecode: println! ( \"{:?}\" , pgm ); Ok (()) }, Err ( e ) => { // Something went wrong during assembly. // Convert the error report, so that `anyhow` can do its magic // and display some helpful error message: Err ( Error :: from ( e )) }, } } The important part is the call to asm::assemble(&name, &constent) . We created a new module asm inside our lib. It exposes only a single function assemble and a few types for error handling. There will be a lot to unpack inside that module. The good news for us is: we do not need to restrain ourselves as much as we do in the VM itself. Resource usage is not really an issue here, because the assembler is not meant to run in a restricted environment. The idea of lovem is, that you write your programs elsewhere, outside the restricted environment, and only run the compiled bytecode in the VM on the restricted device. And since the scope handled by the assembler will still be defined by that restricted device, we expect to only write relatively small and simple programs. With modern computers used for assembling, we can use as much memory as we want. Oh, by the way... Yeah, I seem to stick to these short, cryptic names for the parts of lovem . VM , Pgm , op , asm - I kinda like it that way, and it goes well with the register names etc. That feels right for something as low-lever as a VM. And I give my best to always document those things properly, so that your IDE of choice will always show you, what each thing is.","title":"Calling the real assembler"},{"location":"2022-07/ALL.html#asm","text":"I wrote a very basic assembler inside asm.rs , and it is already over 250 lines long. Quite a lot to unpack. As before, I try to explain as much as possible inside the source code itself, using comments. This makes it easier to follow, and you can even do so inside the source in the repo, without reading this blog. There are four types that I introduce inside the mod: /// Errors that can happen during assembly. # #[derive(Debug, Clone)] pub enum AsmError { InvalidLine , UnknownInstruction ( String ), UnexpectedArgument , MissingArgument , InvalidArgument , } /// Report of failed assembly attempt. /// /// Wraps the error that occurred during assembly and supplied information where it did. # #[derive(Debug)] pub struct AsmErrorReport { /// Name of the program that failed to assemble. name : String , /// Line the error occurred during assembly. line : usize , /// Error that occurred. error : AsmError , } /// A single instruction parsed from the line of an assembly program. # #[derive(Debug)] struct AsmInstruction { /// Number of line the instruction was read from. /// /// The number of the line the instruction was taken from, most likely /// from a source file. Line counting starts at 1. line_number : usize , /// Opcode defining which operation is to be executed. opcode : u8 , /// Arguments used for execution of the operation. /// /// Zero or more bytes. oparg : Vec < u8 > , /// Position inside bytecode (starting at 0). /// /// Number of bytes that come before this instruction in the program. pos : usize , } /// A assembler program during parsing/assembling. # #[derive(Debug)] struct AsmPgm { /// Name of the program (just a string supplied by caller). name : String , /// Vector of parsed assembler instructions, in the order they are in the source file. instructions : Vec < AsmInstruction > , /// Current line number during parsing. /// /// Used for error reporting. line_number : usize , /// Current position inside bytecode during parsing. /// /// Used to calculate the exact position an instruction will be in the bytecode. text_pos : usize , /// The error that happened during parsing/assembling, if any. error : Option < AsmError > , } AsmError is easy enough to understand. We used the same idea for the RuntimeError inside the VM. When we run into an Error while trying to assemble the program, we return Err<AsmError> instead of Ok(()) , so that we can propagate what happened back to the caller. The nice thing is, that with speaking names for the enum values, and with the occasional embedded value (as in UnknownInstruction(String) ), the debug representation of the AsmError alone is enough to make the user understand what error was detected. AsmErrorReport is a little wrapper we use to add the information where we ran into an error. InvalidArgument is nice hint how to fix your program - but if that program is 2000 lines long, then good luck. When you know the InvalidArgument happened in line 1337, then you will find it much faster. Especially in an assembly language, that has never more than one single instruction per line. AsmInstruction is used to represent a single instruction inside a program. So each instance of this type will be linked to a specific line in the source file. If you don't remember, what counts as an instruction in lovem (at least at the time of writing), let me repeat: an instruction consists of exactly one operation that is to be executed, which is identified by its opcode (which is a number from 0x00 to 0xff stored in a single byte). Each instruction has zero or more bytes used as an argument, defining how the operation is to be executed. This argument is called oparg . We will also store the number of the line we found our instruction inside the source code, and the position inside the bytecode where the instruction will be. AsmPgm will represent the complete program during the assembly process. We will collect the instructions we parse from the source in there in a Vector. And we will hold the progress during parsing/assembling. This is not the type that will be returned to the caller, it is only used internally (as you can guess by the fact that it is not defined pub ).","title":"ASM"},{"location":"2022-07/ALL.html#where-does-the-program-come-from","text":"The only function the mod exports it assemble : /// Parse assembly source code and turn it into a runnable program (or create report). pub fn assemble ( name : & str , content : & str ) -> Result < Pgm , AsmErrorReport > { let asm_pgm = AsmPgm :: parse ( name , content ); asm_pgm . to_program () } It will return an AsmErrorReport , if anything goes wrong and the assembling fails. If the assembler succeeds, it returns an instance of Pgm . Now where does that come from? Our VM takes programs in form of a &[u8] . That will be changed soon, and then it will run programs from a special type Pgm that might have a bit more than just bytecode. I added another new module to the library: pgm.rs . That one is tiny and only holds the new struct Pgm \u2013 which itself is basic. But we have a type that holds a program, now. I believe that will be beneficial to us later. /// Holds a program to be executed in VM. # #[derive(Debug)] pub struct Pgm { /// Some name identifying the program. pub name : String , /// Bytecode holding the programs instructions. pub text : Vec < u8 > , } What is it, that the assembler does, to create such a Pgm . We will start to go through that in the next entry. This has been enough for today.","title":"Where does the program come from?"},{"location":"2022-07/ALL.html#parsing-the-source","text":"kratenko \u00b7 kratenko 2022-07-27 \u00b7 Entry #22 \u00b7 4 min read \u00b7 v0.0.8-journey So far we have read an assembly source file into a string, and we got to know some new data structures. It is time we use the one to fill the other. Let us start parsing. What we know so far is this: /// Parse assembly source code and turn it into a runnable program (or create report). pub fn assemble ( name : & str , content : & str ) -> Result < Pgm , AsmErrorReport > { let asm_pgm = AsmPgm :: parse ( name , content ); asm_pgm . to_program () }","title":"Parsing the source"},{"location":"2022-07/ALL.html#assembler-syntax","text":"Our experimental assembler will begin using a simple syntax. Only one instruction per line, short opnames to identify the operation to be executed, optionally a single argument. I have written a short program: hallo-stack.lass . push_u8 123 push_u8 200 add pop fin Straightforward. And you know the syntax already from my human friendly listings of bytecode. Parsing that looks simple. We do want to allow adding whitespaces, though. And we want to allow comments, for sure. Our assembler needs to handle a bit of noise, as in noice.lass . ## This is an awesome program! push_u8 123 push_u8 200 # What are we using the # 200 for? add pop ## let's end it here! fin Those two programs should be identical and produce the same bytecode.","title":"Assembler syntax"},{"location":"2022-07/ALL.html#one-line-at-a-time","text":"The parse() function we call creates an empty instance of AsmPgm and then processes the source file line after line, filling the AsmPgm on the way. /// Parse an assembly program from source into `AsmPgm` struct. fn parse ( name : & str , content : & str ) -> AsmPgm { // create a new, clean instance to fill during parsing: let mut p = AsmPgm { name : String :: from ( name ), instructions : vec ! [], line_number : 0 , text_pos : 0 , error : None , }; // read the source, one line at a time, adding instructions: for ( n , line ) in content . lines (). enumerate () { p . line_number = n + 1 ; let line = AsmPgm :: clean_line ( line ); if let Err ( e ) = p . parse_line ( line ) { // Store error in program and abort parsing: p . error = Some ( e ); break ; } } p } content.lines() gives us an iterator that we can use to handle each line of the String content in a for loop. We extend the iterator by calling enumerate() on it; that gives us a different iterator, which counts the values returned by the first iterator, and adds the number to it. So n will hold the line number and line will hold the line's content. We always keep track of where we are in the source. Because the enumerate() starts counting at 0 (as things should be), we need to add 1 . File lines start counting at 1 . The first thing we do with the line is cleaning it. Then it gets processed by parse_line(line) . If this produces an error, we will store that error and abort parsing. All our errors are fatal. The final line p returns the AsmPgm . We do not use a Result this time, but the AsmPgm can contain an error. Only if its error field is None , the parsing was successful.","title":"One line at a time"},{"location":"2022-07/ALL.html#cleaning-the-noise","text":"/// Removes all noise from an assembler program's line. fn clean_line ( line : & str ) -> String { // Remove comments: let line = if let Some ( pair ) = line . split_once ( \"#\" ) { pair . 0 } else { & line }; // Trim start and end: let line = line . trim (); // Reduce all whitespaces to a single space (0x20): ANY_WHITESPACES . replace_all ( line , \" \" ). to_string () } We use multiple techniques to clean our input: splitting, trimming, regular expressions. When we are done, we only have lines as they look in hallo-stack.lass . The cleaned line can also be completely empty. I want to add a word about that regexp in ANY_WHITESPACES . Where does it come from? I am using some more Rust magic there, and the crate lazy_static : use lazy_static :: lazy_static ; use regex :: Regex ; // Regular expressions used by the assembler. // lazy static takes care that they are compiled only once and then reused. lazy_static ! { static ref ANY_WHITESPACES : Regex = regex :: Regex :: new ( r\"\\s+\" ). unwrap (); static ref OP_LINE_RE : Regex = regex :: Regex :: new ( r\"^(\\S+)(?: (.+))?$\" ). unwrap (); } I do not pretend to understand the macro magic that happens here. But what happens, is that the regular expressions are compiled only once and then kept as some sort of global static immutable variable, that we can than use again and again all over the program as a reference. Static references are a convenient thing in Rust, if you remember what I told you about ownership. You can always have as many references to immutable static variables, because there is nothing that can happen to them, and they exist throughout the complete runtime of the program.","title":"Cleaning the noise"},{"location":"2022-07/ALL.html#parsing-a-clean-line","text":"/// Handles a single cleaned line from an Assembly program. fn parse_line ( & mut self , line : String ) -> Result < (), AsmError > { if line == \"\" { // empty line (or comment only) - skip return Ok (()); } if let Some ( caps ) = OP_LINE_RE . captures ( & line ) { let opname = caps . get ( 1 ). unwrap (). as_str (); let parm = caps . get ( 2 ). map ( | m | m . as_str ()); return self . parse_instruction ( opname , parm ); } Err ( AsmError :: InvalidLine ) } parse_line() processes each line. Empty ones are just skipped. We use another regular expression, to find out if they match our schema. Because we cleaned it the expression can be rather simple: r\"^(\\S+)(?: (.+))?$\" . We look for one or more non-empty chars for our opname . It can be followed by a single argument, which must consist of one or more chars, separated by a single space. That is our optional oparg . If the line fits, we found an introduction we can try to parse. That is the job of parse_instruction() . Everything that is neither empty nor an instruction, is an error, that we can simply return. It will abort the parsing and the caller will know, that there was an invalid line. parse_instruction() can also run into an error. We use our tried pattern of returning a Result where the successful outcome does not carry any additional information (which is why we return Ok(()) ). The error case will return an AsmError, that carries the reason for the error. And because of our the Result type and because of Rust's might enum system, we can simply return what parse_instruction() returns to us. Handling the instruction itself will be handled in the next entry. Don't let yourself be confused by fancy terms like register . You can think of it as a kind of snobbish variable with a special meaning. In computers sometimes stuff magically happens when you write to a register \u2013 but it should always be documented somewhere. \u21a9 Beard, Bob (Autumn 1997). \"The KDF9 Computer - 30 Years On\" . Computer RESURRECTION. \u21a9 Yeah, I know. The answer to the question \"What was the first machine to qualify as a computer?\", differs, depending on whom you ask \u2013 and also on the country you ask the question in. But the Z3 is a prominent candidate. \u21a9 PC: the Program Counter, a special register that points to the next instruction to be executed. \u21a9","title":"Parsing a clean line"},{"location":"2022-07/NAV.html","text":"Parsing the source Assemble! Don't byte me! Go ahead and jump! Reverse polish notation More operations Early VM decisions To the library! Becoming social Turn \"fragile\" into \"rusty\" Running our first program A VM It looks so weird Let there be source code Making virtual a reality What is a Virtual Machine anyway? All new once more State of the Journal","title":"NAV"},{"location":"2022-07/a-vm.html","text":"A VM \u00b6 The first draft of source code, that will be our VM, explained. kratenko \u00b7 kratenko 2022-07-11 \u00b7 Entry #11 \u00b7 8 min read I dumped some source code in front of you, and then I started to talk about programming languages. Time now, to explain what I did and why. We only have 132 lines, including comments. We will go through all parts of it. And I will talk a little about how Rust's basic syntax works, while I use it. Not too much, since it is not good Rust code, yet, but to help you start. This will be a longer entry. I swear, if I do not see some code in this post... \u00b6 Alright, alright... We will start with our VM: #[derive(Debug)] pub struct VM { stack : Vec < i64 > , pc : usize , op_cnt : usize , } Nothing fancy, just a struct that will represent our Virtual Machine. Only three fields for now: stack : Obviously our stack machine would need one of those. This will hold values during execution. I am using a Vector. That is nothing more than a chunk of memory, that knows how much capacity it has and how many values are in it at the moment. It does support resizing, but I do not want to use that. pc will be our program counter . That is a register 1 holding the progress in the program during execution. It will always point at the instruction that is to be executed next. op_cnt will be counting the number of operations executed. For now, I want that information out of curiosity, but later it will be useful for limiting execution time for programs. usize and i64 are Rust's names for integer types. The language is very explicit in those terms (and very strict, as in every aspect). I will not give a real introduction to Rust for you (there are pages that do that), but I will try to start slowly and give you hints on the important things I introduce, so that you get the chance to learn about them parallel to this journal. I hope, that makes it easier to follow for Rust beginners. To readers that know Rust: please excuse the crude code here! I will make it more rusty, soon. Skip to the next post, if you cannot handle it. We will also need a program that we will run in our VM. For the start, a crude array of bytes will do. The VM will be running bytecode after all. And that really is only that: a bunch of bytes, that you will soon be able to understand. // assign `pgm` to hold a program: let pgm = [ 0x00 as u8 , 0x01 , 100 , 0xff ]; We will use a program that is a bit longer, but right now I wanted you to see a program, that is actually nothing but a collection of bytes in Rust code. let declares and assigns a variable here, named pgm . It is an array of 4 bytes ( u8 is an unsigned 8bit integer - you might know it as uint8_t from other languages). And that variable will not be variable at all. By default, all variables in Rust are immutable. If you want to change it, later, you would have to declare it using the modifier mut . There is no need to modify the program after creation, we just want to read it for execution. But our VM will have to be mutable, as it has changing internal state. Here is our complete main function, creating the (immutable) program and the (mutable) VM, and running the program. Of course, the run(...) method is still missing. And you will see the program, we will be using (with some constants that I did not define, yet). fn main () { // Create a program in bytecode. // We just hardcode the bytes in an array here: let pgm = [ op :: NOP , op :: PUSH_U8 , 100 , op :: PUSH_U8 , 77 , op :: ADD , op :: POP , 0xff ]; // Crate our VM instance. let mut vm = VM { stack : Vec :: with_capacity ( 100 ), pc : 0 , op_cnt : 0 }; // Execute the program in our VM: vm . run ( & pgm ); } Behaviour for our VM \u00b6 So far we only have an initialized data structure and some bytes. Let's do something with it. Rust does not really use objects (and I think that is good). But it has associated functions that work on types, and methods that work on instances of types. We will write some methods for our VM struct. Let's start with the one for reading our program: impl VM { /// Fetch the next byte from the bytecode, increase program counter, and return value. fn fetch_u8 ( & mut self , pgm : & [ u8 ]) -> u8 { if self . pc >= pgm . len () { panic! ( \"End of program exceeded\" ); } let v = pgm [ self . pc ]; self . pc += 1 ; v } } The fetch method will work on our VM instance. The first parameter is &mut self \u2013 that tells us it works on an instance of the type VM . It will work on a reference to the instance (indicated by the & ), and it can modify the data (indicated by the mut ). It will also take the reference to an array of u8 s, but that it will not be able to modify (no mut ). It returns a u8 . What it does is simply read and return a byte from the program, and increase the VMs internal program counter by one, so that the next call to fetch will return the next byte. Simple. So, what is that panic!() you might ask? Well, if we reach that instruction, it will start to panic, and then it will die. That is not a nice way to act. Do not worry, we will change that to something more reasonable, when we start writing better Rust. And what about the naked v in the last line? It will have the function return the value of v . Now, let's look at that run method, we were calling in main : impl VM { /// Executes a program (encoded in bytecode). pub fn run ( & mut self , pgm : & [ u8 ]) { // initialise the VM to be in a clean start state: self . stack . clear (); self . pc = 0 ; self . op_cnt = 0 ; // Loop going through the whole program, one instruction at a time. loop { // Log the vm's complete state, so we can follow what happens in console: println! ( \"{:?}\" , self ); // Fetch next opcode from program (increases program counter): let opcode = self . fetch_u8 ( pgm ); // We count the number of instructions we execute: self . op_cnt += 1 ; // If we are done, break loop and stop execution: if opcode == op :: FIN { break ; } // Execute the current instruction (with the opcode we loaded already): self . execute_op ( pgm , opcode ); } // Execution terminated. Output the final state of the VM: println! ( \"Terminated!\" ); println! ( \"{:?}\" , self ); } } The comments should explain, what is going on there. Initialise VM, then loop over the program, fetching one instruction at a time and executing it, until we reach the end. And you might have noticed, that our program will be very talkative. I added a lot of println s, that tell just about everything that happens, during execution. I guess it is time to look at those op:: constants I keep using. /// Module holding the constants defining the opcodes for the VM. pub mod op { /// opcode: Do nothing. No oparg. /// /// pop: 0, push: 0 /// oparg: 0 pub const NOP : u8 = 0x00 ; /// opcode: Pop value from stack and discard it. /// /// pop: 1, push: 0 /// oparg: 0 pub const POP : u8 = 0x01 ; /// opcode: Push immediate value to stack. /// /// pop: 0, push: 1 /// oparg: 1B, u8 value to push pub const PUSH_U8 : u8 = 0x02 ; /// opcode: Add top two values on stack. /// /// pop: 2, push: 1 /// oparg: 0 pub const ADD : u8 = 0x10 ; /// opcode: Terminate program. /// /// pop: 0, push: 0 /// oparg: 0 pub const FIN : u8 = 0xff ; } Just 5 u8 constants there, grouped in a module as a namespace. And a lot of comments to explain them. We have 5 different operations for our VM. The only thing missing is some code, that actually executes those instructions: impl VM { /// Executes an instruction, using the opcode passed. /// /// This might load more data from the program (opargs) and /// manipulate the stack (push, pop). fn execute_op ( & mut self , pgm : & [ u8 ], opcode : u8 ) { println! ( \"Executing op 0x{:02x}\" , opcode ); match opcode { op :: NOP => { println! ( \" NOP\" ); // do nothing }, op :: POP => { println! ( \" POP\" ); let v = self . stack . pop (). unwrap (); println! ( \" dropping value {}\" , v ); }, op :: PUSH_U8 => { println! ( \" PUSH_U8\" ); let v = self . fetch_u8 ( pgm ); println! ( \" value: {}\" , v ); self . stack . push ( v as i64 ); }, op :: ADD => { println! ( \" ADD\" ); let a = self . stack . pop (). unwrap (); let b = self . stack . pop (). unwrap (); self . stack . push ( a + b ); }, _ => { panic! ( \"unknown opcode!\" ); } } } } You can think of the match as a switch statement. It is much more than that, but here we use it as one. Each of our opcodes is handled individually. And we log a lot, so that we can read what is happening, when we run it. Ignore the unwrap() thingies for the time being. They are just there to try and ignore potential runtime errors. Again, not good Rust style, but, you know: later. The four operations get more complex in what they do. Let's go through them one by one: NOP \u2013 this does nothing, it just wastes bytecode and execution time. I have included it simply to be the most basic operation possible. POP \u2013 this is our first modification of the stack. It simply discards the topmost value, decreasing the stack's size by one. PUSH_U8 \u2013 this is the only operation that reads additional data from the program. It only reads a single byte (increasing the program counter by one), and puts it on top of the stack, increasing the stack's size by one. This is how you can get data from your program into the VM, to work with them. It is how numeric literals in your program are handled. ADD \u2013 the only operation that works on data. It pops its two operands from the stack, adds them, and pushes the sum back on the stack. This is how data is manipulated in a stack machine. The operation reduces the stack's size by one effectively, but there need to be at least 2 values on it for it to be executed. That is the out complete VM so far, and it will execute a program, if you compile and run it (which we will do in the next post). You can find the complete program here: https://github.com/kratenko/lovem/blob/v0.0.1-journey/src/main.rs You can access the repo at this state under (there is also a zip file containing all files): https://github.com/kratenko/lovem/releases/tag/v0.0.1-journey How do I work with the code? \u00b6 The easy way, to get the code and play with it, would be to clone the git repository and check out the tag v0.0.1-journey . If you did not understand any of that, you might want to do a tutorial on git, before you continue reading. Anyways, here is some copy&paste commands, you can hack into your bash prompt, to do, what I just told you to do. Use at your own risk, I'm not responsible for what you do to your system. you@host:~$ git clone https://github.com/kratenko/lovem.git you@host:~$ cd lovem you@host:~/lovem$ git checkout v0.0.1-journey you@host:~/lovam$ cargo run lovem This will copy all source code from GitHub and its history to your computer, and it will roll the source code to the state we are looking at in this entry. The last command cargo run lovem will compile and execute the program - that is, if Rust is installed and ready to run (and in the correct version). cargo is Rust's package manager, that handles dependencies and compiles your projects. I will not explain those things further, but now you know what to look for. Don't let yourself be confused by fancy terms like register . You can think of it as a kind of snobbish variable with a special meaning. In computers sometimes stuff magically happens when you write to a register \u2013 but it should always be documented somewhere. \u21a9","title":" A VM"},{"location":"2022-07/a-vm.html#a-vm","text":"The first draft of source code, that will be our VM, explained. kratenko \u00b7 kratenko 2022-07-11 \u00b7 Entry #11 \u00b7 8 min read I dumped some source code in front of you, and then I started to talk about programming languages. Time now, to explain what I did and why. We only have 132 lines, including comments. We will go through all parts of it. And I will talk a little about how Rust's basic syntax works, while I use it. Not too much, since it is not good Rust code, yet, but to help you start. This will be a longer entry.","title":"A VM"},{"location":"2022-07/a-vm.html#i-swear-if-i-do-not-see-some-code-in-this-post","text":"Alright, alright... We will start with our VM: #[derive(Debug)] pub struct VM { stack : Vec < i64 > , pc : usize , op_cnt : usize , } Nothing fancy, just a struct that will represent our Virtual Machine. Only three fields for now: stack : Obviously our stack machine would need one of those. This will hold values during execution. I am using a Vector. That is nothing more than a chunk of memory, that knows how much capacity it has and how many values are in it at the moment. It does support resizing, but I do not want to use that. pc will be our program counter . That is a register 1 holding the progress in the program during execution. It will always point at the instruction that is to be executed next. op_cnt will be counting the number of operations executed. For now, I want that information out of curiosity, but later it will be useful for limiting execution time for programs. usize and i64 are Rust's names for integer types. The language is very explicit in those terms (and very strict, as in every aspect). I will not give a real introduction to Rust for you (there are pages that do that), but I will try to start slowly and give you hints on the important things I introduce, so that you get the chance to learn about them parallel to this journal. I hope, that makes it easier to follow for Rust beginners. To readers that know Rust: please excuse the crude code here! I will make it more rusty, soon. Skip to the next post, if you cannot handle it. We will also need a program that we will run in our VM. For the start, a crude array of bytes will do. The VM will be running bytecode after all. And that really is only that: a bunch of bytes, that you will soon be able to understand. // assign `pgm` to hold a program: let pgm = [ 0x00 as u8 , 0x01 , 100 , 0xff ]; We will use a program that is a bit longer, but right now I wanted you to see a program, that is actually nothing but a collection of bytes in Rust code. let declares and assigns a variable here, named pgm . It is an array of 4 bytes ( u8 is an unsigned 8bit integer - you might know it as uint8_t from other languages). And that variable will not be variable at all. By default, all variables in Rust are immutable. If you want to change it, later, you would have to declare it using the modifier mut . There is no need to modify the program after creation, we just want to read it for execution. But our VM will have to be mutable, as it has changing internal state. Here is our complete main function, creating the (immutable) program and the (mutable) VM, and running the program. Of course, the run(...) method is still missing. And you will see the program, we will be using (with some constants that I did not define, yet). fn main () { // Create a program in bytecode. // We just hardcode the bytes in an array here: let pgm = [ op :: NOP , op :: PUSH_U8 , 100 , op :: PUSH_U8 , 77 , op :: ADD , op :: POP , 0xff ]; // Crate our VM instance. let mut vm = VM { stack : Vec :: with_capacity ( 100 ), pc : 0 , op_cnt : 0 }; // Execute the program in our VM: vm . run ( & pgm ); }","title":"I swear, if I do not see some code in this post..."},{"location":"2022-07/a-vm.html#behaviour-for-our-vm","text":"So far we only have an initialized data structure and some bytes. Let's do something with it. Rust does not really use objects (and I think that is good). But it has associated functions that work on types, and methods that work on instances of types. We will write some methods for our VM struct. Let's start with the one for reading our program: impl VM { /// Fetch the next byte from the bytecode, increase program counter, and return value. fn fetch_u8 ( & mut self , pgm : & [ u8 ]) -> u8 { if self . pc >= pgm . len () { panic! ( \"End of program exceeded\" ); } let v = pgm [ self . pc ]; self . pc += 1 ; v } } The fetch method will work on our VM instance. The first parameter is &mut self \u2013 that tells us it works on an instance of the type VM . It will work on a reference to the instance (indicated by the & ), and it can modify the data (indicated by the mut ). It will also take the reference to an array of u8 s, but that it will not be able to modify (no mut ). It returns a u8 . What it does is simply read and return a byte from the program, and increase the VMs internal program counter by one, so that the next call to fetch will return the next byte. Simple. So, what is that panic!() you might ask? Well, if we reach that instruction, it will start to panic, and then it will die. That is not a nice way to act. Do not worry, we will change that to something more reasonable, when we start writing better Rust. And what about the naked v in the last line? It will have the function return the value of v . Now, let's look at that run method, we were calling in main : impl VM { /// Executes a program (encoded in bytecode). pub fn run ( & mut self , pgm : & [ u8 ]) { // initialise the VM to be in a clean start state: self . stack . clear (); self . pc = 0 ; self . op_cnt = 0 ; // Loop going through the whole program, one instruction at a time. loop { // Log the vm's complete state, so we can follow what happens in console: println! ( \"{:?}\" , self ); // Fetch next opcode from program (increases program counter): let opcode = self . fetch_u8 ( pgm ); // We count the number of instructions we execute: self . op_cnt += 1 ; // If we are done, break loop and stop execution: if opcode == op :: FIN { break ; } // Execute the current instruction (with the opcode we loaded already): self . execute_op ( pgm , opcode ); } // Execution terminated. Output the final state of the VM: println! ( \"Terminated!\" ); println! ( \"{:?}\" , self ); } } The comments should explain, what is going on there. Initialise VM, then loop over the program, fetching one instruction at a time and executing it, until we reach the end. And you might have noticed, that our program will be very talkative. I added a lot of println s, that tell just about everything that happens, during execution. I guess it is time to look at those op:: constants I keep using. /// Module holding the constants defining the opcodes for the VM. pub mod op { /// opcode: Do nothing. No oparg. /// /// pop: 0, push: 0 /// oparg: 0 pub const NOP : u8 = 0x00 ; /// opcode: Pop value from stack and discard it. /// /// pop: 1, push: 0 /// oparg: 0 pub const POP : u8 = 0x01 ; /// opcode: Push immediate value to stack. /// /// pop: 0, push: 1 /// oparg: 1B, u8 value to push pub const PUSH_U8 : u8 = 0x02 ; /// opcode: Add top two values on stack. /// /// pop: 2, push: 1 /// oparg: 0 pub const ADD : u8 = 0x10 ; /// opcode: Terminate program. /// /// pop: 0, push: 0 /// oparg: 0 pub const FIN : u8 = 0xff ; } Just 5 u8 constants there, grouped in a module as a namespace. And a lot of comments to explain them. We have 5 different operations for our VM. The only thing missing is some code, that actually executes those instructions: impl VM { /// Executes an instruction, using the opcode passed. /// /// This might load more data from the program (opargs) and /// manipulate the stack (push, pop). fn execute_op ( & mut self , pgm : & [ u8 ], opcode : u8 ) { println! ( \"Executing op 0x{:02x}\" , opcode ); match opcode { op :: NOP => { println! ( \" NOP\" ); // do nothing }, op :: POP => { println! ( \" POP\" ); let v = self . stack . pop (). unwrap (); println! ( \" dropping value {}\" , v ); }, op :: PUSH_U8 => { println! ( \" PUSH_U8\" ); let v = self . fetch_u8 ( pgm ); println! ( \" value: {}\" , v ); self . stack . push ( v as i64 ); }, op :: ADD => { println! ( \" ADD\" ); let a = self . stack . pop (). unwrap (); let b = self . stack . pop (). unwrap (); self . stack . push ( a + b ); }, _ => { panic! ( \"unknown opcode!\" ); } } } } You can think of the match as a switch statement. It is much more than that, but here we use it as one. Each of our opcodes is handled individually. And we log a lot, so that we can read what is happening, when we run it. Ignore the unwrap() thingies for the time being. They are just there to try and ignore potential runtime errors. Again, not good Rust style, but, you know: later. The four operations get more complex in what they do. Let's go through them one by one: NOP \u2013 this does nothing, it just wastes bytecode and execution time. I have included it simply to be the most basic operation possible. POP \u2013 this is our first modification of the stack. It simply discards the topmost value, decreasing the stack's size by one. PUSH_U8 \u2013 this is the only operation that reads additional data from the program. It only reads a single byte (increasing the program counter by one), and puts it on top of the stack, increasing the stack's size by one. This is how you can get data from your program into the VM, to work with them. It is how numeric literals in your program are handled. ADD \u2013 the only operation that works on data. It pops its two operands from the stack, adds them, and pushes the sum back on the stack. This is how data is manipulated in a stack machine. The operation reduces the stack's size by one effectively, but there need to be at least 2 values on it for it to be executed. That is the out complete VM so far, and it will execute a program, if you compile and run it (which we will do in the next post). You can find the complete program here: https://github.com/kratenko/lovem/blob/v0.0.1-journey/src/main.rs You can access the repo at this state under (there is also a zip file containing all files): https://github.com/kratenko/lovem/releases/tag/v0.0.1-journey","title":"Behaviour for our VM"},{"location":"2022-07/a-vm.html#how-do-i-work-with-the-code","text":"The easy way, to get the code and play with it, would be to clone the git repository and check out the tag v0.0.1-journey . If you did not understand any of that, you might want to do a tutorial on git, before you continue reading. Anyways, here is some copy&paste commands, you can hack into your bash prompt, to do, what I just told you to do. Use at your own risk, I'm not responsible for what you do to your system. you@host:~$ git clone https://github.com/kratenko/lovem.git you@host:~$ cd lovem you@host:~/lovem$ git checkout v0.0.1-journey you@host:~/lovam$ cargo run lovem This will copy all source code from GitHub and its history to your computer, and it will roll the source code to the state we are looking at in this entry. The last command cargo run lovem will compile and execute the program - that is, if Rust is installed and ready to run (and in the correct version). cargo is Rust's package manager, that handles dependencies and compiles your projects. I will not explain those things further, but now you know what to look for. Don't let yourself be confused by fancy terms like register . You can think of it as a kind of snobbish variable with a special meaning. In computers sometimes stuff magically happens when you write to a register \u2013 but it should always be documented somewhere. \u21a9","title":"How do I work with the code?"},{"location":"2022-07/all-new-once-more.html","text":"All new once more \u00b6 Reality strikes again, and code will be written from scratch once more. And the reason is this site. kratenko \u00b7 kratenko 2022-07-03 \u00b7 Entry #6 \u00b7 < 1 min read You want me to get to the code. And I really should. I have written so much already, and I want to show it, but there is so much around it. And after I had written up a long text on how I started, I realised that I had no commits during the early state. So I had to write it all again, slower, and with code to be presentable in this journal. If you are reading this live (and no-one is, because I did not even tell anyone I am doing this), you can of course look at the code I was writing earlier, it exists. I put it in a branch too-early . But I will not give explanations to that. I am rewriting it on the master branch, and that will be showed and discussed in the journal. I advise you to wait for that. Yes, it will take a while. As it looks now, it will be slow. But I have written some new posts on the new code already, and I think it is worth it. There will be more background before we get there. Next entry will be a longer one, so there is that.","title":" All new once more"},{"location":"2022-07/all-new-once-more.html#all-new-once-more","text":"Reality strikes again, and code will be written from scratch once more. And the reason is this site. kratenko \u00b7 kratenko 2022-07-03 \u00b7 Entry #6 \u00b7 < 1 min read You want me to get to the code. And I really should. I have written so much already, and I want to show it, but there is so much around it. And after I had written up a long text on how I started, I realised that I had no commits during the early state. So I had to write it all again, slower, and with code to be presentable in this journal. If you are reading this live (and no-one is, because I did not even tell anyone I am doing this), you can of course look at the code I was writing earlier, it exists. I put it in a branch too-early . But I will not give explanations to that. I am rewriting it on the master branch, and that will be showed and discussed in the journal. I advise you to wait for that. Yes, it will take a while. As it looks now, it will be slow. But I have written some new posts on the new code already, and I think it is worth it. There will be more background before we get there. Next entry will be a longer one, so there is that.","title":"All new once more"},{"location":"2022-07/assemble.html","text":"Assemble! \u00b6 We introduce an API for assembly to our lovem library. kratenko \u00b7 kratenko 2022-07-26 \u00b7 Entry #21 \u00b7 5 min read \u00b7 v0.0.8-journey Last time, we built the frame of a command line program, that will become our new assembler, lovas . It is time that we give that program the power to assemble. Calling the real assembler \u00b6 lovas.rs is just the executable wrapper around the actual assembler, that will live inside the library. All lovas.rs does, is supply the command line interface. And that CLI-part does not belong in a library function. We got it nicely separated. And programs using the library can assemble source to bytecode themselves, without calling an external binary. We alter lovas.rs a bit. The part that just printed out the source lines is gone. We replace it with a call to a new library function, that can transfer assembly code into bytecode: fn main () -> Result < () > { .. . the same as before .. . // run the assembler: match asm :: assemble ( & name , & content ) { Ok ( pgm ) => { // we succeeded and now have a program with bytecode: println! ( \"{:?}\" , pgm ); Ok (()) }, Err ( e ) => { // Something went wrong during assembly. // Convert the error report, so that `anyhow` can do its magic // and display some helpful error message: Err ( Error :: from ( e )) }, } } The important part is the call to asm::assemble(&name, &constent) . We created a new module asm inside our lib. It exposes only a single function assemble and a few types for error handling. There will be a lot to unpack inside that module. The good news for us is: we do not need to restrain ourselves as much as we do in the VM itself. Resource usage is not really an issue here, because the assembler is not meant to run in a restricted environment. The idea of lovem is, that you write your programs elsewhere, outside the restricted environment, and only run the compiled bytecode in the VM on the restricted device. And since the scope handled by the assembler will still be defined by that restricted device, we expect to only write relatively small and simple programs. With modern computers used for assembling, we can use as much memory as we want. Oh, by the way... Yeah, I seem to stick to these short, cryptic names for the parts of lovem . VM , Pgm , op , asm - I kinda like it that way, and it goes well with the register names etc. That feels right for something as low-lever as a VM. And I give my best to always document those things properly, so that your IDE of choice will always show you, what each thing is. ASM \u00b6 I wrote a very basic assembler inside asm.rs , and it is already over 250 lines long. Quite a lot to unpack. As before, I try to explain as much as possible inside the source code itself, using comments. This makes it easier to follow, and you can even do so inside the source in the repo, without reading this blog. There are four types that I introduce inside the mod: /// Errors that can happen during assembly. #[derive(Debug, Clone)] pub enum AsmError { InvalidLine , UnknownInstruction ( String ), UnexpectedArgument , MissingArgument , InvalidArgument , } /// Report of failed assembly attempt. /// /// Wraps the error that occurred during assembly and supplied information where it did. #[derive(Debug)] pub struct AsmErrorReport { /// Name of the program that failed to assemble. name : String , /// Line the error occurred during assembly. line : usize , /// Error that occurred. error : AsmError , } /// A single instruction parsed from the line of an assembly program. #[derive(Debug)] struct AsmInstruction { /// Number of line the instruction was read from. /// /// The number of the line the instruction was taken from, most likely /// from a source file. Line counting starts at 1. line_number : usize , /// Opcode defining which operation is to be executed. opcode : u8 , /// Arguments used for execution of the operation. /// /// Zero or more bytes. oparg : Vec < u8 > , /// Position inside bytecode (starting at 0). /// /// Number of bytes that come before this instruction in the program. pos : usize , } /// A assembler program during parsing/assembling. #[derive(Debug)] struct AsmPgm { /// Name of the program (just a string supplied by caller). name : String , /// Vector of parsed assembler instructions, in the order they are in the source file. instructions : Vec < AsmInstruction > , /// Current line number during parsing. /// /// Used for error reporting. line_number : usize , /// Current position inside bytecode during parsing. /// /// Used to calculate the exact position an instruction will be in the bytecode. text_pos : usize , /// The error that happened during parsing/assembling, if any. error : Option < AsmError > , } AsmError is easy enough to understand. We used the same idea for the RuntimeError inside the VM. When we run into an Error while trying to assemble the program, we return Err<AsmError> instead of Ok(()) , so that we can propagate what happened back to the caller. The nice thing is, that with speaking names for the enum values, and with the occasional embedded value (as in UnknownInstruction(String) ), the debug representation of the AsmError alone is enough to make the user understand what error was detected. AsmErrorReport is a little wrapper we use to add the information where we ran into an error. InvalidArgument is nice hint how to fix your program - but if that program is 2000 lines long, then good luck. When you know the InvalidArgument happened in line 1337, then you will find it much faster. Especially in an assembly language, that has never more than one single instruction per line. AsmInstruction is used to represent a single instruction inside a program. So each instance of this type will be linked to a specific line in the source file. If you don't remember, what counts as an instruction in lovem (at least at the time of writing), let me repeat: an instruction consists of exactly one operation that is to be executed, which is identified by its opcode (which is a number from 0x00 to 0xff stored in a single byte). Each instruction has zero or more bytes used as an argument, defining how the operation is to be executed. This argument is called oparg . We will also store the number of the line we found our instruction inside the source code, and the position inside the bytecode where the instruction will be. AsmPgm will represent the complete program during the assembly process. We will collect the instructions we parse from the source in there in a Vector. And we will hold the progress during parsing/assembling. This is not the type that will be returned to the caller, it is only used internally (as you can guess by the fact that it is not defined pub ). Where does the program come from? \u00b6 The only function the mod exports it assemble : /// Parse assembly source code and turn it into a runnable program (or create report). pub fn assemble ( name : & str , content : & str ) -> Result < Pgm , AsmErrorReport > { let asm_pgm = AsmPgm :: parse ( name , content ); asm_pgm . to_program () } It will return an AsmErrorReport , if anything goes wrong and the assembling fails. If the assembler succeeds, it returns an instance of Pgm . Now where does that come from? Our VM takes programs in form of a &[u8] . That will be changed soon, and then it will run programs from a special type Pgm that might have a bit more than just bytecode. I added another new module to the library: pgm.rs . That one is tiny and only holds the new struct Pgm \u2013 which itself is basic. But we have a type that holds a program, now. I believe that will be beneficial to us later. /// Holds a program to be executed in VM. #[derive(Debug)] pub struct Pgm { /// Some name identifying the program. pub name : String , /// Bytecode holding the programs instructions. pub text : Vec < u8 > , } What is it, that the assembler does, to create such a Pgm . We will start to go through that in the next entry. This has been enough for today. The source code for this post can be found under the tag v0.0.8-journey . v0.0.8-journey source code v0.0.8-journey release v0.0.8-journey.zip v0.0.8-journey.tar.gz git checkout v0.0.8-journey What does this mean?","title":" Assemble!"},{"location":"2022-07/assemble.html#assemble","text":"We introduce an API for assembly to our lovem library. kratenko \u00b7 kratenko 2022-07-26 \u00b7 Entry #21 \u00b7 5 min read \u00b7 v0.0.8-journey Last time, we built the frame of a command line program, that will become our new assembler, lovas . It is time that we give that program the power to assemble.","title":"Assemble!"},{"location":"2022-07/assemble.html#calling-the-real-assembler","text":"lovas.rs is just the executable wrapper around the actual assembler, that will live inside the library. All lovas.rs does, is supply the command line interface. And that CLI-part does not belong in a library function. We got it nicely separated. And programs using the library can assemble source to bytecode themselves, without calling an external binary. We alter lovas.rs a bit. The part that just printed out the source lines is gone. We replace it with a call to a new library function, that can transfer assembly code into bytecode: fn main () -> Result < () > { .. . the same as before .. . // run the assembler: match asm :: assemble ( & name , & content ) { Ok ( pgm ) => { // we succeeded and now have a program with bytecode: println! ( \"{:?}\" , pgm ); Ok (()) }, Err ( e ) => { // Something went wrong during assembly. // Convert the error report, so that `anyhow` can do its magic // and display some helpful error message: Err ( Error :: from ( e )) }, } } The important part is the call to asm::assemble(&name, &constent) . We created a new module asm inside our lib. It exposes only a single function assemble and a few types for error handling. There will be a lot to unpack inside that module. The good news for us is: we do not need to restrain ourselves as much as we do in the VM itself. Resource usage is not really an issue here, because the assembler is not meant to run in a restricted environment. The idea of lovem is, that you write your programs elsewhere, outside the restricted environment, and only run the compiled bytecode in the VM on the restricted device. And since the scope handled by the assembler will still be defined by that restricted device, we expect to only write relatively small and simple programs. With modern computers used for assembling, we can use as much memory as we want. Oh, by the way... Yeah, I seem to stick to these short, cryptic names for the parts of lovem . VM , Pgm , op , asm - I kinda like it that way, and it goes well with the register names etc. That feels right for something as low-lever as a VM. And I give my best to always document those things properly, so that your IDE of choice will always show you, what each thing is.","title":"Calling the real assembler"},{"location":"2022-07/assemble.html#asm","text":"I wrote a very basic assembler inside asm.rs , and it is already over 250 lines long. Quite a lot to unpack. As before, I try to explain as much as possible inside the source code itself, using comments. This makes it easier to follow, and you can even do so inside the source in the repo, without reading this blog. There are four types that I introduce inside the mod: /// Errors that can happen during assembly. #[derive(Debug, Clone)] pub enum AsmError { InvalidLine , UnknownInstruction ( String ), UnexpectedArgument , MissingArgument , InvalidArgument , } /// Report of failed assembly attempt. /// /// Wraps the error that occurred during assembly and supplied information where it did. #[derive(Debug)] pub struct AsmErrorReport { /// Name of the program that failed to assemble. name : String , /// Line the error occurred during assembly. line : usize , /// Error that occurred. error : AsmError , } /// A single instruction parsed from the line of an assembly program. #[derive(Debug)] struct AsmInstruction { /// Number of line the instruction was read from. /// /// The number of the line the instruction was taken from, most likely /// from a source file. Line counting starts at 1. line_number : usize , /// Opcode defining which operation is to be executed. opcode : u8 , /// Arguments used for execution of the operation. /// /// Zero or more bytes. oparg : Vec < u8 > , /// Position inside bytecode (starting at 0). /// /// Number of bytes that come before this instruction in the program. pos : usize , } /// A assembler program during parsing/assembling. #[derive(Debug)] struct AsmPgm { /// Name of the program (just a string supplied by caller). name : String , /// Vector of parsed assembler instructions, in the order they are in the source file. instructions : Vec < AsmInstruction > , /// Current line number during parsing. /// /// Used for error reporting. line_number : usize , /// Current position inside bytecode during parsing. /// /// Used to calculate the exact position an instruction will be in the bytecode. text_pos : usize , /// The error that happened during parsing/assembling, if any. error : Option < AsmError > , } AsmError is easy enough to understand. We used the same idea for the RuntimeError inside the VM. When we run into an Error while trying to assemble the program, we return Err<AsmError> instead of Ok(()) , so that we can propagate what happened back to the caller. The nice thing is, that with speaking names for the enum values, and with the occasional embedded value (as in UnknownInstruction(String) ), the debug representation of the AsmError alone is enough to make the user understand what error was detected. AsmErrorReport is a little wrapper we use to add the information where we ran into an error. InvalidArgument is nice hint how to fix your program - but if that program is 2000 lines long, then good luck. When you know the InvalidArgument happened in line 1337, then you will find it much faster. Especially in an assembly language, that has never more than one single instruction per line. AsmInstruction is used to represent a single instruction inside a program. So each instance of this type will be linked to a specific line in the source file. If you don't remember, what counts as an instruction in lovem (at least at the time of writing), let me repeat: an instruction consists of exactly one operation that is to be executed, which is identified by its opcode (which is a number from 0x00 to 0xff stored in a single byte). Each instruction has zero or more bytes used as an argument, defining how the operation is to be executed. This argument is called oparg . We will also store the number of the line we found our instruction inside the source code, and the position inside the bytecode where the instruction will be. AsmPgm will represent the complete program during the assembly process. We will collect the instructions we parse from the source in there in a Vector. And we will hold the progress during parsing/assembling. This is not the type that will be returned to the caller, it is only used internally (as you can guess by the fact that it is not defined pub ).","title":"ASM"},{"location":"2022-07/assemble.html#where-does-the-program-come-from","text":"The only function the mod exports it assemble : /// Parse assembly source code and turn it into a runnable program (or create report). pub fn assemble ( name : & str , content : & str ) -> Result < Pgm , AsmErrorReport > { let asm_pgm = AsmPgm :: parse ( name , content ); asm_pgm . to_program () } It will return an AsmErrorReport , if anything goes wrong and the assembling fails. If the assembler succeeds, it returns an instance of Pgm . Now where does that come from? Our VM takes programs in form of a &[u8] . That will be changed soon, and then it will run programs from a special type Pgm that might have a bit more than just bytecode. I added another new module to the library: pgm.rs . That one is tiny and only holds the new struct Pgm \u2013 which itself is basic. But we have a type that holds a program, now. I believe that will be beneficial to us later. /// Holds a program to be executed in VM. #[derive(Debug)] pub struct Pgm { /// Some name identifying the program. pub name : String , /// Bytecode holding the programs instructions. pub text : Vec < u8 > , } What is it, that the assembler does, to create such a Pgm . We will start to go through that in the next entry. This has been enough for today. The source code for this post can be found under the tag v0.0.8-journey . v0.0.8-journey source code v0.0.8-journey release v0.0.8-journey.zip v0.0.8-journey.tar.gz git checkout v0.0.8-journey What does this mean?","title":"Where does the program come from?"},{"location":"2022-07/becoming-social.html","text":"Becoming social \u00b6 A new way for you to participate in my journey. kratenko \u00b7 kratenko 2022-07-15 \u00b7 Entry #14 \u00b7 < 1 min read After a few days of progress on the project itself, I spent a bit of time on the site again. We have the fancy link to our GitHub repo in the upper right corner now. But more important, I added support for comments on my entries. You can now react and ask questions or share your thought. I am using giscus.app (and, again, I copied that idea from @squidfunk and their site on mkdocs-material , which is what I did for this complete site, more or less). Giscus is an open source app that stores the comments completely inside GitHub discussions, so the content is stored along the lovem repository and at the one place where everything is stored already anyway. If you want to participate in the comments, you need to log in using your GitHub account. That is great, because I don't need to care about user management, nor about any database. Feel free to use this entry to try out the new feature, because that is what I am gonna do!","title":" Becoming social"},{"location":"2022-07/becoming-social.html#becoming-social","text":"A new way for you to participate in my journey. kratenko \u00b7 kratenko 2022-07-15 \u00b7 Entry #14 \u00b7 < 1 min read After a few days of progress on the project itself, I spent a bit of time on the site again. We have the fancy link to our GitHub repo in the upper right corner now. But more important, I added support for comments on my entries. You can now react and ask questions or share your thought. I am using giscus.app (and, again, I copied that idea from @squidfunk and their site on mkdocs-material , which is what I did for this complete site, more or less). Giscus is an open source app that stores the comments completely inside GitHub discussions, so the content is stored along the lovem repository and at the one place where everything is stored already anyway. If you want to participate in the comments, you need to log in using your GitHub account. That is great, because I don't need to care about user management, nor about any database. Feel free to use this entry to try out the new feature, because that is what I am gonna do!","title":"Becoming social"},{"location":"2022-07/don-t-byte-me.html","text":"Don't byte me! \u00b6 I have had it with these motherloving bytes in this motherloving bytecode! kratenko \u00b7 kratenko 2022-07-25 \u00b7 Entry #20 \u00b7 5 min read \u00b7 v0.0.7-journey By now you should have come to a realisation: writing bytecode sucks! It wasn't fun to begin with, but now that we introduce jumps in our code, we need to count how many bytes the jump takes \u2013 and that with instructions that have different numbers of bytes as opargs. Encoding negative numbers in bytes is also no fun. And just think about it: if you change your program (e.g. add a few instructions), you have to adjust those relative jumps! How horrible is that? Can't someone else do it? Well, yeah, of course. We invented a machine that can do annoying and monotone tasks that require accuracy and that must be done over and over again. That machine is, of course, the computer. Well, lucky us, that we know how to tell a computer what it should do. So let's write a program, that writes bytecode for us. I am not talking about compiling a programming language into our VM; at least not yet, not for a long time. But something that lets us write those instructions in a way that is at least a bit more human friendly. Maybe you remember that I already tried to write some of the bytecode programs I showed you in a more readable way, like this: push_u8 5 push_u8 7 push_u8 11 sub mul push_u8 13 push_u8 17 add add pop fin If that did remind you of something, that might be no coincidence. Assembler \u00b6 The listing up there looks a bit like assembler code. And on the earlier draft of lovem I did already write a program that could translate those listings into bytecode. We will do that again, together. But this will take us some time (that is, multiple journal entries). We need to acquire some additional Rust skills for that. And there is so much to explain inside that assembler program itself. Once again, I am making this up along the way. Yes, I have a plan, but I will just start to introduce syntax for the assembler, and it might not be ideal. That means, I might change it all again later. As the VM itself, our assembler will be experimental. You are welcome to give me ideas for the syntax; we do have the comments now, unter each post, feel free to use them. There is the whole GitHub discussions page as well. And you can still find me on Twitter. Find the link at the bottom of this page. Command line tool \u00b6 The assembler will be a binary that you call with parameters. A typical command line tool, just like gcc or rustc are. So what we need to do, is to learn how one writes a command line tool in Rust. One that can read files, because I plan to write assembly programs in text files. And I have no desire to start parsing command line arguments myself. Neither do I want to write an introduction on writing command line tools in Rust. All this has been done. So I kindly direct you to an online book: Command Line Applications in Rust . That is where I got what I will be using here. They use a crate called clap , which seems to be the most used lib for building command line tools in Rust. It takes about 10 minutes to read. Finding out how to use the options of clap that I want took longer, but that will not be a thing for you, as I will just be using those options. This is the first time we are using external crates in Rust. We need to add our dependencies to Cargo.toml , before we can use them: [dependencies] clap = { version = \"3.2.12\" , features = [ \"derive\" ] } anyhow = \"1.0.58\" Introducing lovas \u00b6 Now let us start with the assembler. We create a new binary that will become our assembler: lovas.rs //! An experimental assembler for lovem use clap :: Parser ; use anyhow :: { Context , Result }; /// Struct used to declare the command line tool behaviour using clap. /// /// This defines the arguments and options the tool provides. It is also used to /// generate the instructions you get when calling it with `--help`. #[derive(Parser, Debug)] #[clap(name = \"lovas\" , long_about = \"An experimental assembler for lovem, the Low Overhead Virtual Embedded Machine.\" , )] struct Cli { #[clap(parse(from_os_str), help = \"Path to assembler source file.\" )] source : std :: path :: PathBuf , } fn main () -> Result < () > { // read, validate, and evaluate command line parameters: let args = Cli :: parse (); // read complete source file into String: let content = std :: fs :: read_to_string ( & args . source ) . with_context ( || format! ( \"could not read file `{}`\" , args . source . as_path (). display (). to_string ()) ) ? ; // For now, just print our all the lines in the file: for ( n , line ) in content . lines (). enumerate () { println! ( \"{:4}: '{}'\" , n + 1 , line ); } // We succeeded in our work, so return Ok() as a Result: Ok (()) } As it happens with Rust, the code is very dense. I try to explain what I do inside the code using comments. This does not look like it does too much. Yet it does. You can call it using cargo run --bin lovas , as we learned earlier: kratenko@jotun:~/git/lovem$ cargo run --bin lovas Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas` error: The following required arguments were not provided: <SOURCE> USAGE: lovas <SOURCE> For more information try --help That is already a lot! It finds out that you did not supply a required argument and tells you in a somewhat understandable error message. We did not write any of that. And it even directs you how to get help: add --help to your call. Now if we use cargo to run our binary, we need to add an extra bit to the call, because we need to tell cargo where its own arguments end, end where the arguments to the called binary begin. This is done (as it is custom) by adding -- , to indicate the end of cargo's arguments. So if we want to pass --help to lovas, we can do it like this: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- --help Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas --help` lovas An experimental assembler for lovem, the Low Overhead Virtual Embedded Machine. USAGE: lovas <SOURCE> ARGS: <SOURCE> Path to assembler source file. OPTIONS: -h, --help Print help information How helpful! Also, now you can see why I added those two strings to our Cli struct; they show up in the help message. Run it \u00b6 It looks like we need to give it a file to read, if we want the program to succeed and not exit with an error. I did write a little assembly program that we can use: hallo-stack.lass . Our assembler will not so anything too useful with it, because we did not write an assembler, yet. It will simply print out the lines of the file, prefixed with the line number (the call to .enumerate() is what I use to count the lines, while iterating over them). kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- pgm/hallo-stack.lass Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas pgm/hallo-stack.lass` 1: 'push_u8 123' 2: 'push_u8 200' 3: 'add' 4: 'pop' 5: 'fin' Neat! I feel this is a lot for such a small program! It is also enough for this journal entry. We will be working on lovas for a bit, now. Homework \u00b6 Well - if you have not done so, read the book I linked. At least up until chapter 1.4, I guess, that is what we need for now. And try to trigger some errors when calling lovas . What if the file you tell it to open does not exist? What if it cannot be read? Do you understand how those error messages propagate through the program and end up as a readable message in your console? The source code for this post can be found under the tag v0.0.7-journey . v0.0.7-journey source code v0.0.7-journey release v0.0.7-journey.zip v0.0.7-journey.tar.gz git checkout v0.0.7-journey What does this mean?","title":" Don't byte me!"},{"location":"2022-07/don-t-byte-me.html#dont-byte-me","text":"I have had it with these motherloving bytes in this motherloving bytecode! kratenko \u00b7 kratenko 2022-07-25 \u00b7 Entry #20 \u00b7 5 min read \u00b7 v0.0.7-journey By now you should have come to a realisation: writing bytecode sucks! It wasn't fun to begin with, but now that we introduce jumps in our code, we need to count how many bytes the jump takes \u2013 and that with instructions that have different numbers of bytes as opargs. Encoding negative numbers in bytes is also no fun. And just think about it: if you change your program (e.g. add a few instructions), you have to adjust those relative jumps! How horrible is that? Can't someone else do it? Well, yeah, of course. We invented a machine that can do annoying and monotone tasks that require accuracy and that must be done over and over again. That machine is, of course, the computer. Well, lucky us, that we know how to tell a computer what it should do. So let's write a program, that writes bytecode for us. I am not talking about compiling a programming language into our VM; at least not yet, not for a long time. But something that lets us write those instructions in a way that is at least a bit more human friendly. Maybe you remember that I already tried to write some of the bytecode programs I showed you in a more readable way, like this: push_u8 5 push_u8 7 push_u8 11 sub mul push_u8 13 push_u8 17 add add pop fin If that did remind you of something, that might be no coincidence.","title":"Don't byte me!"},{"location":"2022-07/don-t-byte-me.html#assembler","text":"The listing up there looks a bit like assembler code. And on the earlier draft of lovem I did already write a program that could translate those listings into bytecode. We will do that again, together. But this will take us some time (that is, multiple journal entries). We need to acquire some additional Rust skills for that. And there is so much to explain inside that assembler program itself. Once again, I am making this up along the way. Yes, I have a plan, but I will just start to introduce syntax for the assembler, and it might not be ideal. That means, I might change it all again later. As the VM itself, our assembler will be experimental. You are welcome to give me ideas for the syntax; we do have the comments now, unter each post, feel free to use them. There is the whole GitHub discussions page as well. And you can still find me on Twitter. Find the link at the bottom of this page.","title":"Assembler"},{"location":"2022-07/don-t-byte-me.html#command-line-tool","text":"The assembler will be a binary that you call with parameters. A typical command line tool, just like gcc or rustc are. So what we need to do, is to learn how one writes a command line tool in Rust. One that can read files, because I plan to write assembly programs in text files. And I have no desire to start parsing command line arguments myself. Neither do I want to write an introduction on writing command line tools in Rust. All this has been done. So I kindly direct you to an online book: Command Line Applications in Rust . That is where I got what I will be using here. They use a crate called clap , which seems to be the most used lib for building command line tools in Rust. It takes about 10 minutes to read. Finding out how to use the options of clap that I want took longer, but that will not be a thing for you, as I will just be using those options. This is the first time we are using external crates in Rust. We need to add our dependencies to Cargo.toml , before we can use them: [dependencies] clap = { version = \"3.2.12\" , features = [ \"derive\" ] } anyhow = \"1.0.58\"","title":"Command line tool"},{"location":"2022-07/don-t-byte-me.html#introducing-lovas","text":"Now let us start with the assembler. We create a new binary that will become our assembler: lovas.rs //! An experimental assembler for lovem use clap :: Parser ; use anyhow :: { Context , Result }; /// Struct used to declare the command line tool behaviour using clap. /// /// This defines the arguments and options the tool provides. It is also used to /// generate the instructions you get when calling it with `--help`. #[derive(Parser, Debug)] #[clap(name = \"lovas\" , long_about = \"An experimental assembler for lovem, the Low Overhead Virtual Embedded Machine.\" , )] struct Cli { #[clap(parse(from_os_str), help = \"Path to assembler source file.\" )] source : std :: path :: PathBuf , } fn main () -> Result < () > { // read, validate, and evaluate command line parameters: let args = Cli :: parse (); // read complete source file into String: let content = std :: fs :: read_to_string ( & args . source ) . with_context ( || format! ( \"could not read file `{}`\" , args . source . as_path (). display (). to_string ()) ) ? ; // For now, just print our all the lines in the file: for ( n , line ) in content . lines (). enumerate () { println! ( \"{:4}: '{}'\" , n + 1 , line ); } // We succeeded in our work, so return Ok() as a Result: Ok (()) } As it happens with Rust, the code is very dense. I try to explain what I do inside the code using comments. This does not look like it does too much. Yet it does. You can call it using cargo run --bin lovas , as we learned earlier: kratenko@jotun:~/git/lovem$ cargo run --bin lovas Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas` error: The following required arguments were not provided: <SOURCE> USAGE: lovas <SOURCE> For more information try --help That is already a lot! It finds out that you did not supply a required argument and tells you in a somewhat understandable error message. We did not write any of that. And it even directs you how to get help: add --help to your call. Now if we use cargo to run our binary, we need to add an extra bit to the call, because we need to tell cargo where its own arguments end, end where the arguments to the called binary begin. This is done (as it is custom) by adding -- , to indicate the end of cargo's arguments. So if we want to pass --help to lovas, we can do it like this: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- --help Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas --help` lovas An experimental assembler for lovem, the Low Overhead Virtual Embedded Machine. USAGE: lovas <SOURCE> ARGS: <SOURCE> Path to assembler source file. OPTIONS: -h, --help Print help information How helpful! Also, now you can see why I added those two strings to our Cli struct; they show up in the help message.","title":"Introducing lovas"},{"location":"2022-07/don-t-byte-me.html#run-it","text":"It looks like we need to give it a file to read, if we want the program to succeed and not exit with an error. I did write a little assembly program that we can use: hallo-stack.lass . Our assembler will not so anything too useful with it, because we did not write an assembler, yet. It will simply print out the lines of the file, prefixed with the line number (the call to .enumerate() is what I use to count the lines, while iterating over them). kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- pgm/hallo-stack.lass Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas pgm/hallo-stack.lass` 1: 'push_u8 123' 2: 'push_u8 200' 3: 'add' 4: 'pop' 5: 'fin' Neat! I feel this is a lot for such a small program! It is also enough for this journal entry. We will be working on lovas for a bit, now.","title":"Run it"},{"location":"2022-07/don-t-byte-me.html#homework","text":"Well - if you have not done so, read the book I linked. At least up until chapter 1.4, I guess, that is what we need for now. And try to trigger some errors when calling lovas . What if the file you tell it to open does not exist? What if it cannot be read? Do you understand how those error messages propagate through the program and end up as a readable message in your console? The source code for this post can be found under the tag v0.0.7-journey . v0.0.7-journey source code v0.0.7-journey release v0.0.7-journey.zip v0.0.7-journey.tar.gz git checkout v0.0.7-journey What does this mean?","title":"Homework"},{"location":"2022-07/early-vm-decisions.html","text":"Early VM decisions \u00b6 Many design decisions must be made for lovem. Here I talk about some of those in the current state. kratenko \u00b7 kratenko 2022-07-19 \u00b7 Entry #16 \u00b7 3 min read \u00b7 v0.0.3-journey I have shared and discussed source code in the recent posts. Now it is time again, to write about design decisions. I made a few of them for the code you saw. So far I have not been reasoning about those here, and some of you might have wondered already. Let's talk about them. Let me remind you: lovem is a research project for myself. And an education project for myself as well. None of my choices at this stage are set into stone. I will make lots of mistakes that I will be changing later. I even choose some paths, that I know I will be leaving again. I might just take any solution for a problem, at this stage, as I do not know, what is the right choice. So start somewhere, see where it goes. Some of those are deliberately weird or bad choices, but they make things clearer or simpler at this stage. Let us address two of those choices you can find in the current source code. Word size \u00b6 I talked about register sizes defining architecture, back in What is a Virtual Machine anyway? . And then I went totally silent about that topic and just used i64 as type for my stack. Is that a good idea? I used it for simplicity. The idea goes back to when I was experimenting with using a register machine for lovem. Having a simple datatype that can handle big values seems simple. After all, other languages/VMs use some version of float as their single numeric datatype: JavaScript JavaScript Numbers are Always 64-bit Floating Point Unlike many other programming languages, JavaScript does not define different types of numbers, like integers, short, long, floating-point etc. JavaScript numbers are always stored as double precision floating point numbers, following the international IEEE 754 standard. \u2014 w3schools.com - retrieved 2022-07-11 Lua 2.3 - Numbers The number type represents real (double-precision floating-point) numbers. Lua has no integer type, as it does not need it. \u2014 Programming in Lua - retrieved 2022-07-11 Well, reducing complexity is good. But having each little number you use in your programs eat up 8 bytes of memory does not sound low overhead to me. And that is, after all, the goal. So I guess, that will change in the future. But let's keep it for the time being. There will be some interesting things we will be doing in the near future; even if we might dump those features later. I already implemented them during the early phase (when I was not writing a public journal), so not adding them here would be insincere. Having 64 bit values is a part of our journey. Opargs \u00b6 I have no glossary, yet, so you have to live with me inventing terms on the spot. I used that word in the source code already. What I mean by it, are the arguments to an instruction inside the bytecode, that follow the opcode and influence the operation. They are the arguments you give inside your program's code. As of v0.0.3-journey we only have a single opcode that takes an oparg, and that is push_u8 . You can see how there is a fetch_u8() instruction in the code that handles that operation, and none in the other operations. See execute_op . So we have different behaviour depending on the opcode. push_u8 fetches an additional byte from the bytecode, the other opcodes do not. Existing VMs handle this differently. The Java VM, for example, has a dynamic number of opargs, too. They call them operands : 2.11. Instruction Set Summary A Java Virtual Machine instruction consists of a one-byte opcode specifying the operation to be performed, followed by zero or more operands supplying arguments or data that are used by the operation. Many instructions have no operands and consist only of an opcode. \u2014 The Java\u00ae Virtual Machine Specification - Java SE 8 Edition - retrieved 2022-07-11 The Python VM on the other hand, uses exactly one byte as oparg on all instructions The bytecode can be thought of as a series of instructions or a low-level program for the Python interpreter. After version 3.6, Python uses 2 bytes for each instruction. One byte is for the code of that instruction which is called an opcode , and one byte is reserved for its argument which is called the oparg . [...] Some instructions do not need an argument, so they ignore the byte after the opcode. The opcodes which have a value below a certain number ignore their argument. This value is stored in dis.HAVE_ARGUMENT and is currently equal to 90. So the opcodes >= dis.HAVE_ARGUMENT have an argument, and the opcodes < dis.HAVE_ARGUMENT ignore it. \u2014 Reza Bagheri - Understanding Python Bytecode - in Towards Data Science - retrieved 2022-07-11 That does remove some complexity. And adds new complexity - for opcodes with more than one oparg byte - they exist in python and are handled with a special opcode, that adds an additional oparg byte. I think it will make execution faster, as fetching can be done it advance. If you do not know, how many bytes you need, before your read your opcode, you cannot prefetch the next instructions. For our goal, keeping the bytecode small is much more important than execution time. So I am pretty sure we will stick with the dynamic number of oparg bytes in lovem. The source code for this post can be found under the tag v0.0.3-journey . v0.0.3-journey source code v0.0.3-journey release v0.0.3-journey.zip v0.0.3-journey.tar.gz git checkout v0.0.3-journey What does this mean?","title":" Early VM decisions"},{"location":"2022-07/early-vm-decisions.html#early-vm-decisions","text":"Many design decisions must be made for lovem. Here I talk about some of those in the current state. kratenko \u00b7 kratenko 2022-07-19 \u00b7 Entry #16 \u00b7 3 min read \u00b7 v0.0.3-journey I have shared and discussed source code in the recent posts. Now it is time again, to write about design decisions. I made a few of them for the code you saw. So far I have not been reasoning about those here, and some of you might have wondered already. Let's talk about them. Let me remind you: lovem is a research project for myself. And an education project for myself as well. None of my choices at this stage are set into stone. I will make lots of mistakes that I will be changing later. I even choose some paths, that I know I will be leaving again. I might just take any solution for a problem, at this stage, as I do not know, what is the right choice. So start somewhere, see where it goes. Some of those are deliberately weird or bad choices, but they make things clearer or simpler at this stage. Let us address two of those choices you can find in the current source code.","title":"Early VM decisions"},{"location":"2022-07/early-vm-decisions.html#word-size","text":"I talked about register sizes defining architecture, back in What is a Virtual Machine anyway? . And then I went totally silent about that topic and just used i64 as type for my stack. Is that a good idea? I used it for simplicity. The idea goes back to when I was experimenting with using a register machine for lovem. Having a simple datatype that can handle big values seems simple. After all, other languages/VMs use some version of float as their single numeric datatype: JavaScript JavaScript Numbers are Always 64-bit Floating Point Unlike many other programming languages, JavaScript does not define different types of numbers, like integers, short, long, floating-point etc. JavaScript numbers are always stored as double precision floating point numbers, following the international IEEE 754 standard. \u2014 w3schools.com - retrieved 2022-07-11 Lua 2.3 - Numbers The number type represents real (double-precision floating-point) numbers. Lua has no integer type, as it does not need it. \u2014 Programming in Lua - retrieved 2022-07-11 Well, reducing complexity is good. But having each little number you use in your programs eat up 8 bytes of memory does not sound low overhead to me. And that is, after all, the goal. So I guess, that will change in the future. But let's keep it for the time being. There will be some interesting things we will be doing in the near future; even if we might dump those features later. I already implemented them during the early phase (when I was not writing a public journal), so not adding them here would be insincere. Having 64 bit values is a part of our journey.","title":"Word size"},{"location":"2022-07/early-vm-decisions.html#opargs","text":"I have no glossary, yet, so you have to live with me inventing terms on the spot. I used that word in the source code already. What I mean by it, are the arguments to an instruction inside the bytecode, that follow the opcode and influence the operation. They are the arguments you give inside your program's code. As of v0.0.3-journey we only have a single opcode that takes an oparg, and that is push_u8 . You can see how there is a fetch_u8() instruction in the code that handles that operation, and none in the other operations. See execute_op . So we have different behaviour depending on the opcode. push_u8 fetches an additional byte from the bytecode, the other opcodes do not. Existing VMs handle this differently. The Java VM, for example, has a dynamic number of opargs, too. They call them operands : 2.11. Instruction Set Summary A Java Virtual Machine instruction consists of a one-byte opcode specifying the operation to be performed, followed by zero or more operands supplying arguments or data that are used by the operation. Many instructions have no operands and consist only of an opcode. \u2014 The Java\u00ae Virtual Machine Specification - Java SE 8 Edition - retrieved 2022-07-11 The Python VM on the other hand, uses exactly one byte as oparg on all instructions The bytecode can be thought of as a series of instructions or a low-level program for the Python interpreter. After version 3.6, Python uses 2 bytes for each instruction. One byte is for the code of that instruction which is called an opcode , and one byte is reserved for its argument which is called the oparg . [...] Some instructions do not need an argument, so they ignore the byte after the opcode. The opcodes which have a value below a certain number ignore their argument. This value is stored in dis.HAVE_ARGUMENT and is currently equal to 90. So the opcodes >= dis.HAVE_ARGUMENT have an argument, and the opcodes < dis.HAVE_ARGUMENT ignore it. \u2014 Reza Bagheri - Understanding Python Bytecode - in Towards Data Science - retrieved 2022-07-11 That does remove some complexity. And adds new complexity - for opcodes with more than one oparg byte - they exist in python and are handled with a special opcode, that adds an additional oparg byte. I think it will make execution faster, as fetching can be done it advance. If you do not know, how many bytes you need, before your read your opcode, you cannot prefetch the next instructions. For our goal, keeping the bytecode small is much more important than execution time. So I am pretty sure we will stick with the dynamic number of oparg bytes in lovem. The source code for this post can be found under the tag v0.0.3-journey . v0.0.3-journey source code v0.0.3-journey release v0.0.3-journey.zip v0.0.3-journey.tar.gz git checkout v0.0.3-journey What does this mean?","title":"Opargs"},{"location":"2022-07/go-ahead-and-jump.html","text":"Go ahead and jump! \u00b6 All our programs have been linear so far. Let's build the base for jumping around. kratenko \u00b7 kratenko 2022-07-22 \u00b7 Entry #19 \u00b7 5 min read \u00b7 v0.0.6-journey In every program we have written so far, each instruction just advances the PC 1 , until we reach the end. That is very linear. We will now introduce a new opcode, that jumps to a different position in the program. A new opcode \u00b6 How do we implement that? That is actually quite easy. Do you remember what I said about the PC? It is a special register, that always points to the instruction in the bytecode, that is executed next. So all our operation needs to do is modify the PC. We will give that opcode an oparg of two bytes, so we can tell it, where to jump to. Here is our new opcode in op.rs : /// opcode: Relative jump. /// /// pop: 0, push: 0 /// oparg: 2B, i16 relative jump pub const GOTO : u8 = 0x20 ; Now we have the dreaded goto . Don't be scared - on bytecode level, that is all well. We are not designing a high level language here, there will be gotos. But how do we fetch an i16 from our bytecode? So far we can only fetch u8 . So we add some more fetching: Fetch more than a byte \u00b6 /// Reads the next byte from the bytecode, increase programm counter, and return byte. fn fetch_u8 ( & mut self , pgm : & [ u8 ]) -> Result < u8 , RuntimeError > { if let Some ( v ) = pgm . get ( self . pc ) { self . pc += 1 ; Ok ( * v ) } else { Err ( RuntimeError :: EndOfProgram ) } } /// Reads the next byte from the bytecode, increase programm counter, and return byte. fn fetch_i8 ( & mut self , pgm : & [ u8 ]) -> Result < i8 , RuntimeError > { if let Some ( v ) = pgm . get ( self . pc ) { self . pc += 1 ; Ok ( * v as i8 ) } else { Err ( RuntimeError :: EndOfProgram ) } } /// Reads the next two bytes from the bytecode, increase programm counter by two, and return as i16. fn fetch_i16 ( & mut self , pgm : & [ u8 ]) -> Result < i16 , RuntimeError > { let hi = self . fetch_i8 ( pgm ) ? as i16 ; let lo = self . fetch_u8 ( pgm ) ? as i16 ; Ok ( hi << 8 | lo ) } We already know fn fetch_u8() . fn fetch_i8() does almost the exact thing, only that it casts that byte from u8 to i8 . Simple enough. Casting in Rust has the beautiful syntax <value> as <type> . So why do we need i8 ? Because we are building an i16 from an i8 and a u8 . Just a bit of bit arithmetic. We can pass on potential EndOfProgram runtime errors easily with ? and Result . It allows us to write some short but still easy-to-read code, I think. So now we can fetch the value, we need for our jump. So let us write the handler for the opcode in fn execute_op() of vm.rs . Goto \u00b6 op :: GOTO => { println! ( \" GOTO\" ); let d = self . fetch_i16 ( pgm ) ? ; self . pc += d ; Ok (()) } So, is that all? No, because we made a Rust-beginner-mistake. If we try and compile the code, we get an error: error[E0308]: mismatched types --> src/vm.rs:174:28 | 174 | self.pc += d; | ^ expected `usize`, found `i16` Yeah - Rust does not allow us to do calculations with different types of integers. We need to explicitly cast everything. Rust tries to avoid ambiguity, so no implicit conversions. And, to be honest, the compiler has a good point. We should care even more about that calculation; we want our VM to be robust. We change the handler to: op :: GOTO => { println! ( \" GOTO\" ); let d = self . fetch_i16 ( pgm ) ? ; self . relative_jump ( pgm , d ) } Safe goto \u00b6 And we add a new method (and we add a new RuntimeError): /// Executes a checked relative jump; Runtime error, if jump leaves program. fn relative_jump ( & mut self , pgm : & [ u8 ], delta : i16 ) -> Result < (), RuntimeError > { println! ( \" Jump from {} by {}\" , self . pc , delta ); if delta < 0 { let d = - delta as usize ; if self . pc >= d { self . pc -= d ; Ok (()) } else { Err ( RuntimeError :: InvalidJump ) } } else { let d = delta as usize ; if self . pc + d < pgm . len () { self . pc += d ; Ok (()) } else { Err ( RuntimeError :: InvalidJump ) } } } Enter the loop \u00b6 Now, let us write a new program that uses the goto opcode: //! Create a VM and run a small bytecode program in it. //! //! This demonstrates the goto operation with an endless loop. use lovem :: { op , VM }; fn main () { // Create a program in bytecode. // We just hardcode the bytes in an array here: let pgm = [ op :: PUSH_U8 , 123 , op :: GOTO , 0xff , 0xfb , op :: FIN ]; // Create our VM instance. let mut vm = VM :: new ( 100 ); // Execute the program in our VM: match vm . run ( & pgm ) { Ok ( _ ) => { println! ( \"Execution successful.\" ) } Err ( e ) => { println! ( \"Error during execution: {:?}\" , e ); } } } I will write that bytecode down in a more readable format again: push_u8 123 goto -5 fin Only 3 instructions. And the fin will never be reached. That 0xff, 0xfb after the op::GOTO is the 2 byte oparg: an i16 with the value -5 . But why -5 ? When the goto executed, we have read both oparg bytes, so the PC points to the fin at index 5. So adding -5 to it will set the PC to 0 . The next executed instruction will be the push_u8 once again. This is an endless loop. So will the program run forever? What do you think will happen? Let's try: VM { stack: [], pc: 0, op_cnt: 0 } Executing op 0x02 PUSH_U8 value: 123 VM { stack: [123], pc: 2, op_cnt: 1 } Executing op 0x20 GOTO Jump from 5 by -5 VM { stack: [123], pc: 0, op_cnt: 2 } Executing op 0x02 PUSH_U8 value: 123 VM { stack: [123, 123], pc: 2, op_cnt: 3 } Executing op 0x20 GOTO [...] VM { stack: [123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123], pc: 0, op_cnt: 200 } Executing op 0x02 PUSH_U8 value: 123 Error during execution: StackOverflow Process finished with exit code 0 There is a push_u8 operation in our endless loop. So it will fill our stack until it is full! The program hits a runtime error after 200 executed instructions. Great, now we tested that, too. NOPE \u00b6 That is not very dynamic. We want to make decisions! We want to choose our path. What we want is branching . We will introduce a new opcode, that will decide, which branch the execution of our program will take, based on a value during runtime. If this sounds unfamiliar to you, let me tell you, what statement we want to introduce: it is the if statement. So, how does that work? As mentioned, normally the PC is incremented on each byte we fetch from the bytecode. And the PC always points to the next instruction, that will be executed. So if we want to change the path of execution, what we have to do is change the value of the PC. An operation, that simply changes the PC statically, would be a GOTO statement. But there is no branching involved in that, the path that will be executed is always clear. The if statement on the other hand only alters the PC, if a certain condition is met. A new opcode \u00b6 /// opcode: Branch if top value is equal to zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFEQ : u8 = 0x20 ; Our new operation pops only one value. So what does it get compared to? That's easy: zero. If you need to compare two values to each other, just subtract them instead, and then you can compare with zero. That gives the same result. And what kind of oparg does this operation take? A signed integer. That is the value that should be added to the PC, if our condition is met. This will result in a relative jump. Homework \u00b6 Same as always. Write some bytecode. Try some jumping around. Run into troubles! You can write a program, that has a fin in the middle, but executes code that lies behind that instruction. The source code for this post can be found under the tag v0.0.6-journey . v0.0.6-journey source code v0.0.6-journey release v0.0.6-journey.zip v0.0.6-journey.tar.gz git checkout v0.0.6-journey What does this mean? PC: the Program Counter, a special register that points to the next instruction to be executed. \u21a9","title":" Go ahead and jump!"},{"location":"2022-07/go-ahead-and-jump.html#go-ahead-and-jump","text":"All our programs have been linear so far. Let's build the base for jumping around. kratenko \u00b7 kratenko 2022-07-22 \u00b7 Entry #19 \u00b7 5 min read \u00b7 v0.0.6-journey In every program we have written so far, each instruction just advances the PC 1 , until we reach the end. That is very linear. We will now introduce a new opcode, that jumps to a different position in the program.","title":"Go ahead and jump!"},{"location":"2022-07/go-ahead-and-jump.html#a-new-opcode","text":"How do we implement that? That is actually quite easy. Do you remember what I said about the PC? It is a special register, that always points to the instruction in the bytecode, that is executed next. So all our operation needs to do is modify the PC. We will give that opcode an oparg of two bytes, so we can tell it, where to jump to. Here is our new opcode in op.rs : /// opcode: Relative jump. /// /// pop: 0, push: 0 /// oparg: 2B, i16 relative jump pub const GOTO : u8 = 0x20 ; Now we have the dreaded goto . Don't be scared - on bytecode level, that is all well. We are not designing a high level language here, there will be gotos. But how do we fetch an i16 from our bytecode? So far we can only fetch u8 . So we add some more fetching:","title":"A new opcode"},{"location":"2022-07/go-ahead-and-jump.html#fetch-more-than-a-byte","text":"/// Reads the next byte from the bytecode, increase programm counter, and return byte. fn fetch_u8 ( & mut self , pgm : & [ u8 ]) -> Result < u8 , RuntimeError > { if let Some ( v ) = pgm . get ( self . pc ) { self . pc += 1 ; Ok ( * v ) } else { Err ( RuntimeError :: EndOfProgram ) } } /// Reads the next byte from the bytecode, increase programm counter, and return byte. fn fetch_i8 ( & mut self , pgm : & [ u8 ]) -> Result < i8 , RuntimeError > { if let Some ( v ) = pgm . get ( self . pc ) { self . pc += 1 ; Ok ( * v as i8 ) } else { Err ( RuntimeError :: EndOfProgram ) } } /// Reads the next two bytes from the bytecode, increase programm counter by two, and return as i16. fn fetch_i16 ( & mut self , pgm : & [ u8 ]) -> Result < i16 , RuntimeError > { let hi = self . fetch_i8 ( pgm ) ? as i16 ; let lo = self . fetch_u8 ( pgm ) ? as i16 ; Ok ( hi << 8 | lo ) } We already know fn fetch_u8() . fn fetch_i8() does almost the exact thing, only that it casts that byte from u8 to i8 . Simple enough. Casting in Rust has the beautiful syntax <value> as <type> . So why do we need i8 ? Because we are building an i16 from an i8 and a u8 . Just a bit of bit arithmetic. We can pass on potential EndOfProgram runtime errors easily with ? and Result . It allows us to write some short but still easy-to-read code, I think. So now we can fetch the value, we need for our jump. So let us write the handler for the opcode in fn execute_op() of vm.rs .","title":"Fetch more than a byte"},{"location":"2022-07/go-ahead-and-jump.html#goto","text":"op :: GOTO => { println! ( \" GOTO\" ); let d = self . fetch_i16 ( pgm ) ? ; self . pc += d ; Ok (()) } So, is that all? No, because we made a Rust-beginner-mistake. If we try and compile the code, we get an error: error[E0308]: mismatched types --> src/vm.rs:174:28 | 174 | self.pc += d; | ^ expected `usize`, found `i16` Yeah - Rust does not allow us to do calculations with different types of integers. We need to explicitly cast everything. Rust tries to avoid ambiguity, so no implicit conversions. And, to be honest, the compiler has a good point. We should care even more about that calculation; we want our VM to be robust. We change the handler to: op :: GOTO => { println! ( \" GOTO\" ); let d = self . fetch_i16 ( pgm ) ? ; self . relative_jump ( pgm , d ) }","title":"Goto"},{"location":"2022-07/go-ahead-and-jump.html#safe-goto","text":"And we add a new method (and we add a new RuntimeError): /// Executes a checked relative jump; Runtime error, if jump leaves program. fn relative_jump ( & mut self , pgm : & [ u8 ], delta : i16 ) -> Result < (), RuntimeError > { println! ( \" Jump from {} by {}\" , self . pc , delta ); if delta < 0 { let d = - delta as usize ; if self . pc >= d { self . pc -= d ; Ok (()) } else { Err ( RuntimeError :: InvalidJump ) } } else { let d = delta as usize ; if self . pc + d < pgm . len () { self . pc += d ; Ok (()) } else { Err ( RuntimeError :: InvalidJump ) } } }","title":"Safe goto"},{"location":"2022-07/go-ahead-and-jump.html#enter-the-loop","text":"Now, let us write a new program that uses the goto opcode: //! Create a VM and run a small bytecode program in it. //! //! This demonstrates the goto operation with an endless loop. use lovem :: { op , VM }; fn main () { // Create a program in bytecode. // We just hardcode the bytes in an array here: let pgm = [ op :: PUSH_U8 , 123 , op :: GOTO , 0xff , 0xfb , op :: FIN ]; // Create our VM instance. let mut vm = VM :: new ( 100 ); // Execute the program in our VM: match vm . run ( & pgm ) { Ok ( _ ) => { println! ( \"Execution successful.\" ) } Err ( e ) => { println! ( \"Error during execution: {:?}\" , e ); } } } I will write that bytecode down in a more readable format again: push_u8 123 goto -5 fin Only 3 instructions. And the fin will never be reached. That 0xff, 0xfb after the op::GOTO is the 2 byte oparg: an i16 with the value -5 . But why -5 ? When the goto executed, we have read both oparg bytes, so the PC points to the fin at index 5. So adding -5 to it will set the PC to 0 . The next executed instruction will be the push_u8 once again. This is an endless loop. So will the program run forever? What do you think will happen? Let's try: VM { stack: [], pc: 0, op_cnt: 0 } Executing op 0x02 PUSH_U8 value: 123 VM { stack: [123], pc: 2, op_cnt: 1 } Executing op 0x20 GOTO Jump from 5 by -5 VM { stack: [123], pc: 0, op_cnt: 2 } Executing op 0x02 PUSH_U8 value: 123 VM { stack: [123, 123], pc: 2, op_cnt: 3 } Executing op 0x20 GOTO [...] VM { stack: [123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123, 123], pc: 0, op_cnt: 200 } Executing op 0x02 PUSH_U8 value: 123 Error during execution: StackOverflow Process finished with exit code 0 There is a push_u8 operation in our endless loop. So it will fill our stack until it is full! The program hits a runtime error after 200 executed instructions. Great, now we tested that, too.","title":"Enter the loop"},{"location":"2022-07/go-ahead-and-jump.html#nope","text":"That is not very dynamic. We want to make decisions! We want to choose our path. What we want is branching . We will introduce a new opcode, that will decide, which branch the execution of our program will take, based on a value during runtime. If this sounds unfamiliar to you, let me tell you, what statement we want to introduce: it is the if statement. So, how does that work? As mentioned, normally the PC is incremented on each byte we fetch from the bytecode. And the PC always points to the next instruction, that will be executed. So if we want to change the path of execution, what we have to do is change the value of the PC. An operation, that simply changes the PC statically, would be a GOTO statement. But there is no branching involved in that, the path that will be executed is always clear. The if statement on the other hand only alters the PC, if a certain condition is met.","title":"NOPE"},{"location":"2022-07/go-ahead-and-jump.html#a-new-opcode_1","text":"/// opcode: Branch if top value is equal to zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFEQ : u8 = 0x20 ; Our new operation pops only one value. So what does it get compared to? That's easy: zero. If you need to compare two values to each other, just subtract them instead, and then you can compare with zero. That gives the same result. And what kind of oparg does this operation take? A signed integer. That is the value that should be added to the PC, if our condition is met. This will result in a relative jump.","title":"A new opcode"},{"location":"2022-07/go-ahead-and-jump.html#homework","text":"Same as always. Write some bytecode. Try some jumping around. Run into troubles! You can write a program, that has a fin in the middle, but executes code that lies behind that instruction. The source code for this post can be found under the tag v0.0.6-journey . v0.0.6-journey source code v0.0.6-journey release v0.0.6-journey.zip v0.0.6-journey.tar.gz git checkout v0.0.6-journey What does this mean? PC: the Program Counter, a special register that points to the next instruction to be executed. \u21a9","title":"Homework"},{"location":"2022-07/it-looks-so-weird.html","text":"It looks so weird \u00b6 Now, that you have seen some code, I might have to explain a bit again. Depends, on where you are coming from, I guess. kratenko \u00b7 kratenko 2022-07-10 \u00b7 Entry #10 \u00b7 4 min read So, did you take a look at the code, yet? In case you've forgotten, this is my \"initial commit\": https://github.com/kratenko/lovem/tree/v0.0.1-journey It is not the original initial commit, as I did commit way too late, and it was not suitable for writing a story about it. So I created a new, clean version, with just very simple concepts that I can explain in a single entry. In the next entry, that is. If you are thinking: \"What is that weird source code?\", then you are in for a real treat (and a lot of pain), should you chose to follow up. The code you are seeing is written in Rust . Once again: but why? \u00b6 Why Rust? Because Rust! Writing Rust can feel so good! And for something like a VM, it is such a good choice. If you have never heard of the language (or heard of it, but never looked into it), it is hard to understand why this is so. My advice: try it! use it! Or read along this journal, code along, you might like it. When you start, chances are high that you will not like Rust. The compiler is a pedantic pain in the ass. But at the same time it is incredibly polite, trying to help you find out, what you did wrong, and suggesting what you might want to do instead. And Rust really, really tries, to keep you from shooting yourself in the foot. It tries to make common mistakes impossible or at least hard to do \u2013 those mistakes that happen everywhere in C/C++ programs and their like. Yes, those mistakes that are the cause of the majority of all security problems and crashes. Buffer overruns, use after free, double free, memory leak \u2013 to name just some common ones from the top of my head. And Rust makes all it can to make those mistakes impossible during compilation! So it does not even add runtime overhead. That is so powerful! And it is so painful. Half of the things you do, when writing C/C++, you will not be able to do in Rust in the same way. Every piece of memory is owned. You can borrow it and return it, but it cannot be owned in two places at once. And if any part of the program has writing access to it, no other part may have any access. This makes some data structures complicated or impossible (there are ways around it), and you will have to think quite differently. But if you give in on that way of thinking, you can gain so much. Even peace of the mind, as the coding world will look a lot saner inside Rust source code. This will, of course, come with the price, that all code in other languages will start to feel dirty to you, but that is the way. Also, there are a lot of ways to write code, that you cannot add to a language that already exists. C and C++ will never be freed of their heritage; they will stay what they are, with all their pros and cons. Things are solved differently in Rust. Did I mention there is no NULL ? And I have never missed it for a moment. Rust solves the problems other languages solve with NULL by using enums. That comes with certainty and safety all the way. There are no exceptions either. That problem is also solved by using enums. The way the language embraces those, they are a really powerful feature! And there are lot more convenient ways of organising code, that I keep missing in my daily C/C++ life. I will not write an introduction into Rust here. At least not your typical \"how to get started in rust\" intro. There are a lot of those out there, and I am already 10 posts into my Journal without programming. Maybe the Journal will become a different kind of Rust introduction, as it will try to take you along a real project, as it develops, from the beginning on. I will run into problems along the way and try to solve them in Rusty ways. This might be a good way, to start thinking in Rust. But, to be honest, I did never finish a project in Rust, yet. I got quite a bit running and functional, and I think in some parts in a rust-like way. But this is for me as much as anyone else as a learning project. I will make weird things. But the basics, I have worked with, yeah. The initial learning curve will be steep! I try to not get too fancy in the first draft, so the code will not be good Rust there! So, if you are shocked at how bad my Rust is \u2013 it will be very different, soon. But I want to give everyone a fair chance to hop on without understanding all the concepts. The initial code should be not too hard to follow, if you know C/C++, I hope. Learning a new thing (writing a VM) in a new, quite different language is a mouth full, I know. Didn't you say, you use C/C++? \u00b6 Yes I did say that. And I do use those. It is not easy to change that, when you have a certain amount of legacy code (and not much experience with the new language, as we do not really have, yet). But we do have a saying these days. Often, after a debugging session that lasted for hours, when we find the bug, understand it and fix it, there is this realisation, that fits in the sentence: \"Mit Rust w\u00e4r' das nicht passiert.\" \u2014 \"This would not have happened with Rust.\" So, this will not happen to me with this project, because those things will not happen with Rust!","title":" It looks so weird"},{"location":"2022-07/it-looks-so-weird.html#it-looks-so-weird","text":"Now, that you have seen some code, I might have to explain a bit again. Depends, on where you are coming from, I guess. kratenko \u00b7 kratenko 2022-07-10 \u00b7 Entry #10 \u00b7 4 min read So, did you take a look at the code, yet? In case you've forgotten, this is my \"initial commit\": https://github.com/kratenko/lovem/tree/v0.0.1-journey It is not the original initial commit, as I did commit way too late, and it was not suitable for writing a story about it. So I created a new, clean version, with just very simple concepts that I can explain in a single entry. In the next entry, that is. If you are thinking: \"What is that weird source code?\", then you are in for a real treat (and a lot of pain), should you chose to follow up. The code you are seeing is written in Rust .","title":"It looks so weird"},{"location":"2022-07/it-looks-so-weird.html#once-again-but-why","text":"Why Rust? Because Rust! Writing Rust can feel so good! And for something like a VM, it is such a good choice. If you have never heard of the language (or heard of it, but never looked into it), it is hard to understand why this is so. My advice: try it! use it! Or read along this journal, code along, you might like it. When you start, chances are high that you will not like Rust. The compiler is a pedantic pain in the ass. But at the same time it is incredibly polite, trying to help you find out, what you did wrong, and suggesting what you might want to do instead. And Rust really, really tries, to keep you from shooting yourself in the foot. It tries to make common mistakes impossible or at least hard to do \u2013 those mistakes that happen everywhere in C/C++ programs and their like. Yes, those mistakes that are the cause of the majority of all security problems and crashes. Buffer overruns, use after free, double free, memory leak \u2013 to name just some common ones from the top of my head. And Rust makes all it can to make those mistakes impossible during compilation! So it does not even add runtime overhead. That is so powerful! And it is so painful. Half of the things you do, when writing C/C++, you will not be able to do in Rust in the same way. Every piece of memory is owned. You can borrow it and return it, but it cannot be owned in two places at once. And if any part of the program has writing access to it, no other part may have any access. This makes some data structures complicated or impossible (there are ways around it), and you will have to think quite differently. But if you give in on that way of thinking, you can gain so much. Even peace of the mind, as the coding world will look a lot saner inside Rust source code. This will, of course, come with the price, that all code in other languages will start to feel dirty to you, but that is the way. Also, there are a lot of ways to write code, that you cannot add to a language that already exists. C and C++ will never be freed of their heritage; they will stay what they are, with all their pros and cons. Things are solved differently in Rust. Did I mention there is no NULL ? And I have never missed it for a moment. Rust solves the problems other languages solve with NULL by using enums. That comes with certainty and safety all the way. There are no exceptions either. That problem is also solved by using enums. The way the language embraces those, they are a really powerful feature! And there are lot more convenient ways of organising code, that I keep missing in my daily C/C++ life. I will not write an introduction into Rust here. At least not your typical \"how to get started in rust\" intro. There are a lot of those out there, and I am already 10 posts into my Journal without programming. Maybe the Journal will become a different kind of Rust introduction, as it will try to take you along a real project, as it develops, from the beginning on. I will run into problems along the way and try to solve them in Rusty ways. This might be a good way, to start thinking in Rust. But, to be honest, I did never finish a project in Rust, yet. I got quite a bit running and functional, and I think in some parts in a rust-like way. But this is for me as much as anyone else as a learning project. I will make weird things. But the basics, I have worked with, yeah. The initial learning curve will be steep! I try to not get too fancy in the first draft, so the code will not be good Rust there! So, if you are shocked at how bad my Rust is \u2013 it will be very different, soon. But I want to give everyone a fair chance to hop on without understanding all the concepts. The initial code should be not too hard to follow, if you know C/C++, I hope. Learning a new thing (writing a VM) in a new, quite different language is a mouth full, I know.","title":"Once again: but why?"},{"location":"2022-07/it-looks-so-weird.html#didnt-you-say-you-use-cc","text":"Yes I did say that. And I do use those. It is not easy to change that, when you have a certain amount of legacy code (and not much experience with the new language, as we do not really have, yet). But we do have a saying these days. Often, after a debugging session that lasted for hours, when we find the bug, understand it and fix it, there is this realisation, that fits in the sentence: \"Mit Rust w\u00e4r' das nicht passiert.\" \u2014 \"This would not have happened with Rust.\" So, this will not happen to me with this project, because those things will not happen with Rust!","title":"Didn't you say, you use C/C++?"},{"location":"2022-07/let-there-be-source-code.html","text":"Let there be source code \u00b6 Finally, I will be showing some source code. Not directly in the journal, but I will link you to GitHub, for a start. kratenko \u00b7 kratenko 2022-07-08 \u00b7 Entry #9 \u00b7 2 min read I have written code. And this time, I (re-)started lovem in a public git repository, so you can see what I do, if you are interested. And I hope it puts enough pressure on me, to keep on the project for a while. In fact, there is quite a bit of code there already. I started coding, before writing any of this, and it went so well. I like how it feels. I was working any hour I could spare. When a friend asked me what I was doing, I started a somewhat complex backstory why I was doing it, instead of actually explaining anything of the stuff I was doing \u2013 and was interrupted quite early, so there was more to tell in me still. The next day, I sat down and started to write all of that down as a little story. I wanted to put it somewhere, so I started this journal to publish it. And I decided to do it in blog form, so I am publishing that background story bit by bit. So, as of writing this, there is a lot of work completed on the VM. Tt is amazing what things it can do for how little code there is. When this post goes public, there should be quite lot more done... But where is the code? \u00b6 Well, if you read this journal, you will know where it lives. Anyway, this is the repo: https://github.com/kratenko/lovem I plan to continue sharing my thoughts while I work on the VM. So you will be able to follow my failures and see the attempts that I will be ditching later. I think the format of this journal can work out, but we will see how I like it over time. It will be behind on progress, as I want to take time to share things as they unfold. And this should help to produce a somewhat continuous publication stream. Git being what git is, should support me in showing you the things I do back in time, using the power of commits. As things are with blogs, my entries will be very different, depending on what I want to tell and on what I did. So far most blogs where conceptional thinking, some research, and a lot of blabla, which I tell because it interests me myself. In the future, there should be concrete problems I find and solve in source code - or which I fail to solve. Back in time \u00b6 Me original first commit was way too late and contained way too much code. Also, I did not plan to show it to you like this, back then. So, as mentioned before, I rolled back and started again, with more commits. And I am keeping tags now, so that I have well-defined versions for my blog posts. That should make it easy for you to follow up, if you want to. The new, artificial \"first commit\" is now a tag/release: v0.0.1-journey . You can view the code for any tag online, this one you will find under: https://github.com/kratenko/lovem/tree/v0.0.1-journey I think this will be a theme of this journal: linking you to what I did, when I am writing about it. And I will try to share my trails of thoughts, leading to my decisions (and errors, as it will be). I will do that, for that v0.0.1-journey, soon, don't worry, I will explain everything I did. But the next journal entry will be about some decisions again; mainly about the language I am using.","title":" Let there be source code"},{"location":"2022-07/let-there-be-source-code.html#let-there-be-source-code","text":"Finally, I will be showing some source code. Not directly in the journal, but I will link you to GitHub, for a start. kratenko \u00b7 kratenko 2022-07-08 \u00b7 Entry #9 \u00b7 2 min read I have written code. And this time, I (re-)started lovem in a public git repository, so you can see what I do, if you are interested. And I hope it puts enough pressure on me, to keep on the project for a while. In fact, there is quite a bit of code there already. I started coding, before writing any of this, and it went so well. I like how it feels. I was working any hour I could spare. When a friend asked me what I was doing, I started a somewhat complex backstory why I was doing it, instead of actually explaining anything of the stuff I was doing \u2013 and was interrupted quite early, so there was more to tell in me still. The next day, I sat down and started to write all of that down as a little story. I wanted to put it somewhere, so I started this journal to publish it. And I decided to do it in blog form, so I am publishing that background story bit by bit. So, as of writing this, there is a lot of work completed on the VM. Tt is amazing what things it can do for how little code there is. When this post goes public, there should be quite lot more done...","title":"Let there be source code"},{"location":"2022-07/let-there-be-source-code.html#but-where-is-the-code","text":"Well, if you read this journal, you will know where it lives. Anyway, this is the repo: https://github.com/kratenko/lovem I plan to continue sharing my thoughts while I work on the VM. So you will be able to follow my failures and see the attempts that I will be ditching later. I think the format of this journal can work out, but we will see how I like it over time. It will be behind on progress, as I want to take time to share things as they unfold. And this should help to produce a somewhat continuous publication stream. Git being what git is, should support me in showing you the things I do back in time, using the power of commits. As things are with blogs, my entries will be very different, depending on what I want to tell and on what I did. So far most blogs where conceptional thinking, some research, and a lot of blabla, which I tell because it interests me myself. In the future, there should be concrete problems I find and solve in source code - or which I fail to solve.","title":"But where is the code?"},{"location":"2022-07/let-there-be-source-code.html#back-in-time","text":"Me original first commit was way too late and contained way too much code. Also, I did not plan to show it to you like this, back then. So, as mentioned before, I rolled back and started again, with more commits. And I am keeping tags now, so that I have well-defined versions for my blog posts. That should make it easy for you to follow up, if you want to. The new, artificial \"first commit\" is now a tag/release: v0.0.1-journey . You can view the code for any tag online, this one you will find under: https://github.com/kratenko/lovem/tree/v0.0.1-journey I think this will be a theme of this journal: linking you to what I did, when I am writing about it. And I will try to share my trails of thoughts, leading to my decisions (and errors, as it will be). I will do that, for that v0.0.1-journey, soon, don't worry, I will explain everything I did. But the next journal entry will be about some decisions again; mainly about the language I am using.","title":"Back in time"},{"location":"2022-07/making-virtual-a-reality.html","text":"Making virtual a reality \u00b6 So I have been talking a lot about VMs without doing anything concrete. Well that is not true, I have done quite a bit already, but I am still describing earlier steps. We will get there. kratenko \u00b7 kratenko 2022-07-06 \u00b7 Entry #8 \u00b7 3 min read Registers? \u00b6 When I was looking around for a scripting language to use inside our embedded devices, I came across an article I mentioned in an earlier post: Creating a Virtual Machine/Register VM in C . Reading it made me want to try working with a register machine, mainly because I have not been stuff like this since my early semesters. Never hurts to refresh rusty knowledge. So I started designing a register VM, starting from that code, but more complex, with longer data words and longer instruction words, more registers, and so forth. For this project I came up with lovem as a working title. It still stuck to now, two approaches and a year later. I also started implementing some concepts I still want to add to lovem in my current approach, but that is for a later post to discuss. I was experimenting with a quite complicated instruction word encoding. I was trying to fit everything in a few bits (32 of them if I recall correctly) with varying instruction code length and quite long arguments. I wanted to include instructions on three registers, which takes up quite some bits to address. Of course, you can get away with two-register operations only - or if you are fancy you can even use a single address or even no address for most instructions. You will just end up with a lot of register swapping. I guess my rational for having three addresses in an instruction was code size. For what I want to do, 32 bit instruction words feel quite long (4 bytes per instruction!). And every swap would mean another 4 bytes of program size. So trying to optimise for fewer operations by having more flexible instructions. I do not even know if that rational makes sense. I guess I would have needed to try different layouts to find out. Or maybe read more about that topic, other people have done similar things I assume. But I never got that far. The experiment showed me, that I do not want to build lovem as a register machine. I think building a clever register based architecture for my goals would make it too complicated. I want simple. To reduce the VM's overhead, but also on principle. Complexity is the enemy. I'm pretty sure, that code still exists somewhere, but there is no sense in publishing it or even in me reading it again, so you will never see it. I think of it as a pre-study with a very useful conclusion: not a register machine. Stacks! \u00b6 So a stack machine it is! I have looked at a few during my research for lovem, looking at instruction sets and design ideas. It is not the first time, I have been working with those. In a different project (around the same time I started work on the register based machine), I was starting to implement a stack machine. That one had a different aim and therefore very different challenges. It was more of an object-oriented approach with dynamic program loading and calling code in different programs. It could do quite a few things already, but it will never be continued. I learned a bit about calling conventions and found out that it is not so simple, when you want to switch between multiple programs and objects. That is where the project got too frustrating for me (and some external events made it obsolete, so that is okay). But I take it for a pre-study on stack machines and calling conventions. Not that I have developed a proven concept for it, but I know about the problems there... I had a PoC for lovem as a stack machine back then, too (right after I ditched the register approach). That code won't be published either, but the attempt showed me, that I want to take that road for a serious approach on creating lovem. Onwards \u00b6 I guess this concludes the prehistory of the lovem story. I am, for whatever reason, back on the project, currently with a decent amount of motivation. You never know how long that lasts, but right now I like the idea of continuing the development, while talking about the development process, sharing my thoughts on decisions I make. Next post should start on sharing newer thoughts.","title":" Making virtual a reality"},{"location":"2022-07/making-virtual-a-reality.html#making-virtual-a-reality","text":"So I have been talking a lot about VMs without doing anything concrete. Well that is not true, I have done quite a bit already, but I am still describing earlier steps. We will get there. kratenko \u00b7 kratenko 2022-07-06 \u00b7 Entry #8 \u00b7 3 min read","title":"Making virtual a reality"},{"location":"2022-07/making-virtual-a-reality.html#registers","text":"When I was looking around for a scripting language to use inside our embedded devices, I came across an article I mentioned in an earlier post: Creating a Virtual Machine/Register VM in C . Reading it made me want to try working with a register machine, mainly because I have not been stuff like this since my early semesters. Never hurts to refresh rusty knowledge. So I started designing a register VM, starting from that code, but more complex, with longer data words and longer instruction words, more registers, and so forth. For this project I came up with lovem as a working title. It still stuck to now, two approaches and a year later. I also started implementing some concepts I still want to add to lovem in my current approach, but that is for a later post to discuss. I was experimenting with a quite complicated instruction word encoding. I was trying to fit everything in a few bits (32 of them if I recall correctly) with varying instruction code length and quite long arguments. I wanted to include instructions on three registers, which takes up quite some bits to address. Of course, you can get away with two-register operations only - or if you are fancy you can even use a single address or even no address for most instructions. You will just end up with a lot of register swapping. I guess my rational for having three addresses in an instruction was code size. For what I want to do, 32 bit instruction words feel quite long (4 bytes per instruction!). And every swap would mean another 4 bytes of program size. So trying to optimise for fewer operations by having more flexible instructions. I do not even know if that rational makes sense. I guess I would have needed to try different layouts to find out. Or maybe read more about that topic, other people have done similar things I assume. But I never got that far. The experiment showed me, that I do not want to build lovem as a register machine. I think building a clever register based architecture for my goals would make it too complicated. I want simple. To reduce the VM's overhead, but also on principle. Complexity is the enemy. I'm pretty sure, that code still exists somewhere, but there is no sense in publishing it or even in me reading it again, so you will never see it. I think of it as a pre-study with a very useful conclusion: not a register machine.","title":"Registers?"},{"location":"2022-07/making-virtual-a-reality.html#stacks","text":"So a stack machine it is! I have looked at a few during my research for lovem, looking at instruction sets and design ideas. It is not the first time, I have been working with those. In a different project (around the same time I started work on the register based machine), I was starting to implement a stack machine. That one had a different aim and therefore very different challenges. It was more of an object-oriented approach with dynamic program loading and calling code in different programs. It could do quite a few things already, but it will never be continued. I learned a bit about calling conventions and found out that it is not so simple, when you want to switch between multiple programs and objects. That is where the project got too frustrating for me (and some external events made it obsolete, so that is okay). But I take it for a pre-study on stack machines and calling conventions. Not that I have developed a proven concept for it, but I know about the problems there... I had a PoC for lovem as a stack machine back then, too (right after I ditched the register approach). That code won't be published either, but the attempt showed me, that I want to take that road for a serious approach on creating lovem.","title":"Stacks!"},{"location":"2022-07/making-virtual-a-reality.html#onwards","text":"I guess this concludes the prehistory of the lovem story. I am, for whatever reason, back on the project, currently with a decent amount of motivation. You never know how long that lasts, but right now I like the idea of continuing the development, while talking about the development process, sharing my thoughts on decisions I make. Next post should start on sharing newer thoughts.","title":"Onwards"},{"location":"2022-07/more-operations.html","text":"More operations \u00b6 The basic operation of the VM is working. Let us add a few more opcodes, so that we can do calculations. kratenko \u00b7 kratenko 2022-07-20 \u00b7 Entry #17 \u00b7 4 min read \u00b7 v0.0.4-journey We have created a rust library that holds our virtual register machine. We can now add multiple executables to it, so that makes it easier, to write different programs and keep them (to mess around with the VM). We will add a few more opcodes to our repertoire, because only adding numbers is just plain boring. I put some sort into what opcodes to introduce; but be advised, that none of them are final. Not only is the VM experimental and in a very early state, I introduce codes that I do not intend to keep on purpose. This is also a demonstration/introduction. So I add codes that are helpful at the time of writing, for experimenting. FIN is an example of a code, that will most likely be removed at some point. But for now it is nice to have a simple way to explicitly terminate the program. It gives some confidence, when we reach that point, that our program works as intended, and that we did not mess up the bytecode. Arithmetics \u00b6 Baby steps. No rush here. We had adding as a first example. We will introduce subtraction , multiplication , division , and modulo . Sounds like not much, but we will run in some complications, anyways... Here is our addtion to op.rs . /// opcode: Subtract top two values on stack. /// /// pop: 2, push: 1 /// oparg: 0 pub const SUB : u8 = 0x11 ; /// opcode: Multiply top two values on stack. /// /// pop: 2, push: 1 /// oparg: 0 pub const MUL : u8 = 0x12 ; /// opcode: Divide top two values on stack. /// /// pop: 2, push: 1 /// oparg: 0 pub const DIV : u8 = 0x13 ; /// opcode: Calculate modulo of top two values on stack. /// /// pop: 2, push: 1 /// oparg: 0 pub const MOD : u8 = 0x14 ; The order of things \u00b6 Simple enough those new codes, just copy and paste from ADD . But it turns out, subtraction is not as easy as addition. Here is the handling code we used for ADD : op :: ADD => { println! ( \" ADD\" ); let a = self . pop () ? ; let b = self . pop () ? ; self . push ( a + b ) }, Works. But if we copy and use that for SUB : op :: SUB => { println! ( \" SUB\" ); let a = self . pop () ? ; let b = self . pop () ? ; self . push ( a - b ) }, It turns out, that I messed up the order of the operands. That does not matter for addition, but subtraction is not commutative. So let's change that: op :: ADD => { println! ( \" ADD\" ); let b = self . pop () ? ; let a = self . pop () ? ; self . push ( a + b ) }, op :: SUB => { println! ( \" SUB\" ); let b = self . pop () ? ; let a = self . pop () ? ; self . push ( a - b ) }, op :: MUL => { println! ( \" MUL\" ); let b = self . pop () ? ; let a = self . pop () ? ; self . push ( a * b ) }, op :: DIV => { println! ( \" DIV\" ); let b = self . pop () ? ; let a = self . pop () ? ; self . push ( a / b ) }, op :: MOD => { println! ( \" MOD\" ); let b = self . pop () ? ; let a = self . pop () ? ; self . push ( a % b ) }, So, we learned something. I put the other operators there, as well. But this is too naive. You might already see the problem. Blowing up the school \u00b6 As my math teacher liked to say: \"... dann fliegt die Schule in die Luft!\" \u2013 If we do that the school building will blow up. It is his way of dealing with the issue, that pupils are told \"you must never divide by zero\", but that they are never given an understandable reason for it. So just own it, and provide a completely absurde one. What happens, is we keep it like this? Well, not much - until you write a program that divides by zero. Then, this will happen: [...] VM { stack: [4, 0], pc: 4, op_cnt: 2 } Executing op 0x13 DIV thread 'main' panicked at 'attempt to divide by zero', src/vm.rs:142:31 stack backtrace: 0: rust_begin_unwind at /rustc/fe5b13d681f25ee6474be29d748c65adcd91f69e/library/std/src/panicking.rs:584:5 1: core::panicking::panic_fmt at /rustc/fe5b13d681f25ee6474be29d748c65adcd91f69e/library/core/src/panicking.rs:143:14 2: core::panicking::panic at /rustc/fe5b13d681f25ee6474be29d748c65adcd91f69e/library/core/src/panicking.rs:48:5 3: lovem::vm::VM::execute_op at ./src/vm.rs:142:31 4: lovem::vm::VM::run at ./src/vm.rs:85:13 5: modulo::main at ./src/bin/modulo.rs:10:11 6: core::ops::function::FnOnce::call_once at /rustc/fe5b13d681f25ee6474be29d748c65adcd91f69e/library/core/src/ops/function.rs:227:5 note: Some details are omitted, run with `RUST_BACKTRACE=full` for a verbose backtrace. Process finished with exit code 101 Our program panics! I told you earlier, that this is not good behaviour. I introduced you to a lot of weird Rust stuff, just to avoid those. So, let us not re-introduce them now. So, what can we do instead? Division by zero is a runtime error, for sure (at least in this numerical domain we are working with). But it should not be a runtime error in our virtual machine, it should be a runtime error in the program it is running. Luckily, we already have that mechanism in our VM. So let us add a new runtime error: /// An error that happens during execution of a program inside the VM. #[derive(Debug, Clone, PartialEq)] pub enum RuntimeError { EndOfProgram , UnknownOpcode ( u8 ), StackUnderflow , StackOverflow , DivisionByZero , } And adjust our opcode handlers: op :: DIV => { println! ( \" DIV\" ); let b = self . pop () ? ; let a = self . pop () ? ; if b == 0 { Err ( RuntimeError :: DivisionByZero ) } else { self . push ( a / b ) } }, op :: MOD => { println! ( \" MOD\" ); let b = self . pop () ? ; let a = self . pop () ? ; if b == 0 { Err ( RuntimeError :: DivisionByZero ) } else { self . push ( a % b ) } }, We add a check for the DIV and MOD handlers (modulo is a division as well). If we run that program dividing by zero again, we now get this: [...] VM { stack: [4, 0], pc: 4, op_cnt: 2 } Executing op 0x13 DIV Error during execution: DivisionByZero Process finished with exit code 0 Yes, it still fails. But only the execution of the bytecode fails, not the execution of our virtual machine. You can now handle the problem inside your Rust program in a way that fits your needs. Much better. In the next post, we will be using our new instructions in a fancy way, that works well with a stack machine. Homework \u00b6 Oh, not sure. Play around with it, I guess? As always. Feel free to write a calculation into a program and compare the results. It should work, unless I messed up again. You should have at least, at some point, write a program in bytecode yourself, so that you know how that feels. The source code for this post can be found under the tag v0.0.4-journey . v0.0.4-journey source code v0.0.4-journey release v0.0.4-journey.zip v0.0.4-journey.tar.gz git checkout v0.0.4-journey What does this mean?","title":" More operations"},{"location":"2022-07/more-operations.html#more-operations","text":"The basic operation of the VM is working. Let us add a few more opcodes, so that we can do calculations. kratenko \u00b7 kratenko 2022-07-20 \u00b7 Entry #17 \u00b7 4 min read \u00b7 v0.0.4-journey We have created a rust library that holds our virtual register machine. We can now add multiple executables to it, so that makes it easier, to write different programs and keep them (to mess around with the VM). We will add a few more opcodes to our repertoire, because only adding numbers is just plain boring. I put some sort into what opcodes to introduce; but be advised, that none of them are final. Not only is the VM experimental and in a very early state, I introduce codes that I do not intend to keep on purpose. This is also a demonstration/introduction. So I add codes that are helpful at the time of writing, for experimenting. FIN is an example of a code, that will most likely be removed at some point. But for now it is nice to have a simple way to explicitly terminate the program. It gives some confidence, when we reach that point, that our program works as intended, and that we did not mess up the bytecode.","title":"More operations"},{"location":"2022-07/more-operations.html#arithmetics","text":"Baby steps. No rush here. We had adding as a first example. We will introduce subtraction , multiplication , division , and modulo . Sounds like not much, but we will run in some complications, anyways... Here is our addtion to op.rs . /// opcode: Subtract top two values on stack. /// /// pop: 2, push: 1 /// oparg: 0 pub const SUB : u8 = 0x11 ; /// opcode: Multiply top two values on stack. /// /// pop: 2, push: 1 /// oparg: 0 pub const MUL : u8 = 0x12 ; /// opcode: Divide top two values on stack. /// /// pop: 2, push: 1 /// oparg: 0 pub const DIV : u8 = 0x13 ; /// opcode: Calculate modulo of top two values on stack. /// /// pop: 2, push: 1 /// oparg: 0 pub const MOD : u8 = 0x14 ;","title":"Arithmetics"},{"location":"2022-07/more-operations.html#the-order-of-things","text":"Simple enough those new codes, just copy and paste from ADD . But it turns out, subtraction is not as easy as addition. Here is the handling code we used for ADD : op :: ADD => { println! ( \" ADD\" ); let a = self . pop () ? ; let b = self . pop () ? ; self . push ( a + b ) }, Works. But if we copy and use that for SUB : op :: SUB => { println! ( \" SUB\" ); let a = self . pop () ? ; let b = self . pop () ? ; self . push ( a - b ) }, It turns out, that I messed up the order of the operands. That does not matter for addition, but subtraction is not commutative. So let's change that: op :: ADD => { println! ( \" ADD\" ); let b = self . pop () ? ; let a = self . pop () ? ; self . push ( a + b ) }, op :: SUB => { println! ( \" SUB\" ); let b = self . pop () ? ; let a = self . pop () ? ; self . push ( a - b ) }, op :: MUL => { println! ( \" MUL\" ); let b = self . pop () ? ; let a = self . pop () ? ; self . push ( a * b ) }, op :: DIV => { println! ( \" DIV\" ); let b = self . pop () ? ; let a = self . pop () ? ; self . push ( a / b ) }, op :: MOD => { println! ( \" MOD\" ); let b = self . pop () ? ; let a = self . pop () ? ; self . push ( a % b ) }, So, we learned something. I put the other operators there, as well. But this is too naive. You might already see the problem.","title":"The order of things"},{"location":"2022-07/more-operations.html#blowing-up-the-school","text":"As my math teacher liked to say: \"... dann fliegt die Schule in die Luft!\" \u2013 If we do that the school building will blow up. It is his way of dealing with the issue, that pupils are told \"you must never divide by zero\", but that they are never given an understandable reason for it. So just own it, and provide a completely absurde one. What happens, is we keep it like this? Well, not much - until you write a program that divides by zero. Then, this will happen: [...] VM { stack: [4, 0], pc: 4, op_cnt: 2 } Executing op 0x13 DIV thread 'main' panicked at 'attempt to divide by zero', src/vm.rs:142:31 stack backtrace: 0: rust_begin_unwind at /rustc/fe5b13d681f25ee6474be29d748c65adcd91f69e/library/std/src/panicking.rs:584:5 1: core::panicking::panic_fmt at /rustc/fe5b13d681f25ee6474be29d748c65adcd91f69e/library/core/src/panicking.rs:143:14 2: core::panicking::panic at /rustc/fe5b13d681f25ee6474be29d748c65adcd91f69e/library/core/src/panicking.rs:48:5 3: lovem::vm::VM::execute_op at ./src/vm.rs:142:31 4: lovem::vm::VM::run at ./src/vm.rs:85:13 5: modulo::main at ./src/bin/modulo.rs:10:11 6: core::ops::function::FnOnce::call_once at /rustc/fe5b13d681f25ee6474be29d748c65adcd91f69e/library/core/src/ops/function.rs:227:5 note: Some details are omitted, run with `RUST_BACKTRACE=full` for a verbose backtrace. Process finished with exit code 101 Our program panics! I told you earlier, that this is not good behaviour. I introduced you to a lot of weird Rust stuff, just to avoid those. So, let us not re-introduce them now. So, what can we do instead? Division by zero is a runtime error, for sure (at least in this numerical domain we are working with). But it should not be a runtime error in our virtual machine, it should be a runtime error in the program it is running. Luckily, we already have that mechanism in our VM. So let us add a new runtime error: /// An error that happens during execution of a program inside the VM. #[derive(Debug, Clone, PartialEq)] pub enum RuntimeError { EndOfProgram , UnknownOpcode ( u8 ), StackUnderflow , StackOverflow , DivisionByZero , } And adjust our opcode handlers: op :: DIV => { println! ( \" DIV\" ); let b = self . pop () ? ; let a = self . pop () ? ; if b == 0 { Err ( RuntimeError :: DivisionByZero ) } else { self . push ( a / b ) } }, op :: MOD => { println! ( \" MOD\" ); let b = self . pop () ? ; let a = self . pop () ? ; if b == 0 { Err ( RuntimeError :: DivisionByZero ) } else { self . push ( a % b ) } }, We add a check for the DIV and MOD handlers (modulo is a division as well). If we run that program dividing by zero again, we now get this: [...] VM { stack: [4, 0], pc: 4, op_cnt: 2 } Executing op 0x13 DIV Error during execution: DivisionByZero Process finished with exit code 0 Yes, it still fails. But only the execution of the bytecode fails, not the execution of our virtual machine. You can now handle the problem inside your Rust program in a way that fits your needs. Much better. In the next post, we will be using our new instructions in a fancy way, that works well with a stack machine.","title":"Blowing up the school"},{"location":"2022-07/more-operations.html#homework","text":"Oh, not sure. Play around with it, I guess? As always. Feel free to write a calculation into a program and compare the results. It should work, unless I messed up again. You should have at least, at some point, write a program in bytecode yourself, so that you know how that feels. The source code for this post can be found under the tag v0.0.4-journey . v0.0.4-journey source code v0.0.4-journey release v0.0.4-journey.zip v0.0.4-journey.tar.gz git checkout v0.0.4-journey What does this mean?","title":"Homework"},{"location":"2022-07/parsing-the-source.html","text":"Parsing the source \u00b6 kratenko \u00b7 kratenko 2022-07-27 \u00b7 Entry #22 \u00b7 4 min read \u00b7 v0.0.8-journey So far we have read an assembly source file into a string, and we got to know some new data structures. It is time we use the one to fill the other. Let us start parsing. What we know so far is this: /// Parse assembly source code and turn it into a runnable program (or create report). pub fn assemble ( name : & str , content : & str ) -> Result < Pgm , AsmErrorReport > { let asm_pgm = AsmPgm :: parse ( name , content ); asm_pgm . to_program () } Assembler syntax \u00b6 Our experimental assembler will begin using a simple syntax. Only one instruction per line, short opnames to identify the operation to be executed, optionally a single argument. I have written a short program: hallo-stack.lass . push_u8 123 push_u8 200 add pop fin Straightforward. And you know the syntax already from my human friendly listings of bytecode. Parsing that looks simple. We do want to allow adding whitespaces, though. And we want to allow comments, for sure. Our assembler needs to handle a bit of noise, as in noice.lass . # This is an awesome program! push_u8 123 push_u8 200 # What are we using the # 200 for? add pop # let's end it here! fin Those two programs should be identical and produce the same bytecode. One line at a time \u00b6 The parse() function we call creates an empty instance of AsmPgm and then processes the source file line after line, filling the AsmPgm on the way. /// Parse an assembly program from source into `AsmPgm` struct. fn parse ( name : & str , content : & str ) -> AsmPgm { // create a new, clean instance to fill during parsing: let mut p = AsmPgm { name : String :: from ( name ), instructions : vec ! [], line_number : 0 , text_pos : 0 , error : None , }; // read the source, one line at a time, adding instructions: for ( n , line ) in content . lines (). enumerate () { p . line_number = n + 1 ; let line = AsmPgm :: clean_line ( line ); if let Err ( e ) = p . parse_line ( line ) { // Store error in program and abort parsing: p . error = Some ( e ); break ; } } p } content.lines() gives us an iterator that we can use to handle each line of the String content in a for loop. We extend the iterator by calling enumerate() on it; that gives us a different iterator, which counts the values returned by the first iterator, and adds the number to it. So n will hold the line number and line will hold the line's content. We always keep track of where we are in the source. Because the enumerate() starts counting at 0 (as things should be), we need to add 1 . File lines start counting at 1 . The first thing we do with the line is cleaning it. Then it gets processed by parse_line(line) . If this produces an error, we will store that error and abort parsing. All our errors are fatal. The final line p returns the AsmPgm . We do not use a Result this time, but the AsmPgm can contain an error. Only if its error field is None , the parsing was successful. Cleaning the noise \u00b6 /// Removes all noise from an assembler program's line. fn clean_line ( line : & str ) -> String { // Remove comments: let line = if let Some ( pair ) = line . split_once ( \"#\" ) { pair . 0 } else { & line }; // Trim start and end: let line = line . trim (); // Reduce all whitespaces to a single space (0x20): ANY_WHITESPACES . replace_all ( line , \" \" ). to_string () } We use multiple techniques to clean our input: splitting, trimming, regular expressions. When we are done, we only have lines as they look in hallo-stack.lass . The cleaned line can also be completely empty. I want to add a word about that regexp in ANY_WHITESPACES . Where does it come from? I am using some more Rust magic there, and the crate lazy_static : use lazy_static :: lazy_static ; use regex :: Regex ; // Regular expressions used by the assembler. // lazy static takes care that they are compiled only once and then reused. lazy_static ! { static ref ANY_WHITESPACES : Regex = regex :: Regex :: new ( r\"\\s+\" ). unwrap (); static ref OP_LINE_RE : Regex = regex :: Regex :: new ( r\"^(\\S+)(?: (.+))?$\" ). unwrap (); } I do not pretend to understand the macro magic that happens here. But what happens, is that the regular expressions are compiled only once and then kept as some sort of global static immutable variable, that we can than use again and again all over the program as a reference. Static references are a convenient thing in Rust, if you remember what I told you about ownership. You can always have as many references to immutable static variables, because there is nothing that can happen to them, and they exist throughout the complete runtime of the program. Parsing a clean line \u00b6 /// Handles a single cleaned line from an Assembly program. fn parse_line ( & mut self , line : String ) -> Result < (), AsmError > { if line == \"\" { // empty line (or comment only) - skip return Ok (()); } if let Some ( caps ) = OP_LINE_RE . captures ( & line ) { let opname = caps . get ( 1 ). unwrap (). as_str (); let parm = caps . get ( 2 ). map ( | m | m . as_str ()); return self . parse_instruction ( opname , parm ); } Err ( AsmError :: InvalidLine ) } parse_line() processes each line. Empty ones are just skipped. We use another regular expression, to find out if they match our schema. Because we cleaned it the expression can be rather simple: r\"^(\\S+)(?: (.+))?$\" . We look for one or more non-empty chars for our opname . It can be followed by a single argument, which must consist of one or more chars, separated by a single space. That is our optional oparg . If the line fits, we found an introduction we can try to parse. That is the job of parse_instruction() . Everything that is neither empty nor an instruction, is an error, that we can simply return. It will abort the parsing and the caller will know, that there was an invalid line. parse_instruction() can also run into an error. We use our tried pattern of returning a Result where the successful outcome does not carry any additional information (which is why we return Ok(()) ). The error case will return an AsmError, that carries the reason for the error. And because of our the Result type and because of Rust's might enum system, we can simply return what parse_instruction() returns to us. Handling the instruction itself will be handled in the next entry. The source code for this post can be found under the tag v0.0.8-journey . v0.0.8-journey source code v0.0.8-journey release v0.0.8-journey.zip v0.0.8-journey.tar.gz git checkout v0.0.8-journey What does this mean?","title":" Parsing the source"},{"location":"2022-07/parsing-the-source.html#parsing-the-source","text":"kratenko \u00b7 kratenko 2022-07-27 \u00b7 Entry #22 \u00b7 4 min read \u00b7 v0.0.8-journey So far we have read an assembly source file into a string, and we got to know some new data structures. It is time we use the one to fill the other. Let us start parsing. What we know so far is this: /// Parse assembly source code and turn it into a runnable program (or create report). pub fn assemble ( name : & str , content : & str ) -> Result < Pgm , AsmErrorReport > { let asm_pgm = AsmPgm :: parse ( name , content ); asm_pgm . to_program () }","title":"Parsing the source"},{"location":"2022-07/parsing-the-source.html#assembler-syntax","text":"Our experimental assembler will begin using a simple syntax. Only one instruction per line, short opnames to identify the operation to be executed, optionally a single argument. I have written a short program: hallo-stack.lass . push_u8 123 push_u8 200 add pop fin Straightforward. And you know the syntax already from my human friendly listings of bytecode. Parsing that looks simple. We do want to allow adding whitespaces, though. And we want to allow comments, for sure. Our assembler needs to handle a bit of noise, as in noice.lass . # This is an awesome program! push_u8 123 push_u8 200 # What are we using the # 200 for? add pop # let's end it here! fin Those two programs should be identical and produce the same bytecode.","title":"Assembler syntax"},{"location":"2022-07/parsing-the-source.html#one-line-at-a-time","text":"The parse() function we call creates an empty instance of AsmPgm and then processes the source file line after line, filling the AsmPgm on the way. /// Parse an assembly program from source into `AsmPgm` struct. fn parse ( name : & str , content : & str ) -> AsmPgm { // create a new, clean instance to fill during parsing: let mut p = AsmPgm { name : String :: from ( name ), instructions : vec ! [], line_number : 0 , text_pos : 0 , error : None , }; // read the source, one line at a time, adding instructions: for ( n , line ) in content . lines (). enumerate () { p . line_number = n + 1 ; let line = AsmPgm :: clean_line ( line ); if let Err ( e ) = p . parse_line ( line ) { // Store error in program and abort parsing: p . error = Some ( e ); break ; } } p } content.lines() gives us an iterator that we can use to handle each line of the String content in a for loop. We extend the iterator by calling enumerate() on it; that gives us a different iterator, which counts the values returned by the first iterator, and adds the number to it. So n will hold the line number and line will hold the line's content. We always keep track of where we are in the source. Because the enumerate() starts counting at 0 (as things should be), we need to add 1 . File lines start counting at 1 . The first thing we do with the line is cleaning it. Then it gets processed by parse_line(line) . If this produces an error, we will store that error and abort parsing. All our errors are fatal. The final line p returns the AsmPgm . We do not use a Result this time, but the AsmPgm can contain an error. Only if its error field is None , the parsing was successful.","title":"One line at a time"},{"location":"2022-07/parsing-the-source.html#cleaning-the-noise","text":"/// Removes all noise from an assembler program's line. fn clean_line ( line : & str ) -> String { // Remove comments: let line = if let Some ( pair ) = line . split_once ( \"#\" ) { pair . 0 } else { & line }; // Trim start and end: let line = line . trim (); // Reduce all whitespaces to a single space (0x20): ANY_WHITESPACES . replace_all ( line , \" \" ). to_string () } We use multiple techniques to clean our input: splitting, trimming, regular expressions. When we are done, we only have lines as they look in hallo-stack.lass . The cleaned line can also be completely empty. I want to add a word about that regexp in ANY_WHITESPACES . Where does it come from? I am using some more Rust magic there, and the crate lazy_static : use lazy_static :: lazy_static ; use regex :: Regex ; // Regular expressions used by the assembler. // lazy static takes care that they are compiled only once and then reused. lazy_static ! { static ref ANY_WHITESPACES : Regex = regex :: Regex :: new ( r\"\\s+\" ). unwrap (); static ref OP_LINE_RE : Regex = regex :: Regex :: new ( r\"^(\\S+)(?: (.+))?$\" ). unwrap (); } I do not pretend to understand the macro magic that happens here. But what happens, is that the regular expressions are compiled only once and then kept as some sort of global static immutable variable, that we can than use again and again all over the program as a reference. Static references are a convenient thing in Rust, if you remember what I told you about ownership. You can always have as many references to immutable static variables, because there is nothing that can happen to them, and they exist throughout the complete runtime of the program.","title":"Cleaning the noise"},{"location":"2022-07/parsing-the-source.html#parsing-a-clean-line","text":"/// Handles a single cleaned line from an Assembly program. fn parse_line ( & mut self , line : String ) -> Result < (), AsmError > { if line == \"\" { // empty line (or comment only) - skip return Ok (()); } if let Some ( caps ) = OP_LINE_RE . captures ( & line ) { let opname = caps . get ( 1 ). unwrap (). as_str (); let parm = caps . get ( 2 ). map ( | m | m . as_str ()); return self . parse_instruction ( opname , parm ); } Err ( AsmError :: InvalidLine ) } parse_line() processes each line. Empty ones are just skipped. We use another regular expression, to find out if they match our schema. Because we cleaned it the expression can be rather simple: r\"^(\\S+)(?: (.+))?$\" . We look for one or more non-empty chars for our opname . It can be followed by a single argument, which must consist of one or more chars, separated by a single space. That is our optional oparg . If the line fits, we found an introduction we can try to parse. That is the job of parse_instruction() . Everything that is neither empty nor an instruction, is an error, that we can simply return. It will abort the parsing and the caller will know, that there was an invalid line. parse_instruction() can also run into an error. We use our tried pattern of returning a Result where the successful outcome does not carry any additional information (which is why we return Ok(()) ). The error case will return an AsmError, that carries the reason for the error. And because of our the Result type and because of Rust's might enum system, we can simply return what parse_instruction() returns to us. Handling the instruction itself will be handled in the next entry. The source code for this post can be found under the tag v0.0.8-journey . v0.0.8-journey source code v0.0.8-journey release v0.0.8-journey.zip v0.0.8-journey.tar.gz git checkout v0.0.8-journey What does this mean?","title":"Parsing a clean line"},{"location":"2022-07/reverse-polish-notation.html","text":"Reverse polish notation \u00b6 We are using the design of a stack machine to efficiently execute some calculations. kratenko \u00b7 kratenko 2022-07-21 \u00b7 Entry #18 \u00b7 4 min read \u00b7 v0.0.5-journey The way stack machines work can be used in programs that execute calculations. We will look at it by implementing an example from the Wikipedia page about stack machines. I will quote a lot of it here. You can see the full text of the article and its authors when you follow the Wikipedia permalink to the article . Design Most or all stack machine instructions assume that operands will be from the stack, and results placed in the stack. The stack easily holds more than two inputs or more than one result, so a rich set of operations can be computed. In stack machine code (sometimes called p-code), instructions will frequently have only an opcode commanding an operation, with no additional fields identifying a constant, register or memory cell, known as a zero address format. 1 This greatly simplifies instruction decoding. Branches, load immediates, and load/store instructions require an argument field, but stack machines often arrange that the frequent cases of these still fit together with the opcode into a compact group of bits. \u2014 Wikipedia - retrieved 2022-07-15 So far nothing new - I wrote about all that in my earlier posts. The selection of operands from prior results is done implicitly by ordering the instructions. [...] \u2014 ibid. Now, here it gets interesting. [...] The instruction set carries out most ALU actions with postfix ( reverse Polish notation ) operations that work only on the expression stack, not on data registers or main memory cells. This can be very convenient for executing high-level languages, because most arithmetic expressions can be easily translated into postfix notation. For example, consider the expression A*(B-C)+(D+E), written in reverse Polish notation as A B C - * D E + +. Compiling and running this on a simple imaginary stack machine would take the form: # stack contents (leftmost = top = most recent): push A # A push B # B A push C # C B A subtract # B-C A multiply # A*(B-C) push D # D A*(B-C) push E # E D A*(B-C) add # D+E A*(B-C) add # A*(B-C)+(D+E) \u2014 ibid. Well, I don't know about a \"simple imaginary stack machine\" - but as it happens to be, we have a very real simple stack machine at our disposal. You know where we will be going next! Porting the code to lovem \u00b6 The program from the Wikipedia article uses 5 variables A to E . We do not support any kind of variables, yet, but that isn't important here. We use immediates (literals from your program) to put some concrete values into the calculation. Let's just take some numbers, totally at random: A = 5, B = 7, C = 11, D = 13, E = 17 And we add a new binary to the project: reverse-polish.rs //! A small program demonstrating execution of arithmetics in our VM. //! //! For an explanation of what we are doing here, look at this wikipedia article: //! https://en.wikipedia.org/w/index.php?title=Stack_machine&oldid=1097292883#Design use lovem :: { op , VM }; // A*(B-C)+(D+E) // A B C - * D E + + // A = 5, B = 7, C = 11, D = 13, E = 17 // 5 * (7 - 11) + (13 + 17) = 10 fn main () { // Create a program in bytecode. // We just hardcode the bytes in an array here: let pgm = [ op :: PUSH_U8 , 5 , op :: PUSH_U8 , 7 , op :: PUSH_U8 , 11 , op :: SUB , op :: MUL , op :: PUSH_U8 , 13 , op :: PUSH_U8 , 17 , op :: ADD , op :: ADD , op :: POP , op :: FIN ]; // Create our VM instance. let mut vm = VM :: new ( 100 ); // Execute the program in our VM: match vm . run ( & pgm ) { Ok ( _ ) => { println! ( \"Execution successful.\" ) } Err ( e ) => { println! ( \"Error during execution: {:?}\" , e ); } } } The comments spoil the result, but we want to check it calculates correctly, so that is okay. The program is the same as before: create a VM and run some hardcoded bytecode on it. Since the VM logs excessively, we will see what happens, when we run it. So the only new thing here is the bytecode program. I'll write it down in a more readable form: push_u8 5 push_u8 7 push_u8 11 sub mul push_u8 13 push_u8 17 add add pop fin To no-ones surprise, this code is the same as in the article - only with the variables replaced by numbers, and I added a pop and a fin at the end, to keep our program clean. Execution \u00b6 VM { stack: [], pc: 0, op_cnt: 0 } Executing op 0x02 PUSH_U8 value: 5 VM { stack: [5], pc: 2, op_cnt: 1 } Executing op 0x02 PUSH_U8 value: 7 VM { stack: [5, 7], pc: 4, op_cnt: 2 } Executing op 0x02 PUSH_U8 value: 11 VM { stack: [5, 7, 11], pc: 6, op_cnt: 3 } Executing op 0x11 SUB VM { stack: [5, -4], pc: 7, op_cnt: 4 } Executing op 0x12 MUL VM { stack: [-20], pc: 8, op_cnt: 5 } Executing op 0x02 PUSH_U8 value: 13 VM { stack: [-20, 13], pc: 10, op_cnt: 6 } Executing op 0x02 PUSH_U8 value: 17 VM { stack: [-20, 13, 17], pc: 12, op_cnt: 7 } Executing op 0x10 ADD VM { stack: [-20, 30], pc: 13, op_cnt: 8 } Executing op 0x10 ADD VM { stack: [10], pc: 14, op_cnt: 9 } Executing op 0x01 POP dropping value 10 VM { stack: [], pc: 15, op_cnt: 10 } Terminated! VM { stack: [], pc: 16, op_cnt: 11 } Execution successful. The output shows you the stack after every instruction. You can compare it to the stack contents in the Wikipedia listing, and you will find them identical (the order of the stack listing is switched, and of course you have numbers instead of arithmetic expressions with variables \u2013 but if you insert our numbers on the Wikipedia listing they should match). Our PoC stack machine really can do what the imaginary one is claimed to do. That's nice. Homework \u00b6 You should really read the article on Reverse Polish Notation ( permalink to article at time of writing ) . It will give some background on why it is important, not at least historically. The Z3, for example, arguably the first computer built by mankind 2 , was using it. The source code for this post can be found under the tag v0.0.5-journey . v0.0.5-journey source code v0.0.5-journey release v0.0.5-journey.zip v0.0.5-journey.tar.gz git checkout v0.0.5-journey What does this mean? Beard, Bob (Autumn 1997). \"The KDF9 Computer - 30 Years On\" . Computer RESURRECTION. \u21a9 Yeah, I know. The answer to the question \"What was the first machine to qualify as a computer?\", differs, depending on whom you ask \u2013 and also on the country you ask the question in. But the Z3 is a prominent candidate. \u21a9","title":" Reverse polish notation"},{"location":"2022-07/reverse-polish-notation.html#reverse-polish-notation","text":"We are using the design of a stack machine to efficiently execute some calculations. kratenko \u00b7 kratenko 2022-07-21 \u00b7 Entry #18 \u00b7 4 min read \u00b7 v0.0.5-journey The way stack machines work can be used in programs that execute calculations. We will look at it by implementing an example from the Wikipedia page about stack machines. I will quote a lot of it here. You can see the full text of the article and its authors when you follow the Wikipedia permalink to the article . Design Most or all stack machine instructions assume that operands will be from the stack, and results placed in the stack. The stack easily holds more than two inputs or more than one result, so a rich set of operations can be computed. In stack machine code (sometimes called p-code), instructions will frequently have only an opcode commanding an operation, with no additional fields identifying a constant, register or memory cell, known as a zero address format. 1 This greatly simplifies instruction decoding. Branches, load immediates, and load/store instructions require an argument field, but stack machines often arrange that the frequent cases of these still fit together with the opcode into a compact group of bits. \u2014 Wikipedia - retrieved 2022-07-15 So far nothing new - I wrote about all that in my earlier posts. The selection of operands from prior results is done implicitly by ordering the instructions. [...] \u2014 ibid. Now, here it gets interesting. [...] The instruction set carries out most ALU actions with postfix ( reverse Polish notation ) operations that work only on the expression stack, not on data registers or main memory cells. This can be very convenient for executing high-level languages, because most arithmetic expressions can be easily translated into postfix notation. For example, consider the expression A*(B-C)+(D+E), written in reverse Polish notation as A B C - * D E + +. Compiling and running this on a simple imaginary stack machine would take the form: # stack contents (leftmost = top = most recent): push A # A push B # B A push C # C B A subtract # B-C A multiply # A*(B-C) push D # D A*(B-C) push E # E D A*(B-C) add # D+E A*(B-C) add # A*(B-C)+(D+E) \u2014 ibid. Well, I don't know about a \"simple imaginary stack machine\" - but as it happens to be, we have a very real simple stack machine at our disposal. You know where we will be going next!","title":"Reverse polish notation"},{"location":"2022-07/reverse-polish-notation.html#porting-the-code-to-lovem","text":"The program from the Wikipedia article uses 5 variables A to E . We do not support any kind of variables, yet, but that isn't important here. We use immediates (literals from your program) to put some concrete values into the calculation. Let's just take some numbers, totally at random: A = 5, B = 7, C = 11, D = 13, E = 17 And we add a new binary to the project: reverse-polish.rs //! A small program demonstrating execution of arithmetics in our VM. //! //! For an explanation of what we are doing here, look at this wikipedia article: //! https://en.wikipedia.org/w/index.php?title=Stack_machine&oldid=1097292883#Design use lovem :: { op , VM }; // A*(B-C)+(D+E) // A B C - * D E + + // A = 5, B = 7, C = 11, D = 13, E = 17 // 5 * (7 - 11) + (13 + 17) = 10 fn main () { // Create a program in bytecode. // We just hardcode the bytes in an array here: let pgm = [ op :: PUSH_U8 , 5 , op :: PUSH_U8 , 7 , op :: PUSH_U8 , 11 , op :: SUB , op :: MUL , op :: PUSH_U8 , 13 , op :: PUSH_U8 , 17 , op :: ADD , op :: ADD , op :: POP , op :: FIN ]; // Create our VM instance. let mut vm = VM :: new ( 100 ); // Execute the program in our VM: match vm . run ( & pgm ) { Ok ( _ ) => { println! ( \"Execution successful.\" ) } Err ( e ) => { println! ( \"Error during execution: {:?}\" , e ); } } } The comments spoil the result, but we want to check it calculates correctly, so that is okay. The program is the same as before: create a VM and run some hardcoded bytecode on it. Since the VM logs excessively, we will see what happens, when we run it. So the only new thing here is the bytecode program. I'll write it down in a more readable form: push_u8 5 push_u8 7 push_u8 11 sub mul push_u8 13 push_u8 17 add add pop fin To no-ones surprise, this code is the same as in the article - only with the variables replaced by numbers, and I added a pop and a fin at the end, to keep our program clean.","title":"Porting the code to lovem"},{"location":"2022-07/reverse-polish-notation.html#execution","text":"VM { stack: [], pc: 0, op_cnt: 0 } Executing op 0x02 PUSH_U8 value: 5 VM { stack: [5], pc: 2, op_cnt: 1 } Executing op 0x02 PUSH_U8 value: 7 VM { stack: [5, 7], pc: 4, op_cnt: 2 } Executing op 0x02 PUSH_U8 value: 11 VM { stack: [5, 7, 11], pc: 6, op_cnt: 3 } Executing op 0x11 SUB VM { stack: [5, -4], pc: 7, op_cnt: 4 } Executing op 0x12 MUL VM { stack: [-20], pc: 8, op_cnt: 5 } Executing op 0x02 PUSH_U8 value: 13 VM { stack: [-20, 13], pc: 10, op_cnt: 6 } Executing op 0x02 PUSH_U8 value: 17 VM { stack: [-20, 13, 17], pc: 12, op_cnt: 7 } Executing op 0x10 ADD VM { stack: [-20, 30], pc: 13, op_cnt: 8 } Executing op 0x10 ADD VM { stack: [10], pc: 14, op_cnt: 9 } Executing op 0x01 POP dropping value 10 VM { stack: [], pc: 15, op_cnt: 10 } Terminated! VM { stack: [], pc: 16, op_cnt: 11 } Execution successful. The output shows you the stack after every instruction. You can compare it to the stack contents in the Wikipedia listing, and you will find them identical (the order of the stack listing is switched, and of course you have numbers instead of arithmetic expressions with variables \u2013 but if you insert our numbers on the Wikipedia listing they should match). Our PoC stack machine really can do what the imaginary one is claimed to do. That's nice.","title":"Execution"},{"location":"2022-07/reverse-polish-notation.html#homework","text":"You should really read the article on Reverse Polish Notation ( permalink to article at time of writing ) . It will give some background on why it is important, not at least historically. The Z3, for example, arguably the first computer built by mankind 2 , was using it. The source code for this post can be found under the tag v0.0.5-journey . v0.0.5-journey source code v0.0.5-journey release v0.0.5-journey.zip v0.0.5-journey.tar.gz git checkout v0.0.5-journey What does this mean? Beard, Bob (Autumn 1997). \"The KDF9 Computer - 30 Years On\" . Computer RESURRECTION. \u21a9 Yeah, I know. The answer to the question \"What was the first machine to qualify as a computer?\", differs, depending on whom you ask \u2013 and also on the country you ask the question in. But the Z3 is a prominent candidate. \u21a9","title":"Homework"},{"location":"2022-07/running-our-first-program.html","text":"Running our first program \u00b6 Now, that we have a VM, we will run a program on it. kratenko \u00b7 kratenko 2022-07-12 \u00b7 Entry #12 \u00b7 3 min read So we built our very first VM and studied the code in detail. It is time to execute a program on it and look at it's output. We will look at every single step the program takes. Aren't we lucky, that our VM is so talkative during execution? If you missed the code, look at the previous post, A VM . Let's go! \u00b6 /home/kratenko/.cargo/bin/cargo run --color=always --package lovem --bin lovem Finished dev [unoptimized + debuginfo] target(s) in 0.00s Running `target/debug/lovem` VM { stack: [], pc: 0, op_cnt: 0 } Executing op 0x00 NOP VM { stack: [], pc: 1, op_cnt: 1 } Executing op 0x02 PUSH_U8 value: 100 VM { stack: [100], pc: 3, op_cnt: 2 } Executing op 0x02 PUSH_U8 value: 77 VM { stack: [100, 77], pc: 5, op_cnt: 3 } Executing op 0x10 ADD VM { stack: [177], pc: 6, op_cnt: 4 } Executing op 0x01 POP dropping value 177 VM { stack: [], pc: 7, op_cnt: 5 } Terminated! VM { stack: [], pc: 8, op_cnt: 6 } Process finished with exit code 0 What just happened? \u00b6 It is quite talkative. And isn't it nice, how easy it is, to print the complete state of our VM in Rust? And it costs no overhead during runtime, as it is generated during compilation for us. Isn't that something? So, what is happening there? Our program pgm looks like this: let pgm = [ op :: NOP , op :: PUSH_U8 , 100 , op :: PUSH_U8 , 77 , op :: ADD , op :: POP , 0xff ]; That are 8 bytes that consist of 6 instructions. Each instruction has a 1 byte opcode. Two of those instructions (the PUSH_U8 ) have one byte of argument each, making up the remaining two bytes of our program. Here they are listed: NOP PUSH_U8 [100] PUSH_U8 [77] ADD POP FIN The NOP does not do anything. I just put it in front of the program to let you see fetching, decoding, and executing without any effects: VM { stack: [], pc: 0, op_cnt: 0 } Executing op 0x00 NOP VM { stack: [], pc: 1, op_cnt: 1 } We just increased the program counter by one (we advance one byte in the bytecode), and the operation counter counts this executed instruction. Let's look at the next instruction, that is more interesting: VM { stack: [], pc: 1, op_cnt: 1 } Executing op 0x02 PUSH_U8 value: 100 VM { stack: [100], pc: 3, op_cnt: 2 } Here the PC is increased by two. That happens, because we fetch an additional value from the bytecode. The op_cnt is only increased by one. And we now have our first value on the stack! It is the byte we read from the bytecode. Let's do that again: VM { stack: [100], pc: 3, op_cnt: 2 } Executing op 0x02 PUSH_U8 value: 77 VM { stack: [100, 77], pc: 5, op_cnt: 3 } Now there are two values on the stack! Time to do something with them. Let's add them up: VM { stack: [100, 77], pc: 5, op_cnt: 3 } Executing op 0x10 ADD VM { stack: [177], pc: 6, op_cnt: 4 } Now there is only one value left on the stack, and it is the sum of the two values we had. There happened quite a lot here. The two values we had before where both popped from the stack (so it was shortly empty). The add operation adds them, and pushes their sum back on the stack. So now there is one value on the stack, and it is the result of our adding operation. What's next? VM { stack: [177], pc: 6, op_cnt: 4 } Executing op 0x01 POP dropping value 177 VM { stack: [], pc: 7, op_cnt: 5 } It is always nice to leave your workplace all tidied up, when you are done. We can do that by popping our result back from the stack, leaving it empty. And besides, our POP operation prints the value it drops. One more instruction to go: VM { stack: [], pc: 7, op_cnt: 5 } Terminated! VM { stack: [], pc: 8, op_cnt: 6 } Well, not much happening there. Just stopping the VM, because we are done. Success! \u00b6 So, we ran a program in a VM. Hooray, we are done. Only 132 lines of code, including excessive comments and logging. That was easy. Well yeah - it doesn't do much. But you can understand the root principle that makes up a stack machine. It's that simple. Go play around with it a bit. It is the best way to learn and to understand. I mean it! Write a longer program. What happens to the stack? Add another opcode \u2013 how about subtraction? Will your program execute at all? What happens, if it does not?","title":" Running our first program"},{"location":"2022-07/running-our-first-program.html#running-our-first-program","text":"Now, that we have a VM, we will run a program on it. kratenko \u00b7 kratenko 2022-07-12 \u00b7 Entry #12 \u00b7 3 min read So we built our very first VM and studied the code in detail. It is time to execute a program on it and look at it's output. We will look at every single step the program takes. Aren't we lucky, that our VM is so talkative during execution? If you missed the code, look at the previous post, A VM .","title":"Running our first program"},{"location":"2022-07/running-our-first-program.html#lets-go","text":"/home/kratenko/.cargo/bin/cargo run --color=always --package lovem --bin lovem Finished dev [unoptimized + debuginfo] target(s) in 0.00s Running `target/debug/lovem` VM { stack: [], pc: 0, op_cnt: 0 } Executing op 0x00 NOP VM { stack: [], pc: 1, op_cnt: 1 } Executing op 0x02 PUSH_U8 value: 100 VM { stack: [100], pc: 3, op_cnt: 2 } Executing op 0x02 PUSH_U8 value: 77 VM { stack: [100, 77], pc: 5, op_cnt: 3 } Executing op 0x10 ADD VM { stack: [177], pc: 6, op_cnt: 4 } Executing op 0x01 POP dropping value 177 VM { stack: [], pc: 7, op_cnt: 5 } Terminated! VM { stack: [], pc: 8, op_cnt: 6 } Process finished with exit code 0","title":"Let's go!"},{"location":"2022-07/running-our-first-program.html#what-just-happened","text":"It is quite talkative. And isn't it nice, how easy it is, to print the complete state of our VM in Rust? And it costs no overhead during runtime, as it is generated during compilation for us. Isn't that something? So, what is happening there? Our program pgm looks like this: let pgm = [ op :: NOP , op :: PUSH_U8 , 100 , op :: PUSH_U8 , 77 , op :: ADD , op :: POP , 0xff ]; That are 8 bytes that consist of 6 instructions. Each instruction has a 1 byte opcode. Two of those instructions (the PUSH_U8 ) have one byte of argument each, making up the remaining two bytes of our program. Here they are listed: NOP PUSH_U8 [100] PUSH_U8 [77] ADD POP FIN The NOP does not do anything. I just put it in front of the program to let you see fetching, decoding, and executing without any effects: VM { stack: [], pc: 0, op_cnt: 0 } Executing op 0x00 NOP VM { stack: [], pc: 1, op_cnt: 1 } We just increased the program counter by one (we advance one byte in the bytecode), and the operation counter counts this executed instruction. Let's look at the next instruction, that is more interesting: VM { stack: [], pc: 1, op_cnt: 1 } Executing op 0x02 PUSH_U8 value: 100 VM { stack: [100], pc: 3, op_cnt: 2 } Here the PC is increased by two. That happens, because we fetch an additional value from the bytecode. The op_cnt is only increased by one. And we now have our first value on the stack! It is the byte we read from the bytecode. Let's do that again: VM { stack: [100], pc: 3, op_cnt: 2 } Executing op 0x02 PUSH_U8 value: 77 VM { stack: [100, 77], pc: 5, op_cnt: 3 } Now there are two values on the stack! Time to do something with them. Let's add them up: VM { stack: [100, 77], pc: 5, op_cnt: 3 } Executing op 0x10 ADD VM { stack: [177], pc: 6, op_cnt: 4 } Now there is only one value left on the stack, and it is the sum of the two values we had. There happened quite a lot here. The two values we had before where both popped from the stack (so it was shortly empty). The add operation adds them, and pushes their sum back on the stack. So now there is one value on the stack, and it is the result of our adding operation. What's next? VM { stack: [177], pc: 6, op_cnt: 4 } Executing op 0x01 POP dropping value 177 VM { stack: [], pc: 7, op_cnt: 5 } It is always nice to leave your workplace all tidied up, when you are done. We can do that by popping our result back from the stack, leaving it empty. And besides, our POP operation prints the value it drops. One more instruction to go: VM { stack: [], pc: 7, op_cnt: 5 } Terminated! VM { stack: [], pc: 8, op_cnt: 6 } Well, not much happening there. Just stopping the VM, because we are done.","title":"What just happened?"},{"location":"2022-07/running-our-first-program.html#success","text":"So, we ran a program in a VM. Hooray, we are done. Only 132 lines of code, including excessive comments and logging. That was easy. Well yeah - it doesn't do much. But you can understand the root principle that makes up a stack machine. It's that simple. Go play around with it a bit. It is the best way to learn and to understand. I mean it! Write a longer program. What happens to the stack? Add another opcode \u2013 how about subtraction? Will your program execute at all? What happens, if it does not?","title":"Success!"},{"location":"2022-07/state-of-the-journal.html","text":"State of the Journal \u00b6 Since I am always focused on my work on lovem, I will never get sidetracked. Unrelated: I spent a few days on reworking the journal on this site. kratenko \u00b7 kratenko 2022-07-01 \u00b7 Entry #5 \u00b7 3 min read So, no update on the core project today, sorry. I was very unhappy with my first solution, on how the Journal entries where created. Way too much to do by hand \u2013 that is not what I learned programming for. But mkdocs is python, and python I can do. So did. And now I can write my Journal entries (like this one) as plain Markdown files with very few metadata entries. And I get entries in the navigation and pages listing the whole month. I even included a whole month in single page version of the journal. I feel it is quite fancy. I will need to do a bit of work on the static content of the site, but one step at a time. What I want \u00b6 I want to write my Journal entries (aka blog posts) as a nice standalone markdown file, one file per entry. I will need to add include a bit of metadata, at least the release date/time. And I want the entries to look fancy without adding the fanciness to each file. Maybe I will be changing the layout later, hmm? And create those teaser pages for me, thank you very much. And I have all that, now! Just look at the source that is used to generate this entry . How it works \u00b6 I use a plugin called mkdocs-gen-files , by @oprypin , that creates additional mkdocs source files on the fly. It does not really put the files on disk, but they are parsed by mkdocs, as if they were in the docs directory. I have a directory journal next to my docs directory, where I put all my posts in a single markdown file each. My script walks through that directory, and processes each file. The content is modified a bit (to put in the card with the author's name and other metadata), and then put in a virtual file inside docs , so that the pages with the entries are created by mkdocs, as if I hat them inside docs . The script also generates two pages for each month: one that shows that month's posts as teasers, with a \"continue reading\" link, and a second one that shows all posts from a month on a single page, so that you can read them without changing pages all the time. The remaining part is adding all the pages, that the script creates, to the navigation in a way that makes sense. The order is a critical part, being a central aspect of a journal or a log. For that I use another plugin by @oprypin : mkdocs-literate-nav . With it, you can control your navigation (completely or in parts) by adding markdown source files with lists of links. This goes together well with the gen-files plugin, because I can just create that navigation files with it in my script. The plugins are a bit light on the documentation side. It took me a while to understand, that you cannot do multiple layers of nested navigation in those files. That is not a problem, because you can always just add another nesting layer by adding more of those nav files as children. Also, what you can do in those files is very limited. I wanted to do some fancy things in the navigation (adding a second link in a single line with alternative representation). I would guess that those limitations come from the ways mkdocs itself handles the navigation, so that is okay. But a word on that would have been nice. And the error messages popping up did not help at all, because the actual error happens way later in the process inside mkdocs itself and is some weird side effect problem. The script \u00b6 If you want to take a look, see blogem.py . That will be the script in its current state. For the version of the script at the time of writing, see the permalink, the original blogem.py . TODOs \u00b6 Automated reload in mkdocs serve when I edit entry sources. just add parameter -w journal to mkdocs serve Exclude journal overview and full month pages from search. Exclude NAV.md from generating NAV.html . Maybe add tags and/or categories for posts? Maybe enable comments, as in material's blog. Add links to source in github repo. Add links to entry's history in github repo. Support multiple posts per day (by adding time to \"released\").","title":" State of the Journal"},{"location":"2022-07/state-of-the-journal.html#state-of-the-journal","text":"Since I am always focused on my work on lovem, I will never get sidetracked. Unrelated: I spent a few days on reworking the journal on this site. kratenko \u00b7 kratenko 2022-07-01 \u00b7 Entry #5 \u00b7 3 min read So, no update on the core project today, sorry. I was very unhappy with my first solution, on how the Journal entries where created. Way too much to do by hand \u2013 that is not what I learned programming for. But mkdocs is python, and python I can do. So did. And now I can write my Journal entries (like this one) as plain Markdown files with very few metadata entries. And I get entries in the navigation and pages listing the whole month. I even included a whole month in single page version of the journal. I feel it is quite fancy. I will need to do a bit of work on the static content of the site, but one step at a time.","title":"State of the Journal"},{"location":"2022-07/state-of-the-journal.html#what-i-want","text":"I want to write my Journal entries (aka blog posts) as a nice standalone markdown file, one file per entry. I will need to add include a bit of metadata, at least the release date/time. And I want the entries to look fancy without adding the fanciness to each file. Maybe I will be changing the layout later, hmm? And create those teaser pages for me, thank you very much. And I have all that, now! Just look at the source that is used to generate this entry .","title":"What I want"},{"location":"2022-07/state-of-the-journal.html#how-it-works","text":"I use a plugin called mkdocs-gen-files , by @oprypin , that creates additional mkdocs source files on the fly. It does not really put the files on disk, but they are parsed by mkdocs, as if they were in the docs directory. I have a directory journal next to my docs directory, where I put all my posts in a single markdown file each. My script walks through that directory, and processes each file. The content is modified a bit (to put in the card with the author's name and other metadata), and then put in a virtual file inside docs , so that the pages with the entries are created by mkdocs, as if I hat them inside docs . The script also generates two pages for each month: one that shows that month's posts as teasers, with a \"continue reading\" link, and a second one that shows all posts from a month on a single page, so that you can read them without changing pages all the time. The remaining part is adding all the pages, that the script creates, to the navigation in a way that makes sense. The order is a critical part, being a central aspect of a journal or a log. For that I use another plugin by @oprypin : mkdocs-literate-nav . With it, you can control your navigation (completely or in parts) by adding markdown source files with lists of links. This goes together well with the gen-files plugin, because I can just create that navigation files with it in my script. The plugins are a bit light on the documentation side. It took me a while to understand, that you cannot do multiple layers of nested navigation in those files. That is not a problem, because you can always just add another nesting layer by adding more of those nav files as children. Also, what you can do in those files is very limited. I wanted to do some fancy things in the navigation (adding a second link in a single line with alternative representation). I would guess that those limitations come from the ways mkdocs itself handles the navigation, so that is okay. But a word on that would have been nice. And the error messages popping up did not help at all, because the actual error happens way later in the process inside mkdocs itself and is some weird side effect problem.","title":"How it works"},{"location":"2022-07/state-of-the-journal.html#the-script","text":"If you want to take a look, see blogem.py . That will be the script in its current state. For the version of the script at the time of writing, see the permalink, the original blogem.py .","title":"The script"},{"location":"2022-07/state-of-the-journal.html#todos","text":"Automated reload in mkdocs serve when I edit entry sources. just add parameter -w journal to mkdocs serve Exclude journal overview and full month pages from search. Exclude NAV.md from generating NAV.html . Maybe add tags and/or categories for posts? Maybe enable comments, as in material's blog. Add links to source in github repo. Add links to entry's history in github repo. Support multiple posts per day (by adding time to \"released\").","title":"TODOs"},{"location":"2022-07/to-the-library.html","text":"To the library! \u00b6 We turn our project from a binary project into a library project. kratenko \u00b7 kratenko 2022-07-18 \u00b7 Entry #15 \u00b7 5 min read \u00b7 v0.0.3-journey So far, our lovem cargo project holds a single binary. That is not very useful for something that should be integrated into other projects. What we need is a library . How is that done? Simple: we rename our main.rs to lib.rs . No main? \u00b6 But wait? What about fn main() ? We do not need that inside a library. But it would be nice to still have some code that we can execute, right? Well, no problem. Your cargo project can only hold a single library, but it can hold even multiple binaries, each with its own fn main() . Just stuff them in the bin subdir. Project layout \u00b6 While we are at it, I split the project up into multiple source files, to get it organised. It is small, still, but we will have it grow, soon. Here is, what we are at now: lovem/ src/ bin/ test-run.rs lib.rs op.rs vm.rs .gitignore Cargo.toml We skip .gitignore . If you don't know what it is, google .gitignore . Cargo.toml \u00b6 So Cargo.toml holds information about our cargo project. There is not much of interest there currently: [package] name = \"lovem\" version = \"0.0.3\" edition = \"2021\" authors = [ \"kratenko\" ] [dependencies] The only real configuration in that file is edition = \"2021\" . Rust has a major edition release every three years. These are used to introduce braking changes. You have to specify the edition you use explicitly, and there are migration guides. We use the most recent one, 2021 . lib.rs \u00b6 Rust manages projects by using default project layouts. That is why we need not write a lot into the Cargo.toml . The src directory holds our source code. The fact that it holds a lib.rs makes it a library, and lib.rs is the entry point. This is what is in it: pub mod op ; pub mod vm ; // re-export main types pub use crate :: vm :: VM ; Really not a lot. It declares the two modules op and vm and makes them public. So, whatever rust project will be using our library will have access to those modules. The modules will be in the files op.rs and vm.rs . What a coincidence, that are exactly the remaining two source files in this directory! The last line just re-exports a symbol from one of those submodules, so that programs using our library can access more easily. Will will be doing that in our binary. op.rs \u00b6 Back in v0.0.2-journey , we already had a module called op to hold the opcodes. We had it stuffed in our main.rs . Now it lives in a separate file, so we do not have to scroll over it every time. vm.rs \u00b6 This holds the rest of our source code (except for fn main() which has no place in a lib). The only new thing, compared with our former main.rs is the first line: use crate :: op ; This simply pulls the module op into the namespace of this module, so that we can access our opcode constants as we did before. The rest remains the way we already know. bin/test-run.rs \u00b6 So how do we use our lib in a project? That is best illustrated by doing it. And we can do so inside our project itself, because we can add binaries. Just put a Rust source file with a fn main() inside the bin subdir. There we can write a binary as we would in a separate project, that can use the lib. We did that in the file test-run.rs : use lovem :: { op , VM }; fn main () { // Create a program in bytecode. // We just hardcode the bytes in an array here: let pgm = [ op :: NOP , op :: PUSH_U8 , 100 , op :: PUSH_U8 , 77 , op :: ADD , op :: POP , 0xff ]; // Crate our VM instance. let mut vm = VM :: new ( 100 ); // Execute the program in our VM: match vm . run ( & pgm ) { Ok ( _ ) => { println! ( \"Execution successful.\" ) } Err ( e ) => { println! ( \"Error during execution: {:?}\" , e ); } } } This is the fn main() function from our former main.rs . Instead of having all the functions and definitions, it just has this single line at the top: use lovem :: { op , VM }; Nothing too complicated. It tells the compiler, that our program uses the library called lovem (which is, of course, the one we are writing ourselves here). It also tells it to bring the two symbols op and VM from it into our namespace. The op one is simply the module op defined in op.rs . Because lib.rs declares the module public, we can access it from here. VM does not refer to the module in vm.rs , as that module is called vm (in lower case). VM is actually the struct we defined in vm , that we use to hold the state of our Virtual Machine. We could include the struct as lovem::vm::VM , which is its full path. But I find that a bit anoying, as VM is the main type of our whole library. We will always be using that. So I re-exported it in lib.rs . Remember the line pub use crate::vm::VM; ? That's what it did. Running the binary \u00b6 So, how do we run our program now? Back in v0.0.2-journey we simply called cargo run . That actually still works, as long as we have exactly one binary. But we can have multiple binaries inside our project. If we do, we need to tell cargo which it should run. That can easily be done: cargo run --bin test-run The parameter to --bin is the name of the file inside bin , without the .rs . And no configuration is needed anywhere, it works by convention of project layout. Homework \u00b6 What, homework again? Yeah, why not. If it fits, I might keep adding ideas for you to play around with. Doing things yourself is understanding. Stuff we just read, we tend to forget. So here is what might help you understand the project layout stuff I was writing about: Add a second binary, that runs a different program in the VM (with different bytecode). You have all the knowledge to do so. And then run it with cargo. Source code \u00b6 In earlier posts I included explicit links to the source code at the time of writing. That got annoying to do really fast. So I added a new feature to my blogem.py that I use to write this journal. Entries like this, that are explaining a specific state of the source of lovem will have a tag from now on. This corresponds to a tag inside the git repository, as it did in earlier posts. You will find it in the card at the top of the post (where you see the publishing date and the author). It is prefixed with a little tag image. For this post it looks like this: v0.0.3-journey At the bottom of the entry (if you view it in the entry page, not in the \"whole month\" page), you will find it again with a list of links that help you access the source in different ways. The best way to work with the code, is to clone the repository and simply check out the tag. I also added a page on this site, explaining how you do that. You can find it under Source Code . So, in future I will not be adding explicit links, only this implicit ones. And there will be a link to the explaining page at the bottom. This should be convenient for both, you and me. The source code for this post can be found under the tag v0.0.3-journey . v0.0.3-journey source code v0.0.3-journey release v0.0.3-journey.zip v0.0.3-journey.tar.gz git checkout v0.0.3-journey What does this mean?","title":" To the library!"},{"location":"2022-07/to-the-library.html#to-the-library","text":"We turn our project from a binary project into a library project. kratenko \u00b7 kratenko 2022-07-18 \u00b7 Entry #15 \u00b7 5 min read \u00b7 v0.0.3-journey So far, our lovem cargo project holds a single binary. That is not very useful for something that should be integrated into other projects. What we need is a library . How is that done? Simple: we rename our main.rs to lib.rs .","title":"To the library!"},{"location":"2022-07/to-the-library.html#no-main","text":"But wait? What about fn main() ? We do not need that inside a library. But it would be nice to still have some code that we can execute, right? Well, no problem. Your cargo project can only hold a single library, but it can hold even multiple binaries, each with its own fn main() . Just stuff them in the bin subdir.","title":"No main?"},{"location":"2022-07/to-the-library.html#project-layout","text":"While we are at it, I split the project up into multiple source files, to get it organised. It is small, still, but we will have it grow, soon. Here is, what we are at now: lovem/ src/ bin/ test-run.rs lib.rs op.rs vm.rs .gitignore Cargo.toml We skip .gitignore . If you don't know what it is, google .gitignore .","title":"Project layout"},{"location":"2022-07/to-the-library.html#cargotoml","text":"So Cargo.toml holds information about our cargo project. There is not much of interest there currently: [package] name = \"lovem\" version = \"0.0.3\" edition = \"2021\" authors = [ \"kratenko\" ] [dependencies] The only real configuration in that file is edition = \"2021\" . Rust has a major edition release every three years. These are used to introduce braking changes. You have to specify the edition you use explicitly, and there are migration guides. We use the most recent one, 2021 .","title":"Cargo.toml"},{"location":"2022-07/to-the-library.html#librs","text":"Rust manages projects by using default project layouts. That is why we need not write a lot into the Cargo.toml . The src directory holds our source code. The fact that it holds a lib.rs makes it a library, and lib.rs is the entry point. This is what is in it: pub mod op ; pub mod vm ; // re-export main types pub use crate :: vm :: VM ; Really not a lot. It declares the two modules op and vm and makes them public. So, whatever rust project will be using our library will have access to those modules. The modules will be in the files op.rs and vm.rs . What a coincidence, that are exactly the remaining two source files in this directory! The last line just re-exports a symbol from one of those submodules, so that programs using our library can access more easily. Will will be doing that in our binary.","title":"lib.rs"},{"location":"2022-07/to-the-library.html#oprs","text":"Back in v0.0.2-journey , we already had a module called op to hold the opcodes. We had it stuffed in our main.rs . Now it lives in a separate file, so we do not have to scroll over it every time.","title":"op.rs"},{"location":"2022-07/to-the-library.html#vmrs","text":"This holds the rest of our source code (except for fn main() which has no place in a lib). The only new thing, compared with our former main.rs is the first line: use crate :: op ; This simply pulls the module op into the namespace of this module, so that we can access our opcode constants as we did before. The rest remains the way we already know.","title":"vm.rs"},{"location":"2022-07/to-the-library.html#bintest-runrs","text":"So how do we use our lib in a project? That is best illustrated by doing it. And we can do so inside our project itself, because we can add binaries. Just put a Rust source file with a fn main() inside the bin subdir. There we can write a binary as we would in a separate project, that can use the lib. We did that in the file test-run.rs : use lovem :: { op , VM }; fn main () { // Create a program in bytecode. // We just hardcode the bytes in an array here: let pgm = [ op :: NOP , op :: PUSH_U8 , 100 , op :: PUSH_U8 , 77 , op :: ADD , op :: POP , 0xff ]; // Crate our VM instance. let mut vm = VM :: new ( 100 ); // Execute the program in our VM: match vm . run ( & pgm ) { Ok ( _ ) => { println! ( \"Execution successful.\" ) } Err ( e ) => { println! ( \"Error during execution: {:?}\" , e ); } } } This is the fn main() function from our former main.rs . Instead of having all the functions and definitions, it just has this single line at the top: use lovem :: { op , VM }; Nothing too complicated. It tells the compiler, that our program uses the library called lovem (which is, of course, the one we are writing ourselves here). It also tells it to bring the two symbols op and VM from it into our namespace. The op one is simply the module op defined in op.rs . Because lib.rs declares the module public, we can access it from here. VM does not refer to the module in vm.rs , as that module is called vm (in lower case). VM is actually the struct we defined in vm , that we use to hold the state of our Virtual Machine. We could include the struct as lovem::vm::VM , which is its full path. But I find that a bit anoying, as VM is the main type of our whole library. We will always be using that. So I re-exported it in lib.rs . Remember the line pub use crate::vm::VM; ? That's what it did.","title":"bin/test-run.rs"},{"location":"2022-07/to-the-library.html#running-the-binary","text":"So, how do we run our program now? Back in v0.0.2-journey we simply called cargo run . That actually still works, as long as we have exactly one binary. But we can have multiple binaries inside our project. If we do, we need to tell cargo which it should run. That can easily be done: cargo run --bin test-run The parameter to --bin is the name of the file inside bin , without the .rs . And no configuration is needed anywhere, it works by convention of project layout.","title":"Running the binary"},{"location":"2022-07/to-the-library.html#homework","text":"What, homework again? Yeah, why not. If it fits, I might keep adding ideas for you to play around with. Doing things yourself is understanding. Stuff we just read, we tend to forget. So here is what might help you understand the project layout stuff I was writing about: Add a second binary, that runs a different program in the VM (with different bytecode). You have all the knowledge to do so. And then run it with cargo.","title":"Homework"},{"location":"2022-07/to-the-library.html#source-code","text":"In earlier posts I included explicit links to the source code at the time of writing. That got annoying to do really fast. So I added a new feature to my blogem.py that I use to write this journal. Entries like this, that are explaining a specific state of the source of lovem will have a tag from now on. This corresponds to a tag inside the git repository, as it did in earlier posts. You will find it in the card at the top of the post (where you see the publishing date and the author). It is prefixed with a little tag image. For this post it looks like this: v0.0.3-journey At the bottom of the entry (if you view it in the entry page, not in the \"whole month\" page), you will find it again with a list of links that help you access the source in different ways. The best way to work with the code, is to clone the repository and simply check out the tag. I also added a page on this site, explaining how you do that. You can find it under Source Code . So, in future I will not be adding explicit links, only this implicit ones. And there will be a link to the explaining page at the bottom. This should be convenient for both, you and me. The source code for this post can be found under the tag v0.0.3-journey . v0.0.3-journey source code v0.0.3-journey release v0.0.3-journey.zip v0.0.3-journey.tar.gz git checkout v0.0.3-journey What does this mean?","title":"Source code"},{"location":"2022-07/turn-fragile-into-rusty.html","text":"Turn \"fragile\" into \"rusty\" \u00b6 After we got our Proof of Concept running, we clean up our code and make it look like a respectable Rust program. kratenko \u00b7 kratenko 2022-07-14 \u00b7 Entry #13 \u00b7 2 min read Did you play around with the program from the previous post? If you are new to Rust, you really should! At least mess around with our bytecode. You should find, that our VM does not react well to errors, yet. It simply panics! That is no behaviour for a respectable rust program. We will make it more rusty, look at the enhanced version: Repo: https://github.com/kratenko/lovem/tree/v0.0.2-journey main.rs: https://github.com/kratenko/lovem/blob/v0.0.2-journey/src/main.rs If you do not know your way around Rust, some of those things will be difficult to understand. It might be time to read up on some Rust, if you intend to follow my journey onwards. I will not explain everything here, but I will give you some leads right now, if you want to understand the things I did in that change. It is all in the enums \u00b6 The most important thing to understand for you will be Enums . Yeah, I know. That is what I thought at first learning Rust. \"I know enums. Yeah, they are handy and useful, but what could be so interesting about them?\" Well, in fact, enums in Rust completely change the way you are writing code. They are such an important part of the language that they have an impact on just about every part of it. I introduced an enum to the code: #[derive(Debug, Clone, PartialEq)] pub enum RuntimeError { EndOfProgram , InvalidOperation ( u8 ), StackUnderflow , StackOverflow , } It is obviously a datatype to communicate runtime errors of different nature. And I use it a bit like you would exceptions in some other languages. Nevermind the #[derive...] part for now. That is just for fancy debug output (and a bit more). Once you understand line 33 : InvalidOperation(u8), , you are on the right track! To put it into easy terms: values of enums in Rust can hold additional values. And, as you see in our RuntimeError , not all values have to hold the same kind of additional value, or a value at all. This is, what makes enums really powerful. If you know what happens in the return type of fn push in line 70 , you are golden. The Result type can communicate a value on success or an error condition on failure. The great difference to typical exceptions form other languages is, that there is no special way to pass on the errors, as with exceptions that are thrown. It is just your normal return statement used. And this is done, you guessed it, with enums. If you want to read up on Result , try understanding Option first. I am using that in my code, even though you cannot see it. If you are wondering now about the return of fn push , that does not have a return statement to be seen, you should find out, while some of my lines do not have a semicolon ; at the end, while most do. And then there is that tiny ? in line 101 . Also find out what happens in the match in [line 166][line166]. It might help if you start with the if let statement. Bonus points: line 66 . If that is clear to you, you need have no worries, you are into enums and how to use them Homework \u00b6 So, this is what will get you through a lot here. Try to understand those in the given order: Option Some(v) vs. None Result<v, e> Ok(v) vs. Err(e) if let Some(v) = match Result<(), e> Ok(()) unwrap() ? Bonus: ok() , ok_or() , and their likes If you understand for each of those, and why I put them in the list, you are prepared to handle most Rust things I will be doing in the next time. If you have problems with parts of it, still, move on. It gets better after a while, when you use them.","title":" Turn \"fragile\" into \"rusty\""},{"location":"2022-07/turn-fragile-into-rusty.html#turn-fragile-into-rusty","text":"After we got our Proof of Concept running, we clean up our code and make it look like a respectable Rust program. kratenko \u00b7 kratenko 2022-07-14 \u00b7 Entry #13 \u00b7 2 min read Did you play around with the program from the previous post? If you are new to Rust, you really should! At least mess around with our bytecode. You should find, that our VM does not react well to errors, yet. It simply panics! That is no behaviour for a respectable rust program. We will make it more rusty, look at the enhanced version: Repo: https://github.com/kratenko/lovem/tree/v0.0.2-journey main.rs: https://github.com/kratenko/lovem/blob/v0.0.2-journey/src/main.rs If you do not know your way around Rust, some of those things will be difficult to understand. It might be time to read up on some Rust, if you intend to follow my journey onwards. I will not explain everything here, but I will give you some leads right now, if you want to understand the things I did in that change.","title":"Turn \"fragile\" into \"rusty\""},{"location":"2022-07/turn-fragile-into-rusty.html#it-is-all-in-the-enums","text":"The most important thing to understand for you will be Enums . Yeah, I know. That is what I thought at first learning Rust. \"I know enums. Yeah, they are handy and useful, but what could be so interesting about them?\" Well, in fact, enums in Rust completely change the way you are writing code. They are such an important part of the language that they have an impact on just about every part of it. I introduced an enum to the code: #[derive(Debug, Clone, PartialEq)] pub enum RuntimeError { EndOfProgram , InvalidOperation ( u8 ), StackUnderflow , StackOverflow , } It is obviously a datatype to communicate runtime errors of different nature. And I use it a bit like you would exceptions in some other languages. Nevermind the #[derive...] part for now. That is just for fancy debug output (and a bit more). Once you understand line 33 : InvalidOperation(u8), , you are on the right track! To put it into easy terms: values of enums in Rust can hold additional values. And, as you see in our RuntimeError , not all values have to hold the same kind of additional value, or a value at all. This is, what makes enums really powerful. If you know what happens in the return type of fn push in line 70 , you are golden. The Result type can communicate a value on success or an error condition on failure. The great difference to typical exceptions form other languages is, that there is no special way to pass on the errors, as with exceptions that are thrown. It is just your normal return statement used. And this is done, you guessed it, with enums. If you want to read up on Result , try understanding Option first. I am using that in my code, even though you cannot see it. If you are wondering now about the return of fn push , that does not have a return statement to be seen, you should find out, while some of my lines do not have a semicolon ; at the end, while most do. And then there is that tiny ? in line 101 . Also find out what happens in the match in [line 166][line166]. It might help if you start with the if let statement. Bonus points: line 66 . If that is clear to you, you need have no worries, you are into enums and how to use them","title":"It is all in the enums"},{"location":"2022-07/turn-fragile-into-rusty.html#homework","text":"So, this is what will get you through a lot here. Try to understand those in the given order: Option Some(v) vs. None Result<v, e> Ok(v) vs. Err(e) if let Some(v) = match Result<(), e> Ok(()) unwrap() ? Bonus: ok() , ok_or() , and their likes If you understand for each of those, and why I put them in the list, you are prepared to handle most Rust things I will be doing in the next time. If you have problems with parts of it, still, move on. It gets better after a while, when you use them.","title":"Homework"},{"location":"2022-07/what-is-a-virtual-machine-anyway.html","text":"What is a Virtual Machine anyway? \u00b6 kratenko \u00b7 kratenko 2022-07-04 \u00b7 Entry #7 \u00b7 5 min read So, how do you build a Virtual Machine. There are actually two quite different approaches: Register Machine vs. Stack Machine Let's take a look at those concepts first. This will be very brief and basic. You can, of course, also have some combination of those concepts, and not everything I say here is true for every implementation of virtual machine, but it will be close enough for this article. Register Machines \u00b6 Most physical computers are register machines. At least those you will be thinking of. You are most likely using one right now to read this article. Virtual register machines use the same concepts, but not in physical hardware, instead inside another computer as software. This allows them to do some things a bit more flexible than a real hardware machine would. A register is nothing more than a dedicated place to store a portion of data where it can be accessed for direct manipulation. They are more or less a variable of the machine's basic data type that have a fixed address, and that can be accessed and manipulated directly by the processing unit. Register machines use those to actually compute and change data. All other storage places are only that: places where data is put when it is not needed at the moment. Register machines have a multitude of registers, from a very few (maybe 4 or 8 in simplistic designs) to hundreds or more in modern computers. The size of the registers often gives the architecture its name. E.g. in the x86-x64 architecture, that most current CPUs by Intel and AMD are of, a register is 64 bits long. The instructions for a register machine are encoded in code words . A code word is a bunch of bytes that tell the machine what to do in the next program step. For simple designs, code words are of a fixed length. This code word length is often longer than the register size. So a 16 bit architecture could have 32 bit instructions. The reason for this is, that instructions consist of an operation code that defines what operation should be executed in the next step, but they also contain the arguments passed to that operation. Because the number and size of arguments needed for an operation differ for different operations, decoding the instruction can be quite complicated. When you put multiple instructions together, you end up with a program. This representation of a computer program is called machine code . For a virtual machine it is also called bytecode , although I think this term fits better for stack machines (more on that later). If you want to understand what I tried to describe here, read this really short article: Creating a Virtual Machine/Register VM in C . It builds a simplistic register VM in C (the whole thing is 87 lines long). It demonstrates the principles used in a register machine (fetch, decode, execute), and shows you what a register is and how it is used. You will understand, how machine code is decoded and executed. The article only uses 16 bit code words and 16 bit data words (register size). If you know C, you should be able to understand what I am talking about in about an hour of reading and coding. If you ever wanted to understand how a computer works on the inside, this might be a nice place to start, before you read about an actual physical computer. A register machine normally has multiple stacks it uses. This does not make it a stack machine, those are just needed to store data when it is not currently used. So a typical operations would be: * \"Take the number from register 0, take the number from register 1, add those two numbers together, write the result in register 0.\" * \"Take the lower 16 bits of this instruction and write them in register 2.\" Lua and Neko are virtual register machines (at least in current versions). Stack Machines \u00b6 And then there are Stack Machines . They are, I think, easier to understand than register machines, but following a program during execution is more confusing, since the manipulated data is more complicated to follow. A stack is just a pile of data. Data is portioned in fixed sizes, a portion is called a word. All you can normally do is put a word on top of the stack - we will call that operation a push , or you can take the word that is currently on top of the stack (if there is one) - we will call that a pop . No other direct manipulations of the stack are allowed (I say \"direct manipulations\", because indirectly there often are ways that this is done, but that is a detail for later). Manipulation of data is done this way by the machine. If you want to add two numbers, say 5 and 23, you would write a program that does this: Push the first number to the stack. Push the second number to the stack. Execute the \"ADD\" operation. That operation will pop the two numbers from the stack, add them, and push their sum back on the stack (so that after the operation there will be one word less on the stack). A stack machine will also typically have some additional place to store words when you do not need them on the stack. These places can relate to variables inside a program. As you can see from the example above, instructions in a stack machine often do not need to have arguments. If data is to be manipulated, it is always on top of the stack. There is no need to address its location, as you would do in a register machine. Because of this, the instructions for a stack machine are typically encoded in a single byte. This byte holds a number we will call opcode (short for operation code), that simply identifies the operation to execute. If your operation does need additional arguments, you write them to the bytes following your opcode byte (the oparg ), so that the operation can read them from your program. This structure of single bytes encoding our program is why we call this representation bytecode . The concept of a stack machine is easy to implement in software, but it is not so easy to do so in hardware. That is why your typical computer is a register machine. There are, however, a lot of historical examples of important physical stack machines. The most famous example of a virtual stack machine is the Java VM . Java source code is compiled to bytecode that is executed inside a virtual machine, the JVM. This vm is so common, that many newer programming languages compile to Java bytecode. It makes it possible to run programs written in that languages on any system that has a JVM; and that includes just about every major and many minor computer systems. A second example for a stack machine is the Python VM. Some random thought on register and stack machines \u00b6 While writing this down, describing the two kinds of machines I couldn't help but notice a curious fact: A register machine manipulates data inside addressable registers. When the data is not need, it can be stored away in some kind of stack. A stack machine manipulates data inside a stack. When the data is not needed, it can be stored away in some kind of addressable spaces, not unlike registers. It looks as if you just need both concepts to work efficiently.","title":" What is a Virtual Machine anyway?"},{"location":"2022-07/what-is-a-virtual-machine-anyway.html#what-is-a-virtual-machine-anyway","text":"kratenko \u00b7 kratenko 2022-07-04 \u00b7 Entry #7 \u00b7 5 min read So, how do you build a Virtual Machine. There are actually two quite different approaches: Register Machine vs. Stack Machine Let's take a look at those concepts first. This will be very brief and basic. You can, of course, also have some combination of those concepts, and not everything I say here is true for every implementation of virtual machine, but it will be close enough for this article.","title":"What is a Virtual Machine anyway?"},{"location":"2022-07/what-is-a-virtual-machine-anyway.html#register-machines","text":"Most physical computers are register machines. At least those you will be thinking of. You are most likely using one right now to read this article. Virtual register machines use the same concepts, but not in physical hardware, instead inside another computer as software. This allows them to do some things a bit more flexible than a real hardware machine would. A register is nothing more than a dedicated place to store a portion of data where it can be accessed for direct manipulation. They are more or less a variable of the machine's basic data type that have a fixed address, and that can be accessed and manipulated directly by the processing unit. Register machines use those to actually compute and change data. All other storage places are only that: places where data is put when it is not needed at the moment. Register machines have a multitude of registers, from a very few (maybe 4 or 8 in simplistic designs) to hundreds or more in modern computers. The size of the registers often gives the architecture its name. E.g. in the x86-x64 architecture, that most current CPUs by Intel and AMD are of, a register is 64 bits long. The instructions for a register machine are encoded in code words . A code word is a bunch of bytes that tell the machine what to do in the next program step. For simple designs, code words are of a fixed length. This code word length is often longer than the register size. So a 16 bit architecture could have 32 bit instructions. The reason for this is, that instructions consist of an operation code that defines what operation should be executed in the next step, but they also contain the arguments passed to that operation. Because the number and size of arguments needed for an operation differ for different operations, decoding the instruction can be quite complicated. When you put multiple instructions together, you end up with a program. This representation of a computer program is called machine code . For a virtual machine it is also called bytecode , although I think this term fits better for stack machines (more on that later). If you want to understand what I tried to describe here, read this really short article: Creating a Virtual Machine/Register VM in C . It builds a simplistic register VM in C (the whole thing is 87 lines long). It demonstrates the principles used in a register machine (fetch, decode, execute), and shows you what a register is and how it is used. You will understand, how machine code is decoded and executed. The article only uses 16 bit code words and 16 bit data words (register size). If you know C, you should be able to understand what I am talking about in about an hour of reading and coding. If you ever wanted to understand how a computer works on the inside, this might be a nice place to start, before you read about an actual physical computer. A register machine normally has multiple stacks it uses. This does not make it a stack machine, those are just needed to store data when it is not currently used. So a typical operations would be: * \"Take the number from register 0, take the number from register 1, add those two numbers together, write the result in register 0.\" * \"Take the lower 16 bits of this instruction and write them in register 2.\" Lua and Neko are virtual register machines (at least in current versions).","title":"Register Machines"},{"location":"2022-07/what-is-a-virtual-machine-anyway.html#stack-machines","text":"And then there are Stack Machines . They are, I think, easier to understand than register machines, but following a program during execution is more confusing, since the manipulated data is more complicated to follow. A stack is just a pile of data. Data is portioned in fixed sizes, a portion is called a word. All you can normally do is put a word on top of the stack - we will call that operation a push , or you can take the word that is currently on top of the stack (if there is one) - we will call that a pop . No other direct manipulations of the stack are allowed (I say \"direct manipulations\", because indirectly there often are ways that this is done, but that is a detail for later). Manipulation of data is done this way by the machine. If you want to add two numbers, say 5 and 23, you would write a program that does this: Push the first number to the stack. Push the second number to the stack. Execute the \"ADD\" operation. That operation will pop the two numbers from the stack, add them, and push their sum back on the stack (so that after the operation there will be one word less on the stack). A stack machine will also typically have some additional place to store words when you do not need them on the stack. These places can relate to variables inside a program. As you can see from the example above, instructions in a stack machine often do not need to have arguments. If data is to be manipulated, it is always on top of the stack. There is no need to address its location, as you would do in a register machine. Because of this, the instructions for a stack machine are typically encoded in a single byte. This byte holds a number we will call opcode (short for operation code), that simply identifies the operation to execute. If your operation does need additional arguments, you write them to the bytes following your opcode byte (the oparg ), so that the operation can read them from your program. This structure of single bytes encoding our program is why we call this representation bytecode . The concept of a stack machine is easy to implement in software, but it is not so easy to do so in hardware. That is why your typical computer is a register machine. There are, however, a lot of historical examples of important physical stack machines. The most famous example of a virtual stack machine is the Java VM . Java source code is compiled to bytecode that is executed inside a virtual machine, the JVM. This vm is so common, that many newer programming languages compile to Java bytecode. It makes it possible to run programs written in that languages on any system that has a JVM; and that includes just about every major and many minor computer systems. A second example for a stack machine is the Python VM.","title":"Stack Machines"},{"location":"2022-07/what-is-a-virtual-machine-anyway.html#some-random-thought-on-register-and-stack-machines","text":"While writing this down, describing the two kinds of machines I couldn't help but notice a curious fact: A register machine manipulates data inside addressable registers. When the data is not need, it can be stored away in some kind of stack. A stack machine manipulates data inside a stack. When the data is not needed, it can be stored away in some kind of addressable spaces, not unlike registers. It looks as if you just need both concepts to work efficiently.","title":"Some random thought on register and stack machines"},{"location":"2022-08/index.html","text":"Journal entries from August 2022 \u00b6 Read all in single page What if? \u00b6 Choose your path. kratenko \u00b7 kratenko 2022-08-19 \u00b7 Entry #27 \u00b7 6 min read \u00b7 v0.0.11-journey Our assembler gives us a lot of convenience for testing features of our VM. So let us start doing interesting stuff with it. We do have support for jumps already, but as it is now, save of an endless loop, there is absolutely no reason to do it, yet. All our programs run their predetermined way. If you look again at label.lva , you can see that none of those goto s introduce any dynamic. We could just ditch them and reorder the rest. It would do the same, only more efficient. They simple tangle up our linear code, without removing its linearity. Continue reading You labeled me, I'll label you \u00b6 We add a feature to our assembler that we overlooked before. kratenko \u00b7 kratenko 2022-08-11 \u00b7 Entry #26 \u00b7 10 min read \u00b7 v0.0.10-journey Over the last few entries we created ourselves a really useful little assembler program. I hope you played around with it and enjoyed not having to write bytecode directly. If you did, you should have noticed that I left out a really important detail. Remember when I was complaining about how bad writing bytecode is? And that it got even worth, when we introduced jumps? Yeah, I did not solve that problem at all. If anything, I made it worse, because you still have to count the relative bytes to your destination, but you do not see those bytes any longer. You just have to know, how many bytes each instruction will produce. Continue reading Running assembler programs \u00b6 We will extend our assembler to do something useful, finally: execute our programs on lovem. kratenko \u00b7 kratenko 2022-08-10 \u00b7 Entry #25 \u00b7 6 min read \u00b7 v0.0.9-journey We have created ourselves an assembler in ~300 lines of code. And it has a command line interface, an API to be used in a program, and even useful error reporting. That is cool! But what do we do with the bytecode? It just dumps them to the console. That is not very useful. We could copy/paste that into one of our example binaries... This is not what we wanted. So let us enhance our assembler. Continue reading Assembling bytes \u00b6 kratenko \u00b7 kratenko 2022-08-09 \u00b7 Entry #24 \u00b7 4 min read \u00b7 v0.0.8-journey Our new assembler is almost done assembling. Over the last entries we learned how the program parses the assembly sourcecode and produces a list of parsed instructions. What we now need to do, is turn that into bytes. Continue reading Handling instructions \u00b6 kratenko \u00b7 kratenko 2022-08-08 \u00b7 Entry #23 \u00b7 4 min read \u00b7 v0.0.8-journey We took care of all the dirty work inside the assembler during the previous posts. We now have a cleanly parsed instruction with an optional argument that we can evaluate. Let us dive into parse_instruction() : Continue reading","title":"Journal entries from August 2022"},{"location":"2022-08/index.html#journal-entries-from-august-2022","text":"Read all in single page","title":"Journal entries from August 2022"},{"location":"2022-08/index.html#what-if","text":"Choose your path. kratenko \u00b7 kratenko 2022-08-19 \u00b7 Entry #27 \u00b7 6 min read \u00b7 v0.0.11-journey Our assembler gives us a lot of convenience for testing features of our VM. So let us start doing interesting stuff with it. We do have support for jumps already, but as it is now, save of an endless loop, there is absolutely no reason to do it, yet. All our programs run their predetermined way. If you look again at label.lva , you can see that none of those goto s introduce any dynamic. We could just ditch them and reorder the rest. It would do the same, only more efficient. They simple tangle up our linear code, without removing its linearity. Continue reading","title":"What if?"},{"location":"2022-08/index.html#you-labeled-me-ill-label-you","text":"We add a feature to our assembler that we overlooked before. kratenko \u00b7 kratenko 2022-08-11 \u00b7 Entry #26 \u00b7 10 min read \u00b7 v0.0.10-journey Over the last few entries we created ourselves a really useful little assembler program. I hope you played around with it and enjoyed not having to write bytecode directly. If you did, you should have noticed that I left out a really important detail. Remember when I was complaining about how bad writing bytecode is? And that it got even worth, when we introduced jumps? Yeah, I did not solve that problem at all. If anything, I made it worse, because you still have to count the relative bytes to your destination, but you do not see those bytes any longer. You just have to know, how many bytes each instruction will produce. Continue reading","title":"You labeled me, I'll label you"},{"location":"2022-08/index.html#running-assembler-programs","text":"We will extend our assembler to do something useful, finally: execute our programs on lovem. kratenko \u00b7 kratenko 2022-08-10 \u00b7 Entry #25 \u00b7 6 min read \u00b7 v0.0.9-journey We have created ourselves an assembler in ~300 lines of code. And it has a command line interface, an API to be used in a program, and even useful error reporting. That is cool! But what do we do with the bytecode? It just dumps them to the console. That is not very useful. We could copy/paste that into one of our example binaries... This is not what we wanted. So let us enhance our assembler. Continue reading","title":"Running assembler programs"},{"location":"2022-08/index.html#assembling-bytes","text":"kratenko \u00b7 kratenko 2022-08-09 \u00b7 Entry #24 \u00b7 4 min read \u00b7 v0.0.8-journey Our new assembler is almost done assembling. Over the last entries we learned how the program parses the assembly sourcecode and produces a list of parsed instructions. What we now need to do, is turn that into bytes. Continue reading","title":"Assembling bytes"},{"location":"2022-08/index.html#handling-instructions","text":"kratenko \u00b7 kratenko 2022-08-08 \u00b7 Entry #23 \u00b7 4 min read \u00b7 v0.0.8-journey We took care of all the dirty work inside the assembler during the previous posts. We now have a cleanly parsed instruction with an optional argument that we can evaluate. Let us dive into parse_instruction() : Continue reading","title":"Handling instructions"},{"location":"2022-08/ALL.html","text":"Complete month of August 2022 \u00b6 Handling instructions \u00b6 kratenko \u00b7 kratenko 2022-08-08 \u00b7 Entry #23 \u00b7 4 min read \u00b7 v0.0.8-journey We took care of all the dirty work inside the assembler during the previous posts. We now have a cleanly parsed instruction with an optional argument that we can evaluate. Let us dive into parse_instruction() : /// Handles a single instruction of opcode an optional oparg parsed from Assembly file. fn parse_instruction ( & mut self , opname : & str , oparg : Option <& str > ) -> Result < (), AsmError > { match opname { \"nop\" => self . parse_a0_instruction ( op :: NOP , oparg ), \"fin\" => self . parse_a0_instruction ( op :: FIN , oparg ), \"pop\" => self . parse_a0_instruction ( op :: POP , oparg ), \"add\" => self . parse_a0_instruction ( op :: ADD , oparg ), \"sub\" => self . parse_a0_instruction ( op :: SUB , oparg ), \"mul\" => self . parse_a0_instruction ( op :: MUL , oparg ), \"div\" => self . parse_a0_instruction ( op :: DIV , oparg ), \"mod\" => self . parse_a0_instruction ( op :: MOD , oparg ), \"push_u8\" => { let oparg = oparg . ok_or ( AsmError :: MissingArgument ) ? ; let v = parse_int :: parse :: < u8 > ( oparg ). or ( Err ( AsmError :: InvalidArgument )) ? ; self . push_a1_instruction ( op :: PUSH_U8 , v ) }, \"goto\" => { let oparg = oparg . ok_or ( AsmError :: MissingArgument ) ? ; let v = parse_int :: parse :: < i16 > ( oparg ). or ( Err ( AsmError :: InvalidArgument )) ? ; let a = v . to_be_bytes (); self . push_a2_instruction ( op :: GOTO , a [ 0 ], a [ 1 ]) }, _ => Err ( AsmError :: UnknownInstruction ( String :: from ( opname ))) } } That is a surprisingly simple function. It receives two parameters. opname is a &str that holds the opname of the instruction. oparg is either None , if there was no argument in the instruction, or it holds a none-empty string that holds whatever argument was present in the instruction. The function only consists of a long match , that directly matches the opname against our known opnames. If there is no match, it returns a helpful error that even contains the unknown opname that was found. The explicit branches look a bit weirder. That is because I do not like to repeat myself when writing code. And Rust tends to allow some very dense source code. Different kind of instructions \u00b6 I decided to group by instructions into three categories. They are grouped by the number of bytes an instruction uses as argument. An a0 instruction has zero bytes of oparg, a1 has one byte, and a2 has two bytes. a0 \u00b6 Most of our operations do not allow any argument at all. We want to make sure that there is none given in the instruction. And the only difference in handling those instructions inside the assembler is the byte that will be written to the bytecode. We can handle all of those with the same function: parse_a0_instruction() : /// Helper that parses an instruction with no oparg and pushes it. fn parse_a0_instruction ( & mut self , opcode : u8 , oparg : Option <& str > ) -> Result < (), AsmError > { if oparg . is_some () { Err ( AsmError :: UnexpectedArgument ) } else { self . push_a0_instruction ( opcode ) } } If we did get an argument, we fail, since that is not allowed. And then we push a very basic instruction to the back of our program. We have helper functions to do that: /// Adds a single instruction to the end of the AsmProgram. fn push_instruction ( & mut self , i : AsmInstruction ) -> Result < (), AsmError > { self . text_pos += i . size (); self . instructions . push ( i ); Ok (()) } /// Helper that creates an instruction with 0 bytes of oparg and pushes it. fn push_a0_instruction ( & mut self , opcode : u8 ) -> Result < (), AsmError > { let i = AsmInstruction { line_number : self . line_number , opcode , oparg : vec ! [], pos : self . text_pos , }; self . push_instruction ( i ) } We create a new instruction instance and add it. We also track the position of every instruction in the bytecode, that is why we update the programs current position in the bytecode for every instruction we add (stored in text_pos ). There is nothing we do with that information, yet. But we will need that information later. a1: push_u8 \u00b6 We only have one operation that needs a single byte of oparg, and that is push_u8 . We use that operation to push values on the stack, taken directly from the bytecode. u8 is the only type supported at the moment. That is not even a hard restriction; you can easily get any i64 value to the stack by using basic arithmetics, and we have those. Parsing numbers is no fun. It is hard. So we let someone else do it for us. The crate we are using is called parse_int . Go take a look at what it can do. It allows us to enter numbers easily in hexadecimal, octal, or binary notation. That is a really handy feature in source code! Thanks, Rust community! So how are we parsing push_u8 ? \"push_u8\" => { let oparg = oparg . ok_or ( AsmError :: MissingArgument ) ? ; let v = parse_int :: parse :: < u8 > ( oparg ). or ( Err ( AsmError :: InvalidArgument )) ? ; self . push_a1_instruction ( op :: PUSH_U8 , v ) }, First we make sure that we have an argument. If not, we fail. We can again use our handy ? syntax. Then we try to parse it into a u8 , using parse_int . The syntax for that call takes some getting used to - I'm still waiting for me to getting used to it. But if it works, we now have a valid u8 . If it fails to parse, we quickly return with that failure information. If all goes well we will reach the third line, that calls our helper for adding a1 instructions. There is no big surprise in what that function does: /// Helper that creates an instruction with 1 byte of oparg and pushes it. fn push_a1_instruction ( & mut self , opcode : u8 , a0 : u8 ) -> Result < (), AsmError > { let i = AsmInstruction { line_number : self . line_number , opcode , oparg : vec ! [ a0 ], pos : self . text_pos , }; self . push_instruction ( i ) } An interesting detail is, that push_instruction() returns a Result , even though it can never fail! It always returns Ok(()) . And if you look at push_a2_instruction() , you will now see that it also will always return Ok(()) . We do be bother? Take a look at the handler for push_u8 again, in context of the complete function parse_instruction() . That function returns a Result , and it can return Err(...) . Because push_a1_instruction() has the same return value of Result , the calls integrate nicely with the layout of the complete function inside the match . For me, it gives the code a clean compactness. a2: goto \u00b6 There is one more branch to look at: \"goto\" => { let oparg = oparg . ok_or ( AsmError :: MissingArgument ) ? ; let v = parse_int :: parse :: < i16 > ( oparg ). or ( Err ( AsmError :: InvalidArgument )) ? ; let a = v . to_be_bytes (); self . push_a2_instruction ( op :: GOTO , a [ 0 ], a [ 1 ]) }, This time we use parse_int to read a i16 . Whether you like the ::<i16> syntax or not, at least you can see what it is for. We need to unpack the two bytes of the i16 after parsing, so that we can store the bytes correctly in the bytecode. to_be_bytes() gives us an array (of size 2) that holds the bytes in big endian byte order. to_le_bytes() is the little endian counterpart. I generally prefer big endian, when I can. And if you remember how we read the bytes in the VM, you can see that we are already using big endian there. There is nothing new in the push_a2_instruction() function, only one additional byte. /// Helper that creates an instruction with 1 byte of oparg and pushes it. fn push_a2_instruction ( & mut self , opcode : u8 , a0 : u8 , a1 : u8 ) -> Result < (), AsmError > { let i = AsmInstruction { line_number : self . line_number , opcode , oparg : vec ! [ a0 , a1 ], pos : self . text_pos , }; self . push_instruction ( i ) } Parsing completed \u00b6 We have now parsed the complete program source into the AsmPgm structure. Or we have failed to do so, in which case there is an Error stored in AsmPgm . Either way, you have now seen all the code that does the parsing. Next journal entry will finally produce the bytecode we are longing for. Assembling bytes \u00b6 kratenko \u00b7 kratenko 2022-08-09 \u00b7 Entry #24 \u00b7 4 min read \u00b7 v0.0.8-journey Our new assembler is almost done assembling. Over the last entries we learned how the program parses the assembly sourcecode and produces a list of parsed instructions. What we now need to do, is turn that into bytes. Parsed \u00b6 Let us take a look at where we are. We have our sample program hallo-stack.lass : push_u8 123 push_u8 200 add pop fin If we debug-print the AsmPgm after the parsing, it looks like this: AsmPgm { name: \"pgm/hallo-stack.lass\", instructions: [ AsmInstruction { line_number: 1, opcode: 2, oparg: [123], pos: 0 }, AsmInstruction { line_number: 2, opcode: 2, oparg: [200], pos: 2 }, AsmInstruction { line_number: 3, opcode: 16, oparg: [], pos: 4 }, AsmInstruction { line_number: 4, opcode: 1, oparg: [], pos: 5 }, AsmInstruction { line_number: 5, opcode: 255, oparg: [], pos: 6 } ], line_number: 5, text_pos: 7, error: None } No error, that is nice. And we can see all five instructions parsed. We have a function that connects those bytes. Connect the bytes \u00b6 /// Convert parsed assembly source to runnable program (or error report). fn to_program ( & self ) -> Result < Pgm , AsmErrorReport > { if let Some ( e ) = & self . error { // Assembling failed: Err ( AsmErrorReport { name : self . name . clone (), line : self . line_number , error : e . clone (), }) } else { // Assembling succeeded, return a Pgm instance: let mut text : Vec < u8 > = vec! []; for i in & self . instructions { text . push ( i . opcode ); text . extend ( & i . oparg ); } Ok ( Pgm { name : self . name . clone (), text , }) } } The error part is straightforward. A small detail is the clone() call for name and error. We need to do that, because we cannot move ownership of those values (they must still exist in the AsmPgm instance). And we cannot use references. There is no need to clone the line number; as an integer type it can simply be copied. The success part isn't complex either. We create a Vector of bytes and push all bytes into it: for each instruction the opcode and the opargs (which there can be zero). We have our bytecode now! Wrap it inside our new Pgm type, and we are done. Run the assembler \u00b6 Let us see what our program looks like, assembled: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- pgm/hallo-stack.lass Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas pgm/hallo-stack.lass` Pgm { name: \"pgm/hallo-stack.lass\", text: [2, 123, 2, 200, 16, 1, 255] } And how about our noisy program, noice.lass ? kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- pgm/noise.lass Finished dev [unoptimized + debuginfo] target(s) in 0.03s Running `target/debug/lovas pgm/noise.lass` Pgm { name: \"pgm/noise.lass\", text: [2, 123, 2, 200, 16, 1, 255] } So it does produce the same bytecode for both. As we demanded. Running into errors \u00b6 What happens, if our program has errors? Easy to find out, I included a broken program: syntax-error.lass push_u8 123 push_u8 300 add pop fin Have you found the problem? Will the assembler? kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- pgm/syntax-error.lass Finished dev [unoptimized + debuginfo] target(s) in 0.04s Running `target/debug/lovas pgm/syntax-error.lass` Error: assembly failed in line 2 of program 'pgm/syntax-error.lass' Caused by: InvalidArgument It does find the error. Using the parse_int create already pays. And the error message really tells us, what is wrong and where. We get a lot of value for very few code we have written. Why AsmPgm? \u00b6 There does not really seem to be a point of storing all that information inside AsmPgm . We could easily have created the bytecode directly. That would have been a lot easier. And if you have run the code yourself, you will have been bombarded with compiler warnings about unread fields. We will be needing that information soon, and it was easiest to build it like this right away. But let us just enjoy our new assembler for now. impl error::Error \u00b6 Okay, before we leave for today, one more thing that you might have spotted. What's with that impl blocks? impl Display for AsmError { fn fmt ( & self , f : & mut Formatter <' _ > ) -> std :: fmt :: Result { write! ( f , \"{:?}\" , self ) } } impl error :: Error for AsmError { } impl Display for AsmErrorReport { fn fmt ( & self , f : & mut Formatter <' _ > ) -> std :: fmt :: Result { write! ( f , \"assembly failed in line {} of program '{}'\" , self . line , self . name ) } } impl error :: Error for AsmErrorReport { fn source ( & self ) -> Option <& ( dyn error :: Error + ' static ) > { Some ( & self . error ) } } That is the price we have to pay when we want to use Rust magic. Rust's answer to writing generic code that can be applied to different types (that might not exist at the time of writing) are traits . A function can accept a trait as a type. If you implement that trait for your type, you can use that function. That is a very simplified introduction. A trait defines specific functions you have to write for a type. That is what we do here. We implement the trait std::error::Error for our AsmError and AsmErrorReport . To do so, we must also implement the trait std::fmt::Display (because the Error trait says so). There is not much we do there. Types implementing the Display trait can be printed using println!(\"{}\", value) . What the println! macro does is just calling that fmt method we define. The trait Debug does a similar thing, but for use with println!(\"{:?}\", value) . We can use any value with those constructs that implements the Display trait (for \"{}\" ) or the Debug trait (for \"{:?}\" ). The Debug trait we let the compiler implement (derive) for us. That is what the line #[derive(Debug)] does. And for our Display trait we are lazy and just use the function that was created by #[derive(Debug)] . The Error trait lets you implement a source() method, that is used to get a nested Error inside your Error, that was its cause. Think of exception stacks, only that we do not have exceptions, of course. That is exactly what we want for AsmErrorReport ; it is, after all, a wrapper for AsmError . AsmError on the other hand does not have a nested error, so we do not implement the source() method. The empty impl error::Error for AsmError block is still needed. If you remove it, the Error trait will not be implemented for AsmError . Cool story, but why do we do all this? This is what enables us to use the magic of anyhow in our lovas.rs . We can use AsmError and AsmErrorReport (wrapped in an Err() ) as return for our main function. It returns anyhow::Result<()> . And when there is an error returned by it, an error message is created and printed for us. With this we can easily create useful error messages in the error type itself, at the place where we understand, what errors exist and what they mean. And we need do it in that one place only. Every program that uses our library (as lovas.rs does) benefits from that without any extra work or even without knowing, error types can be returned by the library. Running assembler programs \u00b6 We will extend our assembler to do something useful, finally: execute our programs on lovem. kratenko \u00b7 kratenko 2022-08-10 \u00b7 Entry #25 \u00b7 6 min read \u00b7 v0.0.9-journey We have created ourselves an assembler in ~300 lines of code. And it has a command line interface, an API to be used in a program, and even useful error reporting. That is cool! But what do we do with the bytecode? It just dumps them to the console. That is not very useful. We could copy/paste that into one of our example binaries... This is not what we wanted. So let us enhance our assembler. Execution \u00b6 We add some features to lovas.rs . A new command line parameter --run , that takes no arguments. If you add that flag to the call, lovas will take the assembled program (if there are no errors), create an instance of the VM and run the program on it. Thanks to clap, that is really easy to do. We add another field to our Cli struct. Actually, while we are at it, we add four new parameters: # #[clap(short, long, help = \"Run the assembled program in lovem.\" )] run : bool , # #[clap(long, help = \"Enable tracing log when running lovem.\" )] trace : bool , # #[clap(long, help = \"Output the program to stdout.\" )] print : bool , # #[clap(long, default_value_t = 100, help = \"Setting the stack size for lovem when running the program.\" )] stack_size : usize , And we change what we do with a successfully created program, depending on our new flag: // run the assembler: match asm :: assemble ( & name , & content ) { Ok ( pgm ) => { if args . print { println! ( \"{:?}\" , pgm ); } // we succeeded and now have a program with bytecode: if args . run { // lovas was called with `--run`, so create a VM and execute program: run ( & pgm , & args ) ? } Ok (()) }, Err ( e ) => { // Something went wrong during assembly. // Convert the error report, so that `anyhow` can do its magic // and display some helpful error message: Err ( Error :: from ( e )) }, } Just printing the program to stdout is no very useful default behaviour for an assembler. It might still come in handy, if you want to see what you are executing, so we make it optional and for the caller to decide with the --print flag. If the --run flag is set, we call run() . So what does run() do? /// Executes a program in a freshly created lovem VM. fn run ( pgm : & Pgm , args : & Cli ) -> Result < () > { // Create our VM instance. let mut vm = VM :: new ( args . stack_size ); vm . trace = args . trace ; let start = Instant :: now (); let outcome = vm . run ( & pgm . text ); let duration = start . elapsed (); match outcome { Ok ( _ ) => { // Execution successful, program terminated: eprintln! ( \"Terminated. \\n Runtime={:?} \\n op_cnt={}, pc={}, stack-depth={}, watermark={}\" , duration , vm . op_cnt , vm . pc , vm . stack . len (), vm . watermark ); Ok (()) }, Err ( e ) => { // Runtime error. Error will be printed on return of main. eprintln! ( \"Runtime error! \\n Runtime={:?} \\n op_cnt={}, pc={}, stack-depth={}, watermark={}\" , duration , vm . op_cnt , vm . pc , vm . stack . len (), vm . watermark ); Err ( Error :: from ( e )) } } } We create a VM instance, and we run the program on it. If there is a RuntimeError , we return it, just as we did with the AsmErrorReport . Back in our examples, we created a VM with a stack size of 100 - simply because we needed a number there. 100 is still the default, but now you can choose the stack size, when calling lovas . If you do lovas --run pgm/some-program.lva --stack-size 512 lovas will execute the program in a VM with a stack that can hold 512 values. Trace Log \u00b6 When we were running a program in our VM, we did always get a lot of output during execution. That is nice for understanding, what a stack machine does, but in general it is not a got idea for a VM to do that. It can be very beneficial, if you run into a problem with your program, so it is an easily available tool for debugging. That is why I removed all those log messages from lovem, but I let some in that can be activated, if you set vm.trace = true . That is what we added the new command line parameter --trace for. You can now control, if you want to see it. Diagnostics \u00b6 There is some output by lovas , after the execution. It reports if the run was successfully terminated (by executing a fin instruction), or if there was a RuntimeError . In both cases it will show you the time the execution took (wallclock time), as well as the number of instructions executed by the VM, the final position of the programm counter, the number of values on the stack at termination, and the highest number of values on the stack at any time during execution (the watermark). This can give you some quick insight on what your program did and maybe where it ran into trouble. All this lead to some changes to vm.rs , but nothing that should give you any problems to understand. Remember that we have the power of git at our disposal, so you can easily find out what changed in a file between two releases. You could do that for vm.rs with this handy link: https://github.com/kratenko/lovem/compare/v0.0.8-journey...v0.0.9-journey#diff-3bc51552cab41d1a2dbf07842cb438088563f6134a9c69a266dfd0d79b631495 Our programs \u00b6 We have written a few example programs so far. Each is its own binary in src/bin/ , and all of them consist of the same Rust code of creating a VM and running a program. Only the bytecode changed between them. I got rid of all of those (except for the most basic one) and translated the programs into assembly programs that live in pgm/ . You can now execute those using lovas , like this: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/reverse-polish.lva --trace Compiling lovem v0.0.9 (/home/kratenko/git/lovem) Finished dev [unoptimized + debuginfo] target(s) in 2.02s Running `target/debug/lovas -r pgm/reverse-polish.lva --trace` VM { stack: [], pc: 0, op_cnt: 0, trace: true, watermark: 0 } Executing op 0x02 VM { stack: [5], pc: 2, op_cnt: 1, trace: true, watermark: 1 } Executing op 0x02 VM { stack: [5, 7], pc: 4, op_cnt: 2, trace: true, watermark: 2 } Executing op 0x02 VM { stack: [5, 7, 11], pc: 6, op_cnt: 3, trace: true, watermark: 3 } Executing op 0x11 VM { stack: [5, -4], pc: 7, op_cnt: 4, trace: true, watermark: 3 } Executing op 0x12 VM { stack: [-20], pc: 8, op_cnt: 5, trace: true, watermark: 3 } Executing op 0x02 VM { stack: [-20, 13], pc: 10, op_cnt: 6, trace: true, watermark: 3 } Executing op 0x02 VM { stack: [-20, 13, 17], pc: 12, op_cnt: 7, trace: true, watermark: 3 } Executing op 0x10 VM { stack: [-20, 30], pc: 13, op_cnt: 8, trace: true, watermark: 3 } Executing op 0x10 VM { stack: [10], pc: 14, op_cnt: 9, trace: true, watermark: 3 } Executing op 0x01 VM { stack: [], pc: 15, op_cnt: 10, trace: true, watermark: 3 } Terminated! VM { stack: [], pc: 16, op_cnt: 11, trace: true, watermark: 3 } Terminated. Runtime=49.33\u00b5s op_cnt=11, pc=16, stack size=0, watermark=3 Remember to add --trace to the call, or you won't see very much. It has become a lot easier, to play around with the VM. No more writing bytecode by hand! File extension \u00b6 You might have noticed that I changed the filename extension that I use for the assembly programs from .lass to .lva . There are multiple reasons, but the main one is, that I thought Lass could be a nice name for a programming language, when I will finally come to writing one for lovem. So I want to reserve the extension for that possible future. Playing around \u00b6 The diagnostic information given after the execution can be interesting, when you mess around. Let us play a bit with the program endless-stack.lva . ## This program runs in an endless loop, but it will push a new value to the stack on every iteration. ## It will inevitably lead to a stack overrun at some point and crash the program. push_u8 123 goto -5 fin The program will fill the stack until it is full, and then it will crash: Running `target/debug/lovas -r pgm/endless-stack.lva --print` Pgm { name: \"pgm/endless-stack.lva\", text: [2, 123, 32, 255, 251, 255] } Runtime error! Runtime=41.589\u00b5s op_cnt=201, pc=2, stack-depth=100, watermark=100 Error: StackOverflow After 201 executed instructions it crashes. The stack depth at the time of the crash is 100. That is the complete stack, the next instruction tried to push value 101, which must fail. Instruction number 201 did cause the crash. That makes sense, if you follow the execution in your head. And the program counter is on 2. The last instruction executed will be the one before that, which would be at 0. That is the push_u8 instruction. There is no surprise that the watermark is at 100. That is the highest possible value for it and also the current value of out stack depth. As we can now easily change the stack size, let us try what happens with a bigger stack: Running `target/debug/lovas -r pgm/endless-stack.lva --print --stack-size 150` Pgm { name: \"pgm/endless-stack.lva\", text: [2, 123, 32, 255, 251, 255] } Runtime error! Runtime=47.648\u00b5s op_cnt=301, pc=2, stack-depth=150, watermark=150 Error: StackOverflow So now the stack overflows at over 150 values, of course. And it takes 301 instructions to fill it. Runtime has been longer, but only about 15%. I would not have expected a rise of 50%, as there is overhead for starting the program. What happens, if we activate --trace ? Running `target/debug/lovas -r pgm/endless-stack.lva --print --stack-size 150 --trace` Pgm { name: \"pgm/endless-stack.lva\", text: [2, 123, 32, 255, 251, 255] } VM { stack: [], pc: 0, op_cnt: 0, trace: true, watermark: 0 } Executing op 0x02 VM { stack: [123], pc: 2, op_cnt: 1, trace: true, watermark: 1 } Executing op 0x20 [...] Executing op 0x02 Runtime error! Runtime=67.312973ms op_cnt=301, pc=2, stack-depth=150, watermark=150 Error: StackOverflow There is, of course, a lot of output, that I cut out. What is interesting is the change in execution time. I ran this inside the CLion IDE by JetBrains. The console there will not be a very fast console, as it does a lot with that output coming through. But the impact of the logging is enormous! The runtime until we hit our stack overflow is more than 1000 times longer! The exact numbers don't mean anything; we are running unoptimised Rust code with debuginfo, and the bottleneck is the console. But it is still fascinating to see. You labeled me, I'll label you \u00b6 We add a feature to our assembler that we overlooked before. kratenko \u00b7 kratenko 2022-08-11 \u00b7 Entry #26 \u00b7 10 min read \u00b7 v0.0.10-journey Over the last few entries we created ourselves a really useful little assembler program. I hope you played around with it and enjoyed not having to write bytecode directly. If you did, you should have noticed that I left out a really important detail. Remember when I was complaining about how bad writing bytecode is? And that it got even worth, when we introduced jumps? Yeah, I did not solve that problem at all. If anything, I made it worse, because you still have to count the relative bytes to your destination, but you do not see those bytes any longer. You just have to know, how many bytes each instruction will produce. Labels \u00b6 There was so much already going on in that assembler program, that I did not want to introduce more complexity up front. Let's fix that now: we will introduce a way to give a position inside your program a name, so that you can goto that name later. And in good tradition, we will call this names labels . The traditional way of defining labels in assembly is by writing them first thing on a line, followed by a colon : . Take a look at this little program, label.lva . It is neither good style, nor does it do anything useful, but it shows us labels: pgm/label.lva 1 2 3 4 5 6 7 8 9 10 ## A small demonstration of how labels work with goto. push_u8 1 goto coda back: push_u8 3 fin coda: push_u8 2 goto back There are two labels defined here: back in line 5, and coda in line 9. A label definition is a short string that is directly followed by a colon : . We restrict it to letters, numbers, and underscore, with a letter at the front. For the curious, the regex is: ^[A-Za-z][0-9A-Za-z_]{0,31}$ . As you can see in the example, there can be an optional instruction in the same line as the label definition. Now, how will our assembler parse those? Reconstruction \u00b6 First of all, I did a little reconstruction inside asm.rs , because I did not like how the parsing was done inside an associated function, that also created the AsmPgm instance. That seems messed up. After the change, the fn assemble() creates the instance itself and then calls a method on it, to parse the source code. Here is the new version: src/asm.rs 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 /// Parse assembly source code and turn it into a runnable program (or create report). pub fn assemble ( name : & str , content : & str ) -> Result < Pgm , AsmErrorReport > { // create a new, clean instance to fill during parsing: let mut asm_pgm = AsmPgm { name : String :: from ( name ), instructions : vec ! [], line_number : 0 , text_pos : 0 , error : None , labels : Default :: default (), }; // evaluate the source code: asm_pgm . process_assembly ( content ); // convert to Pgm instance if successful, or to Error Report, if assembly failed: asm_pgm . to_program () } And there is no problem with us changing the code like this. The only public function inside asm.rs is that pub fn assemble() . All methods of AsmPgm are private and therefore internal detail. Not that it would matter at this state of development, but it demonstrates how separation of public API and internal implementation work. What is also new in that function is a new field inside AsmPgm : labels . /// A assembler program during parsing/assembling. # #[derive(Debug)] struct AsmPgm { .. . /// A map storing label definitions by name with there position in bytecode. labels : HashMap < String , usize > , } It is a HashMap (aka. associative array in other languages). This is where we put all label definitions we find, while parsing the source file. It maps the label's name to its position inside the bytecode. Here we can look up where to jump, for a goto that wants to jump to a label. This is what our parsing methods now look like: 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 fn process ( & mut self , content : & str ) -> Result < (), AsmError > { // Go over complete source, extracting instructions. Some will have their opargs // left empty (with placeholders). self . parse ( content ) ? ; self . update_instructions () } /// Process assembly source code. Must be used with \"empty\" AsmPgm. fn process_assembly ( & mut self , content : & str ) { // this function is just a wrapper around `process()`, so that I can use the // return magic and don't need to write the error check twice. if let Err ( e ) = self . process ( content ) { self . error = Some ( e ); } } The important part is, that we have to steps now. We parse the complete source, as before. The second run is needed to write the actual relative jump address to the instructions. We do not know them during parsing, at least not for jumps forward. Parsing label definitions \u00b6 I got a little fancy again, while writing the function for parsing label definitions: 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 /// Parses and extracts optional label definition from line. /// /// Looks for a colon ':'. If one exists, the part before the first colon will be /// seen as the name for a label, that is defined on this line. Instructions inside /// the program that execute jumps can refer to these labels as a destination. /// Lines containing a label definition may also contain an instruction and/or a comment. /// This can return `AsmError::InvalidLabel` if the part before the colon is not a valid /// label name, or `AsmError::DuplicateLabel` if a label name is reused. /// If a label could be parsed, it will be stored to the `AsmPgm`. /// On success, the line without the label definition is returned, so that it can be /// used to extract an instruction. This will be the complete line, if there was no /// label definition. fn parse_label_definition <' a > ( & mut self , line : & ' a str ) -> Result <&' a str , AsmError > { if let Some (( label , rest )) = line . split_once ( \":\" ) { let label = label . trim_start (); if VALID_LABEL . is_match ( label ) { if self . labels . contains_key ( label ) { Err ( AsmError :: DuplicateLabel ( String :: from ( label ))) } else { self . labels . insert ( String :: from ( label ), self . text_pos ); Ok ( rest ) } } else { Err ( AsmError :: InvalidLabel ( String :: from ( label ))) } } else { Ok ( line ) } } The method is trying to find a label definition in the line, and if so, handles it. We use our trusted Result<> returning, to communicate potential errors. But instead of Ok(()) , which is the empty okay value, we return a &str on success. This is because there might also be an instruction in the line. If we find a label definition, it returns the line after the colon. If there is none, it returns the complete line it got. This gives us the lines as we used to get before we introduced labels. Great. But what is that weird 'a that shows up in that highlighted line everywhere? Lifetime \u00b6 Yeah, this is where it becomes rusty, again. I said, in an early post, that you would hate the Rust compiler and its pedantic error messages. The thing Rust is most pedantic about, is ownership and access to values you do not own. We are working with references to String s here. A &str references the bytes inside that String directly (a &str need not reference a String , but it does here). We did that before, where is the problem now? This is the first time we are returning a &str . When you are using references, Rust makes sure that the value you are referencing exists at least as long as the reference exists. That is easy for functions, as long as you drop every reference you have when you are done. But in this function, we return a reference to the parameter we got. Rust cannot allow that without some special care. When I remove the 'a parts of the method, I get a compilation error: error[E0623]: lifetime mismatch --> src/asm.rs:277:21 | 269 | fn parse_label_definition(&mut self, line: &str) -> Result<&str, AsmError> { | ---- ---------------------- | | | this parameter and the return type are declared with different lifetimes... ... 277 | Ok(rest) | ^^^^^^^^ ...but data from `line` is returned here | = note: each elided lifetime in input position becomes a distinct lifetime help: consider introducing a named lifetime parameter and update trait if needed | 269 | fn parse_label_definition<'a>(&'a mut self, line: &'a str) -> Result<&str, AsmError> { | ++++ ++ ++ The compiler tells me, that I messed up the lifetimes. It even proposes a change that introduces lifetime parameters (but gets it slightly wrong). What do we do with the 'a ? Well we introduce a lifetime parameter called a . The syntax for that is the apostrophe, which looked weird to me at start, but it is so lightweight, that I came to like it. It is custom, to just call your lifetimes 'a , 'b , ... \u2013 they normally don't have a long scope anyway. The thing we are telling the compiler with this parameter is this: the lifetime of the returned &str is dependent on the lifetime of the parameter line: &str . So whenever the reference the function is called with runs out of scope, the reference that was returned must be out of scope as well. An example \u00b6 This is a concept that is new to many programmers when they learn Rust. I think, what we do here demonstrates it quiet well. Let us look at what happens for line 9 of our assembly program: pgm/label.lva 9 coda: push_u8 2 Our function receives a reference to a String holding that line: \" coda: push_u8 2\" . It finds the label coda and stores it inside self.labels . Its work is done, but there might be more to this line. It returns a reference to a substring of it ( &str are actually slices; they can reference only a part of a String 's data). That is what we return, a reference to the part data inside the String , starting at the first char after the colon, so it looks like this \" push_u8 2\" . It is not a copy, it is the same area inside the computer's memory! So if you want to make certain, that there are no accesses to memory after its content has run out of scope (use after free, or use of local variable after it runs our of scope), you must not allow access to it, unless you are sure the value still exists. And this is what Rust does. This is what makes Rust a secure language. Many bugs and exploits in the world exist, because most languages do not check this, but leave the responsibility to the programmer. And the really cool thing about Rust is, it does this completely at compile time, as you can see by the fact that we got a compiler error. The way we call our function is not a problem at all: src/asm.rs 292 293 294 295 296 297 298 for ( n , line ) in content . lines (). enumerate () { // File lines start counting at 1: self . line_number = n + 1 ; let line = self . parse_label_definition ( line ) ? ; let line = AsmPgm :: clean_line ( line ); self . parse_clean_line ( line ) ? ; } Our initial line comes from line 228. It is already a reference, because content.lines() is also giving us a reference to the memory inside of content . That is a reference already, the String variable that holds (and owns) the data lives inside lovas.rs : src/bin/lovas.rs 67 68 69 70 71 72 73 // read complete source file into String: let content = std :: fs :: read_to_string ( & args . source ) . with_context ( || format! ( \"could not read file `{}`\" , & name ) ) ? ; // run the assembler: match asm :: assemble ( & name , & content ) { We do not copy any of that bytes along the way. The first time we do that is in clean_line() . Returning a &str will not work there, because we actually modify the contents of the string, by replacing characters inside it. Have you ever tried to work with inplace \"substrings\" (I mean char arrays, like this char *str ), without modifying the contents (placing \\0 bytes). It is not fun. In Rust, it can be, if you understand lifetime restrictions. Easy way out \u00b6 If you run into problems with your &str inside a Rust program, there is often an easy way to get around that. You can simply create a new String from your &str , as we do in clean_line() . That will copy the bytes. For our program, that would have been no problem at all. Cloning a few bytes of source code for every line during assembly would cost us next to nothing. You would not notice in execution time. But things are different when you need to quickly handle long substrings in a program. Think of a diagnostic job on a busy server. And remember that String s will be created on the heap. That is a complexity that you sometimes want to avoid. When programming microcontrollers, there is a chance that you do not even have a memory allocator at your disposal. And microcontrollers is, what we are aiming for in our project. There are already some parts of lovem, that we will need to change, because of that. But that is a story for another time. I just thought that this was a nice little example to introduce you to lifetime parameters. We will need them at some point... Run it already! \u00b6 This is a long entry already. You can look at the complete state of the assembler directly in the sourcecode. You should know how to find the tags inside the repo by now. But I want to execute our new program, using the labels, before I end this. Here it is again: pgm/label.lva 1 2 3 4 5 6 7 8 9 10 ## A small demonstration of how labels work with goto. push_u8 1 goto coda back: push_u8 3 fin coda: push_u8 2 goto back We need to execute it with the --trace flag, or we will not see anything: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/label.lva --print --trace Compiling lovem v0.0.10 (/home/kratenko/git/lovem) Finished dev [unoptimized + debuginfo] target(s) in 1.33s Running `target/debug/lovas -r pgm/label.lva --print --trace` Pgm { name: \"pgm/label.lva\", text: [2, 1, 32, 0, 3, 2, 3, 255, 2, 2, 32, 255, 248] } VM { stack: [], pc: 0, op_cnt: 0, trace: true, watermark: 0 } Executing op 0x02 VM { stack: [1], pc: 2, op_cnt: 1, trace: true, watermark: 1 } Executing op 0x20 Jump from 5 by 3 VM { stack: [1], pc: 8, op_cnt: 2, trace: true, watermark: 1 } Executing op 0x02 VM { stack: [1, 2], pc: 10, op_cnt: 3, trace: true, watermark: 2 } Executing op 0x20 Jump from 13 by -8 VM { stack: [1, 2], pc: 5, op_cnt: 4, trace: true, watermark: 2 } Executing op 0x02 VM { stack: [1, 2, 3], pc: 7, op_cnt: 5, trace: true, watermark: 3 } Terminated! VM { stack: [1, 2, 3], pc: 8, op_cnt: 6, trace: true, watermark: 3 } Terminated. Runtime=65.598\u00b5s op_cnt=6, pc=8, stack-depth=3, watermark=3 The program has three push_u8 operations. If you executed them in the order of the source code, they would push [1, 3, 2] to the stack. But because of the goto instructions, they are not executed in that order. You can see the jumps in the trace, and you can see that the stack at termination holds the values in this order: [1, 2, 3] . Not much of a program, but it shows you, how our new labels work. And finally: no more counting bytes! Homework \u00b6 Our programs endless.lva and endless-stack.lva no longer work, because we changed how the goto instruction must be written. Can you fix them? What if? \u00b6 Choose your path. kratenko \u00b7 kratenko 2022-08-19 \u00b7 Entry #27 \u00b7 6 min read \u00b7 v0.0.11-journey Our assembler gives us a lot of convenience for testing features of our VM. So let us start doing interesting stuff with it. We do have support for jumps already, but as it is now, save of an endless loop, there is absolutely no reason to do it, yet. All our programs run their predetermined way. If you look again at label.lva , you can see that none of those goto s introduce any dynamic. We could just ditch them and reorder the rest. It would do the same, only more efficient. They simple tangle up our linear code, without removing its linearity. Today we will introduce branches to our VM. A branch is a point in a program from which there are multiple possible paths to take. Two paths, normally. Which of those paths is takes is decided at runtime by looking at the state of the program. For us that means that we look at the value on top of the stack. How does it work? Conditional jump \u00b6 We already introduced the goto operation. What we will add now, works exactly the same way, but only if a certain condition is met. And, yes, we will call that operation if . But if what? How about if equal ? So we get the new opname ifeq , that pops a value from the stack and only executes its jump when that value is equal. Equal to what, you want to know? How about if it is equal to zero. If you want to compare it to a different number, it is easy to subtract that number from your value before you compare it to zero, and you achieve what you need. New operations \u00b6 We will introduce multiple if-operations. Six, to be precise. src/op.rs 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 /// opcode: Conditional relative jump (branch) on pop == zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFEQ : u8 = 0x21 ; /// opcode: Conditional relative jump (branch) on pop != zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFNE : u8 = 0x22 ; /// opcode: Conditional relative jump (branch) on pop < zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFLT : u8 = 0x23 ; /// opcode: Conditional relative jump (branch) on pop <= zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFLE : u8 = 0x24 ; /// opcode: Conditional relative jump (branch) on pop > zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFGT : u8 = 0x25 ; /// opcode: Conditional relative jump (branch) on pop >= zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFGE : u8 = 0x26 ; And we add another operation, while we add it: dup src/op.rs 21 22 23 24 25 /// opcode: Pop value from stack and push it back, twice. /// /// pop: 1, push: 2 /// oparg: 0 pub const DUP : u8 = 0x03 ; This one simply duplicates the value on top of the stack, so that there will be another copy of it on top of it. We will use that often when testing values with an if , if we still need the value after testing it. The if will consume the top most value. Extending the assembler \u00b6 We add the parsing handlers for our new instructions: src/asm.rs 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 fn parse_instruction ( & mut self , opname : & str , oparg : Option <& str > ) -> Result < (), AsmError > { match opname { \"nop\" => self . parse_a0_instruction ( op :: NOP , oparg ), \"fin\" => self . parse_a0_instruction ( op :: FIN , oparg ), \"pop\" => self . parse_a0_instruction ( op :: POP , oparg ), \"dup\" => self . parse_a0_instruction ( op :: DUP , oparg ), \"add\" => self . parse_a0_instruction ( op :: ADD , oparg ), \"sub\" => self . parse_a0_instruction ( op :: SUB , oparg ), \"mul\" => self . parse_a0_instruction ( op :: MUL , oparg ), \"div\" => self . parse_a0_instruction ( op :: DIV , oparg ), \"mod\" => self . parse_a0_instruction ( op :: MOD , oparg ), \"push_u8\" => { let oparg = oparg . ok_or ( AsmError :: MissingArgument ) ? ; let v = parse_int :: parse :: < u8 > ( oparg ). or ( Err ( AsmError :: InvalidArgument )) ? ; self . push_a1_instruction ( op :: PUSH_U8 , v ) }, \"goto\" => self . parse_label_instruction ( op :: GOTO , oparg ), \"ifeq\" => self . parse_label_instruction ( op :: IFEQ , oparg ), \"ifne\" => self . parse_label_instruction ( op :: IFNE , oparg ), \"iflt\" => self . parse_label_instruction ( op :: IFLT , oparg ), \"ifle\" => self . parse_label_instruction ( op :: IFLE , oparg ), \"ifgt\" => self . parse_label_instruction ( op :: IFGT , oparg ), \"ifge\" => self . parse_label_instruction ( op :: IFGE , oparg ), _ => Err ( AsmError :: UnknownInstruction ( String :: from ( opname ))) } } And that is all we need to change on our assembler. The way we have written it, it is easy to introduce new operations, when they share the same syntax in assembly and in bytecode as existing ones. Adjust the VM \u00b6 First, we add the handler for the dup . Just pop a value and push it back, twice. Easy. src/vm.rs 175 176 177 178 179 180 op :: DUP => { let v = self . pop () ? ; self . push ( v ) ? ; self . push ( v ) ? ; Ok (()) }, And now, the if* -handlers. They are similar to the goto -handler, just with an if added. src/vm.rs 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 op :: GOTO => { let d = self . fetch_i16 ( pgm ) ? ; self . relative_jump ( pgm , d ) }, op :: IFEQ => { let d = self . fetch_i16 ( pgm ) ? ; let v = self . pop () ? ; if v == 0 { self . relative_jump ( pgm , d ) } else { Ok (()) } }, op :: IFNE => { let d = self . fetch_i16 ( pgm ) ? ; let v = self . pop () ? ; if v != 0 { self . relative_jump ( pgm , d ) } else { Ok (()) } }, op :: IFLT => { let d = self . fetch_i16 ( pgm ) ? ; let v = self . pop () ? ; if v < 0 { self . relative_jump ( pgm , d ) } else { Ok (()) } }, op :: IFLE => { let d = self . fetch_i16 ( pgm ) ? ; let v = self . pop () ? ; if v <= 0 { self . relative_jump ( pgm , d ) } else { Ok (()) } }, op :: IFGT => { let d = self . fetch_i16 ( pgm ) ? ; let v = self . pop () ? ; if v > 0 { self . relative_jump ( pgm , d ) } else { Ok (()) } }, op :: IFGE => { let d = self . fetch_i16 ( pgm ) ? ; let v = self . pop () ? ; if v >= 0 { self . relative_jump ( pgm , d ) } else { Ok (()) } }, And that is all the code we have to change. Our VM can now execute conditional jumps. Now we can do some serious programming! A for-loop \u00b6 Can't wait to use an if in program: pgm/loop.lva 1 2 3 4 5 6 7 8 9 10 ## Demonstrate the conditional jump (a branch) ## The program has a loop that it executes thrice, before it terminates. push_u8 3 loop: push_u8 1 sub dup ifgt loop pop fin And execute it: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/loop.lva --print --trace Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas -r pgm/loop.lva --print --trace` Pgm { name: \"pgm/loop.lva\", text: [2, 3, 2, 1, 17, 3, 37, 255, 249, 1, 255] } VM { stack: [], pc: 0, op_cnt: 0, trace: true, watermark: 0 } Executing op 0x02 VM { stack: [3], pc: 2, op_cnt: 1, trace: true, watermark: 1 } Executing op 0x02 VM { stack: [3, 1], pc: 4, op_cnt: 2, trace: true, watermark: 2 } Executing op 0x11 VM { stack: [2], pc: 5, op_cnt: 3, trace: true, watermark: 2 } Executing op 0x03 VM { stack: [2, 2], pc: 6, op_cnt: 4, trace: true, watermark: 2 } Executing op 0x25 Jump from 9 by -7 VM { stack: [2], pc: 2, op_cnt: 5, trace: true, watermark: 2 } Executing op 0x02 VM { stack: [2, 1], pc: 4, op_cnt: 6, trace: true, watermark: 2 } Executing op 0x11 VM { stack: [1], pc: 5, op_cnt: 7, trace: true, watermark: 2 } Executing op 0x03 VM { stack: [1, 1], pc: 6, op_cnt: 8, trace: true, watermark: 2 } Executing op 0x25 Jump from 9 by -7 VM { stack: [1], pc: 2, op_cnt: 9, trace: true, watermark: 2 } Executing op 0x02 VM { stack: [1, 1], pc: 4, op_cnt: 10, trace: true, watermark: 2 } Executing op 0x11 VM { stack: [0], pc: 5, op_cnt: 11, trace: true, watermark: 2 } Executing op 0x03 VM { stack: [0, 0], pc: 6, op_cnt: 12, trace: true, watermark: 2 } Executing op 0x25 VM { stack: [0], pc: 9, op_cnt: 13, trace: true, watermark: 2 } Executing op 0x01 VM { stack: [], pc: 10, op_cnt: 14, trace: true, watermark: 2 } Terminated! VM { stack: [], pc: 11, op_cnt: 15, trace: true, watermark: 2 } Terminated. Runtime=100.972\u00b5s op_cnt=15, pc=11, stack-depth=0, watermark=2 Nice! This is basically a for-loop. Granted, it does not do anything but loop, but you can see how the program counts down from 3 to 0 and after the third time it reaches line 8, it stops jumping back to loop: and advances to the end. We can increase the number in line 3, and the number of runs increase with it. If we change it to 200 , we get this (I ditched the --trace for this). kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/loop.lva --print Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas -r pgm/loop.lva --print` Pgm { name: \"pgm/loop.lva\", text: [2, 200, 2, 1, 17, 3, 37, 255, 249, 1, 255] } Terminated. Runtime=128.709\u00b5s op_cnt=803, pc=11, stack-depth=0, watermark=2 More than 800 operations with only 10 lines of code. Shall we cranc it up to a million? kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/loop.lva --print Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas -r pgm/loop.lva --print` Pgm { name: \"pgm/loop.lva\", text: [2, 100, 2, 100, 18, 2, 100, 18, 2, 1, 17, 3, 37, 255, 249, 1, 255] } Terminated. Runtime=564.184652ms op_cnt=4000007, pc=17, stack-depth=0, watermark=2 Takes about have a second to execute, over 4000000 operations where executed. And the stack never held more than 2 values, as you can see by the watermark. We are programming! Homework \u00b6 Wait a second! Our only way of getting values on the stack is push_u8 . That can only push a u8 , so only values 0 - 255 . How did I push that 1000000 there?","title":"August 2022 complete"},{"location":"2022-08/ALL.html#complete-month-of-august-2022","text":"","title":"Complete month of August 2022"},{"location":"2022-08/ALL.html#handling-instructions","text":"kratenko \u00b7 kratenko 2022-08-08 \u00b7 Entry #23 \u00b7 4 min read \u00b7 v0.0.8-journey We took care of all the dirty work inside the assembler during the previous posts. We now have a cleanly parsed instruction with an optional argument that we can evaluate. Let us dive into parse_instruction() : /// Handles a single instruction of opcode an optional oparg parsed from Assembly file. fn parse_instruction ( & mut self , opname : & str , oparg : Option <& str > ) -> Result < (), AsmError > { match opname { \"nop\" => self . parse_a0_instruction ( op :: NOP , oparg ), \"fin\" => self . parse_a0_instruction ( op :: FIN , oparg ), \"pop\" => self . parse_a0_instruction ( op :: POP , oparg ), \"add\" => self . parse_a0_instruction ( op :: ADD , oparg ), \"sub\" => self . parse_a0_instruction ( op :: SUB , oparg ), \"mul\" => self . parse_a0_instruction ( op :: MUL , oparg ), \"div\" => self . parse_a0_instruction ( op :: DIV , oparg ), \"mod\" => self . parse_a0_instruction ( op :: MOD , oparg ), \"push_u8\" => { let oparg = oparg . ok_or ( AsmError :: MissingArgument ) ? ; let v = parse_int :: parse :: < u8 > ( oparg ). or ( Err ( AsmError :: InvalidArgument )) ? ; self . push_a1_instruction ( op :: PUSH_U8 , v ) }, \"goto\" => { let oparg = oparg . ok_or ( AsmError :: MissingArgument ) ? ; let v = parse_int :: parse :: < i16 > ( oparg ). or ( Err ( AsmError :: InvalidArgument )) ? ; let a = v . to_be_bytes (); self . push_a2_instruction ( op :: GOTO , a [ 0 ], a [ 1 ]) }, _ => Err ( AsmError :: UnknownInstruction ( String :: from ( opname ))) } } That is a surprisingly simple function. It receives two parameters. opname is a &str that holds the opname of the instruction. oparg is either None , if there was no argument in the instruction, or it holds a none-empty string that holds whatever argument was present in the instruction. The function only consists of a long match , that directly matches the opname against our known opnames. If there is no match, it returns a helpful error that even contains the unknown opname that was found. The explicit branches look a bit weirder. That is because I do not like to repeat myself when writing code. And Rust tends to allow some very dense source code.","title":"Handling instructions"},{"location":"2022-08/ALL.html#different-kind-of-instructions","text":"I decided to group by instructions into three categories. They are grouped by the number of bytes an instruction uses as argument. An a0 instruction has zero bytes of oparg, a1 has one byte, and a2 has two bytes.","title":"Different kind of instructions"},{"location":"2022-08/ALL.html#a0","text":"Most of our operations do not allow any argument at all. We want to make sure that there is none given in the instruction. And the only difference in handling those instructions inside the assembler is the byte that will be written to the bytecode. We can handle all of those with the same function: parse_a0_instruction() : /// Helper that parses an instruction with no oparg and pushes it. fn parse_a0_instruction ( & mut self , opcode : u8 , oparg : Option <& str > ) -> Result < (), AsmError > { if oparg . is_some () { Err ( AsmError :: UnexpectedArgument ) } else { self . push_a0_instruction ( opcode ) } } If we did get an argument, we fail, since that is not allowed. And then we push a very basic instruction to the back of our program. We have helper functions to do that: /// Adds a single instruction to the end of the AsmProgram. fn push_instruction ( & mut self , i : AsmInstruction ) -> Result < (), AsmError > { self . text_pos += i . size (); self . instructions . push ( i ); Ok (()) } /// Helper that creates an instruction with 0 bytes of oparg and pushes it. fn push_a0_instruction ( & mut self , opcode : u8 ) -> Result < (), AsmError > { let i = AsmInstruction { line_number : self . line_number , opcode , oparg : vec ! [], pos : self . text_pos , }; self . push_instruction ( i ) } We create a new instruction instance and add it. We also track the position of every instruction in the bytecode, that is why we update the programs current position in the bytecode for every instruction we add (stored in text_pos ). There is nothing we do with that information, yet. But we will need that information later.","title":"a0"},{"location":"2022-08/ALL.html#a1-push_u8","text":"We only have one operation that needs a single byte of oparg, and that is push_u8 . We use that operation to push values on the stack, taken directly from the bytecode. u8 is the only type supported at the moment. That is not even a hard restriction; you can easily get any i64 value to the stack by using basic arithmetics, and we have those. Parsing numbers is no fun. It is hard. So we let someone else do it for us. The crate we are using is called parse_int . Go take a look at what it can do. It allows us to enter numbers easily in hexadecimal, octal, or binary notation. That is a really handy feature in source code! Thanks, Rust community! So how are we parsing push_u8 ? \"push_u8\" => { let oparg = oparg . ok_or ( AsmError :: MissingArgument ) ? ; let v = parse_int :: parse :: < u8 > ( oparg ). or ( Err ( AsmError :: InvalidArgument )) ? ; self . push_a1_instruction ( op :: PUSH_U8 , v ) }, First we make sure that we have an argument. If not, we fail. We can again use our handy ? syntax. Then we try to parse it into a u8 , using parse_int . The syntax for that call takes some getting used to - I'm still waiting for me to getting used to it. But if it works, we now have a valid u8 . If it fails to parse, we quickly return with that failure information. If all goes well we will reach the third line, that calls our helper for adding a1 instructions. There is no big surprise in what that function does: /// Helper that creates an instruction with 1 byte of oparg and pushes it. fn push_a1_instruction ( & mut self , opcode : u8 , a0 : u8 ) -> Result < (), AsmError > { let i = AsmInstruction { line_number : self . line_number , opcode , oparg : vec ! [ a0 ], pos : self . text_pos , }; self . push_instruction ( i ) } An interesting detail is, that push_instruction() returns a Result , even though it can never fail! It always returns Ok(()) . And if you look at push_a2_instruction() , you will now see that it also will always return Ok(()) . We do be bother? Take a look at the handler for push_u8 again, in context of the complete function parse_instruction() . That function returns a Result , and it can return Err(...) . Because push_a1_instruction() has the same return value of Result , the calls integrate nicely with the layout of the complete function inside the match . For me, it gives the code a clean compactness.","title":"a1: push_u8"},{"location":"2022-08/ALL.html#a2-goto","text":"There is one more branch to look at: \"goto\" => { let oparg = oparg . ok_or ( AsmError :: MissingArgument ) ? ; let v = parse_int :: parse :: < i16 > ( oparg ). or ( Err ( AsmError :: InvalidArgument )) ? ; let a = v . to_be_bytes (); self . push_a2_instruction ( op :: GOTO , a [ 0 ], a [ 1 ]) }, This time we use parse_int to read a i16 . Whether you like the ::<i16> syntax or not, at least you can see what it is for. We need to unpack the two bytes of the i16 after parsing, so that we can store the bytes correctly in the bytecode. to_be_bytes() gives us an array (of size 2) that holds the bytes in big endian byte order. to_le_bytes() is the little endian counterpart. I generally prefer big endian, when I can. And if you remember how we read the bytes in the VM, you can see that we are already using big endian there. There is nothing new in the push_a2_instruction() function, only one additional byte. /// Helper that creates an instruction with 1 byte of oparg and pushes it. fn push_a2_instruction ( & mut self , opcode : u8 , a0 : u8 , a1 : u8 ) -> Result < (), AsmError > { let i = AsmInstruction { line_number : self . line_number , opcode , oparg : vec ! [ a0 , a1 ], pos : self . text_pos , }; self . push_instruction ( i ) }","title":"a2: goto"},{"location":"2022-08/ALL.html#parsing-completed","text":"We have now parsed the complete program source into the AsmPgm structure. Or we have failed to do so, in which case there is an Error stored in AsmPgm . Either way, you have now seen all the code that does the parsing. Next journal entry will finally produce the bytecode we are longing for.","title":"Parsing completed"},{"location":"2022-08/ALL.html#assembling-bytes","text":"kratenko \u00b7 kratenko 2022-08-09 \u00b7 Entry #24 \u00b7 4 min read \u00b7 v0.0.8-journey Our new assembler is almost done assembling. Over the last entries we learned how the program parses the assembly sourcecode and produces a list of parsed instructions. What we now need to do, is turn that into bytes.","title":"Assembling bytes"},{"location":"2022-08/ALL.html#parsed","text":"Let us take a look at where we are. We have our sample program hallo-stack.lass : push_u8 123 push_u8 200 add pop fin If we debug-print the AsmPgm after the parsing, it looks like this: AsmPgm { name: \"pgm/hallo-stack.lass\", instructions: [ AsmInstruction { line_number: 1, opcode: 2, oparg: [123], pos: 0 }, AsmInstruction { line_number: 2, opcode: 2, oparg: [200], pos: 2 }, AsmInstruction { line_number: 3, opcode: 16, oparg: [], pos: 4 }, AsmInstruction { line_number: 4, opcode: 1, oparg: [], pos: 5 }, AsmInstruction { line_number: 5, opcode: 255, oparg: [], pos: 6 } ], line_number: 5, text_pos: 7, error: None } No error, that is nice. And we can see all five instructions parsed. We have a function that connects those bytes.","title":"Parsed"},{"location":"2022-08/ALL.html#connect-the-bytes","text":"/// Convert parsed assembly source to runnable program (or error report). fn to_program ( & self ) -> Result < Pgm , AsmErrorReport > { if let Some ( e ) = & self . error { // Assembling failed: Err ( AsmErrorReport { name : self . name . clone (), line : self . line_number , error : e . clone (), }) } else { // Assembling succeeded, return a Pgm instance: let mut text : Vec < u8 > = vec! []; for i in & self . instructions { text . push ( i . opcode ); text . extend ( & i . oparg ); } Ok ( Pgm { name : self . name . clone (), text , }) } } The error part is straightforward. A small detail is the clone() call for name and error. We need to do that, because we cannot move ownership of those values (they must still exist in the AsmPgm instance). And we cannot use references. There is no need to clone the line number; as an integer type it can simply be copied. The success part isn't complex either. We create a Vector of bytes and push all bytes into it: for each instruction the opcode and the opargs (which there can be zero). We have our bytecode now! Wrap it inside our new Pgm type, and we are done.","title":"Connect the bytes"},{"location":"2022-08/ALL.html#run-the-assembler","text":"Let us see what our program looks like, assembled: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- pgm/hallo-stack.lass Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas pgm/hallo-stack.lass` Pgm { name: \"pgm/hallo-stack.lass\", text: [2, 123, 2, 200, 16, 1, 255] } And how about our noisy program, noice.lass ? kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- pgm/noise.lass Finished dev [unoptimized + debuginfo] target(s) in 0.03s Running `target/debug/lovas pgm/noise.lass` Pgm { name: \"pgm/noise.lass\", text: [2, 123, 2, 200, 16, 1, 255] } So it does produce the same bytecode for both. As we demanded.","title":"Run the assembler"},{"location":"2022-08/ALL.html#running-into-errors","text":"What happens, if our program has errors? Easy to find out, I included a broken program: syntax-error.lass push_u8 123 push_u8 300 add pop fin Have you found the problem? Will the assembler? kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- pgm/syntax-error.lass Finished dev [unoptimized + debuginfo] target(s) in 0.04s Running `target/debug/lovas pgm/syntax-error.lass` Error: assembly failed in line 2 of program 'pgm/syntax-error.lass' Caused by: InvalidArgument It does find the error. Using the parse_int create already pays. And the error message really tells us, what is wrong and where. We get a lot of value for very few code we have written.","title":"Running into errors"},{"location":"2022-08/ALL.html#why-asmpgm","text":"There does not really seem to be a point of storing all that information inside AsmPgm . We could easily have created the bytecode directly. That would have been a lot easier. And if you have run the code yourself, you will have been bombarded with compiler warnings about unread fields. We will be needing that information soon, and it was easiest to build it like this right away. But let us just enjoy our new assembler for now.","title":"Why AsmPgm?"},{"location":"2022-08/ALL.html#impl-errorerror","text":"Okay, before we leave for today, one more thing that you might have spotted. What's with that impl blocks? impl Display for AsmError { fn fmt ( & self , f : & mut Formatter <' _ > ) -> std :: fmt :: Result { write! ( f , \"{:?}\" , self ) } } impl error :: Error for AsmError { } impl Display for AsmErrorReport { fn fmt ( & self , f : & mut Formatter <' _ > ) -> std :: fmt :: Result { write! ( f , \"assembly failed in line {} of program '{}'\" , self . line , self . name ) } } impl error :: Error for AsmErrorReport { fn source ( & self ) -> Option <& ( dyn error :: Error + ' static ) > { Some ( & self . error ) } } That is the price we have to pay when we want to use Rust magic. Rust's answer to writing generic code that can be applied to different types (that might not exist at the time of writing) are traits . A function can accept a trait as a type. If you implement that trait for your type, you can use that function. That is a very simplified introduction. A trait defines specific functions you have to write for a type. That is what we do here. We implement the trait std::error::Error for our AsmError and AsmErrorReport . To do so, we must also implement the trait std::fmt::Display (because the Error trait says so). There is not much we do there. Types implementing the Display trait can be printed using println!(\"{}\", value) . What the println! macro does is just calling that fmt method we define. The trait Debug does a similar thing, but for use with println!(\"{:?}\", value) . We can use any value with those constructs that implements the Display trait (for \"{}\" ) or the Debug trait (for \"{:?}\" ). The Debug trait we let the compiler implement (derive) for us. That is what the line #[derive(Debug)] does. And for our Display trait we are lazy and just use the function that was created by #[derive(Debug)] . The Error trait lets you implement a source() method, that is used to get a nested Error inside your Error, that was its cause. Think of exception stacks, only that we do not have exceptions, of course. That is exactly what we want for AsmErrorReport ; it is, after all, a wrapper for AsmError . AsmError on the other hand does not have a nested error, so we do not implement the source() method. The empty impl error::Error for AsmError block is still needed. If you remove it, the Error trait will not be implemented for AsmError . Cool story, but why do we do all this? This is what enables us to use the magic of anyhow in our lovas.rs . We can use AsmError and AsmErrorReport (wrapped in an Err() ) as return for our main function. It returns anyhow::Result<()> . And when there is an error returned by it, an error message is created and printed for us. With this we can easily create useful error messages in the error type itself, at the place where we understand, what errors exist and what they mean. And we need do it in that one place only. Every program that uses our library (as lovas.rs does) benefits from that without any extra work or even without knowing, error types can be returned by the library.","title":"impl error::Error"},{"location":"2022-08/ALL.html#running-assembler-programs","text":"We will extend our assembler to do something useful, finally: execute our programs on lovem. kratenko \u00b7 kratenko 2022-08-10 \u00b7 Entry #25 \u00b7 6 min read \u00b7 v0.0.9-journey We have created ourselves an assembler in ~300 lines of code. And it has a command line interface, an API to be used in a program, and even useful error reporting. That is cool! But what do we do with the bytecode? It just dumps them to the console. That is not very useful. We could copy/paste that into one of our example binaries... This is not what we wanted. So let us enhance our assembler.","title":"Running assembler programs"},{"location":"2022-08/ALL.html#execution","text":"We add some features to lovas.rs . A new command line parameter --run , that takes no arguments. If you add that flag to the call, lovas will take the assembled program (if there are no errors), create an instance of the VM and run the program on it. Thanks to clap, that is really easy to do. We add another field to our Cli struct. Actually, while we are at it, we add four new parameters: # #[clap(short, long, help = \"Run the assembled program in lovem.\" )] run : bool , # #[clap(long, help = \"Enable tracing log when running lovem.\" )] trace : bool , # #[clap(long, help = \"Output the program to stdout.\" )] print : bool , # #[clap(long, default_value_t = 100, help = \"Setting the stack size for lovem when running the program.\" )] stack_size : usize , And we change what we do with a successfully created program, depending on our new flag: // run the assembler: match asm :: assemble ( & name , & content ) { Ok ( pgm ) => { if args . print { println! ( \"{:?}\" , pgm ); } // we succeeded and now have a program with bytecode: if args . run { // lovas was called with `--run`, so create a VM and execute program: run ( & pgm , & args ) ? } Ok (()) }, Err ( e ) => { // Something went wrong during assembly. // Convert the error report, so that `anyhow` can do its magic // and display some helpful error message: Err ( Error :: from ( e )) }, } Just printing the program to stdout is no very useful default behaviour for an assembler. It might still come in handy, if you want to see what you are executing, so we make it optional and for the caller to decide with the --print flag. If the --run flag is set, we call run() . So what does run() do? /// Executes a program in a freshly created lovem VM. fn run ( pgm : & Pgm , args : & Cli ) -> Result < () > { // Create our VM instance. let mut vm = VM :: new ( args . stack_size ); vm . trace = args . trace ; let start = Instant :: now (); let outcome = vm . run ( & pgm . text ); let duration = start . elapsed (); match outcome { Ok ( _ ) => { // Execution successful, program terminated: eprintln! ( \"Terminated. \\n Runtime={:?} \\n op_cnt={}, pc={}, stack-depth={}, watermark={}\" , duration , vm . op_cnt , vm . pc , vm . stack . len (), vm . watermark ); Ok (()) }, Err ( e ) => { // Runtime error. Error will be printed on return of main. eprintln! ( \"Runtime error! \\n Runtime={:?} \\n op_cnt={}, pc={}, stack-depth={}, watermark={}\" , duration , vm . op_cnt , vm . pc , vm . stack . len (), vm . watermark ); Err ( Error :: from ( e )) } } } We create a VM instance, and we run the program on it. If there is a RuntimeError , we return it, just as we did with the AsmErrorReport . Back in our examples, we created a VM with a stack size of 100 - simply because we needed a number there. 100 is still the default, but now you can choose the stack size, when calling lovas . If you do lovas --run pgm/some-program.lva --stack-size 512 lovas will execute the program in a VM with a stack that can hold 512 values.","title":"Execution"},{"location":"2022-08/ALL.html#trace-log","text":"When we were running a program in our VM, we did always get a lot of output during execution. That is nice for understanding, what a stack machine does, but in general it is not a got idea for a VM to do that. It can be very beneficial, if you run into a problem with your program, so it is an easily available tool for debugging. That is why I removed all those log messages from lovem, but I let some in that can be activated, if you set vm.trace = true . That is what we added the new command line parameter --trace for. You can now control, if you want to see it.","title":"Trace Log"},{"location":"2022-08/ALL.html#diagnostics","text":"There is some output by lovas , after the execution. It reports if the run was successfully terminated (by executing a fin instruction), or if there was a RuntimeError . In both cases it will show you the time the execution took (wallclock time), as well as the number of instructions executed by the VM, the final position of the programm counter, the number of values on the stack at termination, and the highest number of values on the stack at any time during execution (the watermark). This can give you some quick insight on what your program did and maybe where it ran into trouble. All this lead to some changes to vm.rs , but nothing that should give you any problems to understand. Remember that we have the power of git at our disposal, so you can easily find out what changed in a file between two releases. You could do that for vm.rs with this handy link: https://github.com/kratenko/lovem/compare/v0.0.8-journey...v0.0.9-journey#diff-3bc51552cab41d1a2dbf07842cb438088563f6134a9c69a266dfd0d79b631495","title":"Diagnostics"},{"location":"2022-08/ALL.html#our-programs","text":"We have written a few example programs so far. Each is its own binary in src/bin/ , and all of them consist of the same Rust code of creating a VM and running a program. Only the bytecode changed between them. I got rid of all of those (except for the most basic one) and translated the programs into assembly programs that live in pgm/ . You can now execute those using lovas , like this: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/reverse-polish.lva --trace Compiling lovem v0.0.9 (/home/kratenko/git/lovem) Finished dev [unoptimized + debuginfo] target(s) in 2.02s Running `target/debug/lovas -r pgm/reverse-polish.lva --trace` VM { stack: [], pc: 0, op_cnt: 0, trace: true, watermark: 0 } Executing op 0x02 VM { stack: [5], pc: 2, op_cnt: 1, trace: true, watermark: 1 } Executing op 0x02 VM { stack: [5, 7], pc: 4, op_cnt: 2, trace: true, watermark: 2 } Executing op 0x02 VM { stack: [5, 7, 11], pc: 6, op_cnt: 3, trace: true, watermark: 3 } Executing op 0x11 VM { stack: [5, -4], pc: 7, op_cnt: 4, trace: true, watermark: 3 } Executing op 0x12 VM { stack: [-20], pc: 8, op_cnt: 5, trace: true, watermark: 3 } Executing op 0x02 VM { stack: [-20, 13], pc: 10, op_cnt: 6, trace: true, watermark: 3 } Executing op 0x02 VM { stack: [-20, 13, 17], pc: 12, op_cnt: 7, trace: true, watermark: 3 } Executing op 0x10 VM { stack: [-20, 30], pc: 13, op_cnt: 8, trace: true, watermark: 3 } Executing op 0x10 VM { stack: [10], pc: 14, op_cnt: 9, trace: true, watermark: 3 } Executing op 0x01 VM { stack: [], pc: 15, op_cnt: 10, trace: true, watermark: 3 } Terminated! VM { stack: [], pc: 16, op_cnt: 11, trace: true, watermark: 3 } Terminated. Runtime=49.33\u00b5s op_cnt=11, pc=16, stack size=0, watermark=3 Remember to add --trace to the call, or you won't see very much. It has become a lot easier, to play around with the VM. No more writing bytecode by hand!","title":"Our programs"},{"location":"2022-08/ALL.html#file-extension","text":"You might have noticed that I changed the filename extension that I use for the assembly programs from .lass to .lva . There are multiple reasons, but the main one is, that I thought Lass could be a nice name for a programming language, when I will finally come to writing one for lovem. So I want to reserve the extension for that possible future.","title":"File extension"},{"location":"2022-08/ALL.html#playing-around","text":"The diagnostic information given after the execution can be interesting, when you mess around. Let us play a bit with the program endless-stack.lva . ## This program runs in an endless loop, but it will push a new value to the stack on every iteration. ## It will inevitably lead to a stack overrun at some point and crash the program. push_u8 123 goto -5 fin The program will fill the stack until it is full, and then it will crash: Running `target/debug/lovas -r pgm/endless-stack.lva --print` Pgm { name: \"pgm/endless-stack.lva\", text: [2, 123, 32, 255, 251, 255] } Runtime error! Runtime=41.589\u00b5s op_cnt=201, pc=2, stack-depth=100, watermark=100 Error: StackOverflow After 201 executed instructions it crashes. The stack depth at the time of the crash is 100. That is the complete stack, the next instruction tried to push value 101, which must fail. Instruction number 201 did cause the crash. That makes sense, if you follow the execution in your head. And the program counter is on 2. The last instruction executed will be the one before that, which would be at 0. That is the push_u8 instruction. There is no surprise that the watermark is at 100. That is the highest possible value for it and also the current value of out stack depth. As we can now easily change the stack size, let us try what happens with a bigger stack: Running `target/debug/lovas -r pgm/endless-stack.lva --print --stack-size 150` Pgm { name: \"pgm/endless-stack.lva\", text: [2, 123, 32, 255, 251, 255] } Runtime error! Runtime=47.648\u00b5s op_cnt=301, pc=2, stack-depth=150, watermark=150 Error: StackOverflow So now the stack overflows at over 150 values, of course. And it takes 301 instructions to fill it. Runtime has been longer, but only about 15%. I would not have expected a rise of 50%, as there is overhead for starting the program. What happens, if we activate --trace ? Running `target/debug/lovas -r pgm/endless-stack.lva --print --stack-size 150 --trace` Pgm { name: \"pgm/endless-stack.lva\", text: [2, 123, 32, 255, 251, 255] } VM { stack: [], pc: 0, op_cnt: 0, trace: true, watermark: 0 } Executing op 0x02 VM { stack: [123], pc: 2, op_cnt: 1, trace: true, watermark: 1 } Executing op 0x20 [...] Executing op 0x02 Runtime error! Runtime=67.312973ms op_cnt=301, pc=2, stack-depth=150, watermark=150 Error: StackOverflow There is, of course, a lot of output, that I cut out. What is interesting is the change in execution time. I ran this inside the CLion IDE by JetBrains. The console there will not be a very fast console, as it does a lot with that output coming through. But the impact of the logging is enormous! The runtime until we hit our stack overflow is more than 1000 times longer! The exact numbers don't mean anything; we are running unoptimised Rust code with debuginfo, and the bottleneck is the console. But it is still fascinating to see.","title":"Playing around"},{"location":"2022-08/ALL.html#you-labeled-me-ill-label-you","text":"We add a feature to our assembler that we overlooked before. kratenko \u00b7 kratenko 2022-08-11 \u00b7 Entry #26 \u00b7 10 min read \u00b7 v0.0.10-journey Over the last few entries we created ourselves a really useful little assembler program. I hope you played around with it and enjoyed not having to write bytecode directly. If you did, you should have noticed that I left out a really important detail. Remember when I was complaining about how bad writing bytecode is? And that it got even worth, when we introduced jumps? Yeah, I did not solve that problem at all. If anything, I made it worse, because you still have to count the relative bytes to your destination, but you do not see those bytes any longer. You just have to know, how many bytes each instruction will produce.","title":"You labeled me, I'll label you"},{"location":"2022-08/ALL.html#labels","text":"There was so much already going on in that assembler program, that I did not want to introduce more complexity up front. Let's fix that now: we will introduce a way to give a position inside your program a name, so that you can goto that name later. And in good tradition, we will call this names labels . The traditional way of defining labels in assembly is by writing them first thing on a line, followed by a colon : . Take a look at this little program, label.lva . It is neither good style, nor does it do anything useful, but it shows us labels: pgm/label.lva 1 2 3 4 5 6 7 8 9 10 ## A small demonstration of how labels work with goto. push_u8 1 goto coda back: push_u8 3 fin coda: push_u8 2 goto back There are two labels defined here: back in line 5, and coda in line 9. A label definition is a short string that is directly followed by a colon : . We restrict it to letters, numbers, and underscore, with a letter at the front. For the curious, the regex is: ^[A-Za-z][0-9A-Za-z_]{0,31}$ . As you can see in the example, there can be an optional instruction in the same line as the label definition. Now, how will our assembler parse those?","title":"Labels"},{"location":"2022-08/ALL.html#reconstruction","text":"First of all, I did a little reconstruction inside asm.rs , because I did not like how the parsing was done inside an associated function, that also created the AsmPgm instance. That seems messed up. After the change, the fn assemble() creates the instance itself and then calls a method on it, to parse the source code. Here is the new version: src/asm.rs 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 /// Parse assembly source code and turn it into a runnable program (or create report). pub fn assemble ( name : & str , content : & str ) -> Result < Pgm , AsmErrorReport > { // create a new, clean instance to fill during parsing: let mut asm_pgm = AsmPgm { name : String :: from ( name ), instructions : vec ! [], line_number : 0 , text_pos : 0 , error : None , labels : Default :: default (), }; // evaluate the source code: asm_pgm . process_assembly ( content ); // convert to Pgm instance if successful, or to Error Report, if assembly failed: asm_pgm . to_program () } And there is no problem with us changing the code like this. The only public function inside asm.rs is that pub fn assemble() . All methods of AsmPgm are private and therefore internal detail. Not that it would matter at this state of development, but it demonstrates how separation of public API and internal implementation work. What is also new in that function is a new field inside AsmPgm : labels . /// A assembler program during parsing/assembling. # #[derive(Debug)] struct AsmPgm { .. . /// A map storing label definitions by name with there position in bytecode. labels : HashMap < String , usize > , } It is a HashMap (aka. associative array in other languages). This is where we put all label definitions we find, while parsing the source file. It maps the label's name to its position inside the bytecode. Here we can look up where to jump, for a goto that wants to jump to a label. This is what our parsing methods now look like: 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 fn process ( & mut self , content : & str ) -> Result < (), AsmError > { // Go over complete source, extracting instructions. Some will have their opargs // left empty (with placeholders). self . parse ( content ) ? ; self . update_instructions () } /// Process assembly source code. Must be used with \"empty\" AsmPgm. fn process_assembly ( & mut self , content : & str ) { // this function is just a wrapper around `process()`, so that I can use the // return magic and don't need to write the error check twice. if let Err ( e ) = self . process ( content ) { self . error = Some ( e ); } } The important part is, that we have to steps now. We parse the complete source, as before. The second run is needed to write the actual relative jump address to the instructions. We do not know them during parsing, at least not for jumps forward.","title":"Reconstruction"},{"location":"2022-08/ALL.html#parsing-label-definitions","text":"I got a little fancy again, while writing the function for parsing label definitions: 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 /// Parses and extracts optional label definition from line. /// /// Looks for a colon ':'. If one exists, the part before the first colon will be /// seen as the name for a label, that is defined on this line. Instructions inside /// the program that execute jumps can refer to these labels as a destination. /// Lines containing a label definition may also contain an instruction and/or a comment. /// This can return `AsmError::InvalidLabel` if the part before the colon is not a valid /// label name, or `AsmError::DuplicateLabel` if a label name is reused. /// If a label could be parsed, it will be stored to the `AsmPgm`. /// On success, the line without the label definition is returned, so that it can be /// used to extract an instruction. This will be the complete line, if there was no /// label definition. fn parse_label_definition <' a > ( & mut self , line : & ' a str ) -> Result <&' a str , AsmError > { if let Some (( label , rest )) = line . split_once ( \":\" ) { let label = label . trim_start (); if VALID_LABEL . is_match ( label ) { if self . labels . contains_key ( label ) { Err ( AsmError :: DuplicateLabel ( String :: from ( label ))) } else { self . labels . insert ( String :: from ( label ), self . text_pos ); Ok ( rest ) } } else { Err ( AsmError :: InvalidLabel ( String :: from ( label ))) } } else { Ok ( line ) } } The method is trying to find a label definition in the line, and if so, handles it. We use our trusted Result<> returning, to communicate potential errors. But instead of Ok(()) , which is the empty okay value, we return a &str on success. This is because there might also be an instruction in the line. If we find a label definition, it returns the line after the colon. If there is none, it returns the complete line it got. This gives us the lines as we used to get before we introduced labels. Great. But what is that weird 'a that shows up in that highlighted line everywhere?","title":"Parsing label definitions"},{"location":"2022-08/ALL.html#lifetime","text":"Yeah, this is where it becomes rusty, again. I said, in an early post, that you would hate the Rust compiler and its pedantic error messages. The thing Rust is most pedantic about, is ownership and access to values you do not own. We are working with references to String s here. A &str references the bytes inside that String directly (a &str need not reference a String , but it does here). We did that before, where is the problem now? This is the first time we are returning a &str . When you are using references, Rust makes sure that the value you are referencing exists at least as long as the reference exists. That is easy for functions, as long as you drop every reference you have when you are done. But in this function, we return a reference to the parameter we got. Rust cannot allow that without some special care. When I remove the 'a parts of the method, I get a compilation error: error[E0623]: lifetime mismatch --> src/asm.rs:277:21 | 269 | fn parse_label_definition(&mut self, line: &str) -> Result<&str, AsmError> { | ---- ---------------------- | | | this parameter and the return type are declared with different lifetimes... ... 277 | Ok(rest) | ^^^^^^^^ ...but data from `line` is returned here | = note: each elided lifetime in input position becomes a distinct lifetime help: consider introducing a named lifetime parameter and update trait if needed | 269 | fn parse_label_definition<'a>(&'a mut self, line: &'a str) -> Result<&str, AsmError> { | ++++ ++ ++ The compiler tells me, that I messed up the lifetimes. It even proposes a change that introduces lifetime parameters (but gets it slightly wrong). What do we do with the 'a ? Well we introduce a lifetime parameter called a . The syntax for that is the apostrophe, which looked weird to me at start, but it is so lightweight, that I came to like it. It is custom, to just call your lifetimes 'a , 'b , ... \u2013 they normally don't have a long scope anyway. The thing we are telling the compiler with this parameter is this: the lifetime of the returned &str is dependent on the lifetime of the parameter line: &str . So whenever the reference the function is called with runs out of scope, the reference that was returned must be out of scope as well.","title":"Lifetime"},{"location":"2022-08/ALL.html#an-example","text":"This is a concept that is new to many programmers when they learn Rust. I think, what we do here demonstrates it quiet well. Let us look at what happens for line 9 of our assembly program: pgm/label.lva 9 coda: push_u8 2 Our function receives a reference to a String holding that line: \" coda: push_u8 2\" . It finds the label coda and stores it inside self.labels . Its work is done, but there might be more to this line. It returns a reference to a substring of it ( &str are actually slices; they can reference only a part of a String 's data). That is what we return, a reference to the part data inside the String , starting at the first char after the colon, so it looks like this \" push_u8 2\" . It is not a copy, it is the same area inside the computer's memory! So if you want to make certain, that there are no accesses to memory after its content has run out of scope (use after free, or use of local variable after it runs our of scope), you must not allow access to it, unless you are sure the value still exists. And this is what Rust does. This is what makes Rust a secure language. Many bugs and exploits in the world exist, because most languages do not check this, but leave the responsibility to the programmer. And the really cool thing about Rust is, it does this completely at compile time, as you can see by the fact that we got a compiler error. The way we call our function is not a problem at all: src/asm.rs 292 293 294 295 296 297 298 for ( n , line ) in content . lines (). enumerate () { // File lines start counting at 1: self . line_number = n + 1 ; let line = self . parse_label_definition ( line ) ? ; let line = AsmPgm :: clean_line ( line ); self . parse_clean_line ( line ) ? ; } Our initial line comes from line 228. It is already a reference, because content.lines() is also giving us a reference to the memory inside of content . That is a reference already, the String variable that holds (and owns) the data lives inside lovas.rs : src/bin/lovas.rs 67 68 69 70 71 72 73 // read complete source file into String: let content = std :: fs :: read_to_string ( & args . source ) . with_context ( || format! ( \"could not read file `{}`\" , & name ) ) ? ; // run the assembler: match asm :: assemble ( & name , & content ) { We do not copy any of that bytes along the way. The first time we do that is in clean_line() . Returning a &str will not work there, because we actually modify the contents of the string, by replacing characters inside it. Have you ever tried to work with inplace \"substrings\" (I mean char arrays, like this char *str ), without modifying the contents (placing \\0 bytes). It is not fun. In Rust, it can be, if you understand lifetime restrictions.","title":"An example"},{"location":"2022-08/ALL.html#easy-way-out","text":"If you run into problems with your &str inside a Rust program, there is often an easy way to get around that. You can simply create a new String from your &str , as we do in clean_line() . That will copy the bytes. For our program, that would have been no problem at all. Cloning a few bytes of source code for every line during assembly would cost us next to nothing. You would not notice in execution time. But things are different when you need to quickly handle long substrings in a program. Think of a diagnostic job on a busy server. And remember that String s will be created on the heap. That is a complexity that you sometimes want to avoid. When programming microcontrollers, there is a chance that you do not even have a memory allocator at your disposal. And microcontrollers is, what we are aiming for in our project. There are already some parts of lovem, that we will need to change, because of that. But that is a story for another time. I just thought that this was a nice little example to introduce you to lifetime parameters. We will need them at some point...","title":"Easy way out"},{"location":"2022-08/ALL.html#run-it-already","text":"This is a long entry already. You can look at the complete state of the assembler directly in the sourcecode. You should know how to find the tags inside the repo by now. But I want to execute our new program, using the labels, before I end this. Here it is again: pgm/label.lva 1 2 3 4 5 6 7 8 9 10 ## A small demonstration of how labels work with goto. push_u8 1 goto coda back: push_u8 3 fin coda: push_u8 2 goto back We need to execute it with the --trace flag, or we will not see anything: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/label.lva --print --trace Compiling lovem v0.0.10 (/home/kratenko/git/lovem) Finished dev [unoptimized + debuginfo] target(s) in 1.33s Running `target/debug/lovas -r pgm/label.lva --print --trace` Pgm { name: \"pgm/label.lva\", text: [2, 1, 32, 0, 3, 2, 3, 255, 2, 2, 32, 255, 248] } VM { stack: [], pc: 0, op_cnt: 0, trace: true, watermark: 0 } Executing op 0x02 VM { stack: [1], pc: 2, op_cnt: 1, trace: true, watermark: 1 } Executing op 0x20 Jump from 5 by 3 VM { stack: [1], pc: 8, op_cnt: 2, trace: true, watermark: 1 } Executing op 0x02 VM { stack: [1, 2], pc: 10, op_cnt: 3, trace: true, watermark: 2 } Executing op 0x20 Jump from 13 by -8 VM { stack: [1, 2], pc: 5, op_cnt: 4, trace: true, watermark: 2 } Executing op 0x02 VM { stack: [1, 2, 3], pc: 7, op_cnt: 5, trace: true, watermark: 3 } Terminated! VM { stack: [1, 2, 3], pc: 8, op_cnt: 6, trace: true, watermark: 3 } Terminated. Runtime=65.598\u00b5s op_cnt=6, pc=8, stack-depth=3, watermark=3 The program has three push_u8 operations. If you executed them in the order of the source code, they would push [1, 3, 2] to the stack. But because of the goto instructions, they are not executed in that order. You can see the jumps in the trace, and you can see that the stack at termination holds the values in this order: [1, 2, 3] . Not much of a program, but it shows you, how our new labels work. And finally: no more counting bytes!","title":"Run it already!"},{"location":"2022-08/ALL.html#homework","text":"Our programs endless.lva and endless-stack.lva no longer work, because we changed how the goto instruction must be written. Can you fix them?","title":"Homework"},{"location":"2022-08/ALL.html#what-if","text":"Choose your path. kratenko \u00b7 kratenko 2022-08-19 \u00b7 Entry #27 \u00b7 6 min read \u00b7 v0.0.11-journey Our assembler gives us a lot of convenience for testing features of our VM. So let us start doing interesting stuff with it. We do have support for jumps already, but as it is now, save of an endless loop, there is absolutely no reason to do it, yet. All our programs run their predetermined way. If you look again at label.lva , you can see that none of those goto s introduce any dynamic. We could just ditch them and reorder the rest. It would do the same, only more efficient. They simple tangle up our linear code, without removing its linearity. Today we will introduce branches to our VM. A branch is a point in a program from which there are multiple possible paths to take. Two paths, normally. Which of those paths is takes is decided at runtime by looking at the state of the program. For us that means that we look at the value on top of the stack. How does it work?","title":"What if?"},{"location":"2022-08/ALL.html#conditional-jump","text":"We already introduced the goto operation. What we will add now, works exactly the same way, but only if a certain condition is met. And, yes, we will call that operation if . But if what? How about if equal ? So we get the new opname ifeq , that pops a value from the stack and only executes its jump when that value is equal. Equal to what, you want to know? How about if it is equal to zero. If you want to compare it to a different number, it is easy to subtract that number from your value before you compare it to zero, and you achieve what you need.","title":"Conditional jump"},{"location":"2022-08/ALL.html#new-operations","text":"We will introduce multiple if-operations. Six, to be precise. src/op.rs 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 /// opcode: Conditional relative jump (branch) on pop == zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFEQ : u8 = 0x21 ; /// opcode: Conditional relative jump (branch) on pop != zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFNE : u8 = 0x22 ; /// opcode: Conditional relative jump (branch) on pop < zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFLT : u8 = 0x23 ; /// opcode: Conditional relative jump (branch) on pop <= zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFLE : u8 = 0x24 ; /// opcode: Conditional relative jump (branch) on pop > zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFGT : u8 = 0x25 ; /// opcode: Conditional relative jump (branch) on pop >= zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFGE : u8 = 0x26 ; And we add another operation, while we add it: dup src/op.rs 21 22 23 24 25 /// opcode: Pop value from stack and push it back, twice. /// /// pop: 1, push: 2 /// oparg: 0 pub const DUP : u8 = 0x03 ; This one simply duplicates the value on top of the stack, so that there will be another copy of it on top of it. We will use that often when testing values with an if , if we still need the value after testing it. The if will consume the top most value.","title":"New operations"},{"location":"2022-08/ALL.html#extending-the-assembler","text":"We add the parsing handlers for our new instructions: src/asm.rs 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 fn parse_instruction ( & mut self , opname : & str , oparg : Option <& str > ) -> Result < (), AsmError > { match opname { \"nop\" => self . parse_a0_instruction ( op :: NOP , oparg ), \"fin\" => self . parse_a0_instruction ( op :: FIN , oparg ), \"pop\" => self . parse_a0_instruction ( op :: POP , oparg ), \"dup\" => self . parse_a0_instruction ( op :: DUP , oparg ), \"add\" => self . parse_a0_instruction ( op :: ADD , oparg ), \"sub\" => self . parse_a0_instruction ( op :: SUB , oparg ), \"mul\" => self . parse_a0_instruction ( op :: MUL , oparg ), \"div\" => self . parse_a0_instruction ( op :: DIV , oparg ), \"mod\" => self . parse_a0_instruction ( op :: MOD , oparg ), \"push_u8\" => { let oparg = oparg . ok_or ( AsmError :: MissingArgument ) ? ; let v = parse_int :: parse :: < u8 > ( oparg ). or ( Err ( AsmError :: InvalidArgument )) ? ; self . push_a1_instruction ( op :: PUSH_U8 , v ) }, \"goto\" => self . parse_label_instruction ( op :: GOTO , oparg ), \"ifeq\" => self . parse_label_instruction ( op :: IFEQ , oparg ), \"ifne\" => self . parse_label_instruction ( op :: IFNE , oparg ), \"iflt\" => self . parse_label_instruction ( op :: IFLT , oparg ), \"ifle\" => self . parse_label_instruction ( op :: IFLE , oparg ), \"ifgt\" => self . parse_label_instruction ( op :: IFGT , oparg ), \"ifge\" => self . parse_label_instruction ( op :: IFGE , oparg ), _ => Err ( AsmError :: UnknownInstruction ( String :: from ( opname ))) } } And that is all we need to change on our assembler. The way we have written it, it is easy to introduce new operations, when they share the same syntax in assembly and in bytecode as existing ones.","title":"Extending the assembler"},{"location":"2022-08/ALL.html#adjust-the-vm","text":"First, we add the handler for the dup . Just pop a value and push it back, twice. Easy. src/vm.rs 175 176 177 178 179 180 op :: DUP => { let v = self . pop () ? ; self . push ( v ) ? ; self . push ( v ) ? ; Ok (()) }, And now, the if* -handlers. They are similar to the goto -handler, just with an if added. src/vm.rs 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 op :: GOTO => { let d = self . fetch_i16 ( pgm ) ? ; self . relative_jump ( pgm , d ) }, op :: IFEQ => { let d = self . fetch_i16 ( pgm ) ? ; let v = self . pop () ? ; if v == 0 { self . relative_jump ( pgm , d ) } else { Ok (()) } }, op :: IFNE => { let d = self . fetch_i16 ( pgm ) ? ; let v = self . pop () ? ; if v != 0 { self . relative_jump ( pgm , d ) } else { Ok (()) } }, op :: IFLT => { let d = self . fetch_i16 ( pgm ) ? ; let v = self . pop () ? ; if v < 0 { self . relative_jump ( pgm , d ) } else { Ok (()) } }, op :: IFLE => { let d = self . fetch_i16 ( pgm ) ? ; let v = self . pop () ? ; if v <= 0 { self . relative_jump ( pgm , d ) } else { Ok (()) } }, op :: IFGT => { let d = self . fetch_i16 ( pgm ) ? ; let v = self . pop () ? ; if v > 0 { self . relative_jump ( pgm , d ) } else { Ok (()) } }, op :: IFGE => { let d = self . fetch_i16 ( pgm ) ? ; let v = self . pop () ? ; if v >= 0 { self . relative_jump ( pgm , d ) } else { Ok (()) } }, And that is all the code we have to change. Our VM can now execute conditional jumps. Now we can do some serious programming!","title":"Adjust the VM"},{"location":"2022-08/ALL.html#a-for-loop","text":"Can't wait to use an if in program: pgm/loop.lva 1 2 3 4 5 6 7 8 9 10 ## Demonstrate the conditional jump (a branch) ## The program has a loop that it executes thrice, before it terminates. push_u8 3 loop: push_u8 1 sub dup ifgt loop pop fin And execute it: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/loop.lva --print --trace Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas -r pgm/loop.lva --print --trace` Pgm { name: \"pgm/loop.lva\", text: [2, 3, 2, 1, 17, 3, 37, 255, 249, 1, 255] } VM { stack: [], pc: 0, op_cnt: 0, trace: true, watermark: 0 } Executing op 0x02 VM { stack: [3], pc: 2, op_cnt: 1, trace: true, watermark: 1 } Executing op 0x02 VM { stack: [3, 1], pc: 4, op_cnt: 2, trace: true, watermark: 2 } Executing op 0x11 VM { stack: [2], pc: 5, op_cnt: 3, trace: true, watermark: 2 } Executing op 0x03 VM { stack: [2, 2], pc: 6, op_cnt: 4, trace: true, watermark: 2 } Executing op 0x25 Jump from 9 by -7 VM { stack: [2], pc: 2, op_cnt: 5, trace: true, watermark: 2 } Executing op 0x02 VM { stack: [2, 1], pc: 4, op_cnt: 6, trace: true, watermark: 2 } Executing op 0x11 VM { stack: [1], pc: 5, op_cnt: 7, trace: true, watermark: 2 } Executing op 0x03 VM { stack: [1, 1], pc: 6, op_cnt: 8, trace: true, watermark: 2 } Executing op 0x25 Jump from 9 by -7 VM { stack: [1], pc: 2, op_cnt: 9, trace: true, watermark: 2 } Executing op 0x02 VM { stack: [1, 1], pc: 4, op_cnt: 10, trace: true, watermark: 2 } Executing op 0x11 VM { stack: [0], pc: 5, op_cnt: 11, trace: true, watermark: 2 } Executing op 0x03 VM { stack: [0, 0], pc: 6, op_cnt: 12, trace: true, watermark: 2 } Executing op 0x25 VM { stack: [0], pc: 9, op_cnt: 13, trace: true, watermark: 2 } Executing op 0x01 VM { stack: [], pc: 10, op_cnt: 14, trace: true, watermark: 2 } Terminated! VM { stack: [], pc: 11, op_cnt: 15, trace: true, watermark: 2 } Terminated. Runtime=100.972\u00b5s op_cnt=15, pc=11, stack-depth=0, watermark=2 Nice! This is basically a for-loop. Granted, it does not do anything but loop, but you can see how the program counts down from 3 to 0 and after the third time it reaches line 8, it stops jumping back to loop: and advances to the end. We can increase the number in line 3, and the number of runs increase with it. If we change it to 200 , we get this (I ditched the --trace for this). kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/loop.lva --print Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas -r pgm/loop.lva --print` Pgm { name: \"pgm/loop.lva\", text: [2, 200, 2, 1, 17, 3, 37, 255, 249, 1, 255] } Terminated. Runtime=128.709\u00b5s op_cnt=803, pc=11, stack-depth=0, watermark=2 More than 800 operations with only 10 lines of code. Shall we cranc it up to a million? kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/loop.lva --print Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas -r pgm/loop.lva --print` Pgm { name: \"pgm/loop.lva\", text: [2, 100, 2, 100, 18, 2, 100, 18, 2, 1, 17, 3, 37, 255, 249, 1, 255] } Terminated. Runtime=564.184652ms op_cnt=4000007, pc=17, stack-depth=0, watermark=2 Takes about have a second to execute, over 4000000 operations where executed. And the stack never held more than 2 values, as you can see by the watermark. We are programming!","title":"A for-loop"},{"location":"2022-08/ALL.html#homework_1","text":"Wait a second! Our only way of getting values on the stack is push_u8 . That can only push a u8 , so only values 0 - 255 . How did I push that 1000000 there?","title":"Homework"},{"location":"2022-08/NAV.html","text":"What if? You labeled me, I'll label you Running assembler programs Assembling bytes Handling instructions","title":"NAV"},{"location":"2022-08/assembling-bytes.html","text":"Assembling bytes \u00b6 kratenko \u00b7 kratenko 2022-08-09 \u00b7 Entry #24 \u00b7 4 min read \u00b7 v0.0.8-journey Our new assembler is almost done assembling. Over the last entries we learned how the program parses the assembly sourcecode and produces a list of parsed instructions. What we now need to do, is turn that into bytes. Parsed \u00b6 Let us take a look at where we are. We have our sample program hallo-stack.lass : push_u8 123 push_u8 200 add pop fin If we debug-print the AsmPgm after the parsing, it looks like this: AsmPgm { name: \"pgm/hallo-stack.lass\", instructions: [ AsmInstruction { line_number: 1, opcode: 2, oparg: [123], pos: 0 }, AsmInstruction { line_number: 2, opcode: 2, oparg: [200], pos: 2 }, AsmInstruction { line_number: 3, opcode: 16, oparg: [], pos: 4 }, AsmInstruction { line_number: 4, opcode: 1, oparg: [], pos: 5 }, AsmInstruction { line_number: 5, opcode: 255, oparg: [], pos: 6 } ], line_number: 5, text_pos: 7, error: None } No error, that is nice. And we can see all five instructions parsed. We have a function that connects those bytes. Connect the bytes \u00b6 /// Convert parsed assembly source to runnable program (or error report). fn to_program ( & self ) -> Result < Pgm , AsmErrorReport > { if let Some ( e ) = & self . error { // Assembling failed: Err ( AsmErrorReport { name : self . name . clone (), line : self . line_number , error : e . clone (), }) } else { // Assembling succeeded, return a Pgm instance: let mut text : Vec < u8 > = vec! []; for i in & self . instructions { text . push ( i . opcode ); text . extend ( & i . oparg ); } Ok ( Pgm { name : self . name . clone (), text , }) } } The error part is straightforward. A small detail is the clone() call for name and error. We need to do that, because we cannot move ownership of those values (they must still exist in the AsmPgm instance). And we cannot use references. There is no need to clone the line number; as an integer type it can simply be copied. The success part isn't complex either. We create a Vector of bytes and push all bytes into it: for each instruction the opcode and the opargs (which there can be zero). We have our bytecode now! Wrap it inside our new Pgm type, and we are done. Run the assembler \u00b6 Let us see what our program looks like, assembled: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- pgm/hallo-stack.lass Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas pgm/hallo-stack.lass` Pgm { name: \"pgm/hallo-stack.lass\", text: [2, 123, 2, 200, 16, 1, 255] } And how about our noisy program, noice.lass ? kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- pgm/noise.lass Finished dev [unoptimized + debuginfo] target(s) in 0.03s Running `target/debug/lovas pgm/noise.lass` Pgm { name: \"pgm/noise.lass\", text: [2, 123, 2, 200, 16, 1, 255] } So it does produce the same bytecode for both. As we demanded. Running into errors \u00b6 What happens, if our program has errors? Easy to find out, I included a broken program: syntax-error.lass push_u8 123 push_u8 300 add pop fin Have you found the problem? Will the assembler? kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- pgm/syntax-error.lass Finished dev [unoptimized + debuginfo] target(s) in 0.04s Running `target/debug/lovas pgm/syntax-error.lass` Error: assembly failed in line 2 of program 'pgm/syntax-error.lass' Caused by: InvalidArgument It does find the error. Using the parse_int create already pays. And the error message really tells us, what is wrong and where. We get a lot of value for very few code we have written. Why AsmPgm? \u00b6 There does not really seem to be a point of storing all that information inside AsmPgm . We could easily have created the bytecode directly. That would have been a lot easier. And if you have run the code yourself, you will have been bombarded with compiler warnings about unread fields. We will be needing that information soon, and it was easiest to build it like this right away. But let us just enjoy our new assembler for now. impl error::Error \u00b6 Okay, before we leave for today, one more thing that you might have spotted. What's with that impl blocks? impl Display for AsmError { fn fmt ( & self , f : & mut Formatter <' _ > ) -> std :: fmt :: Result { write! ( f , \"{:?}\" , self ) } } impl error :: Error for AsmError { } impl Display for AsmErrorReport { fn fmt ( & self , f : & mut Formatter <' _ > ) -> std :: fmt :: Result { write! ( f , \"assembly failed in line {} of program '{}'\" , self . line , self . name ) } } impl error :: Error for AsmErrorReport { fn source ( & self ) -> Option <& ( dyn error :: Error + ' static ) > { Some ( & self . error ) } } That is the price we have to pay when we want to use Rust magic. Rust's answer to writing generic code that can be applied to different types (that might not exist at the time of writing) are traits . A function can accept a trait as a type. If you implement that trait for your type, you can use that function. That is a very simplified introduction. A trait defines specific functions you have to write for a type. That is what we do here. We implement the trait std::error::Error for our AsmError and AsmErrorReport . To do so, we must also implement the trait std::fmt::Display (because the Error trait says so). There is not much we do there. Types implementing the Display trait can be printed using println!(\"{}\", value) . What the println! macro does is just calling that fmt method we define. The trait Debug does a similar thing, but for use with println!(\"{:?}\", value) . We can use any value with those constructs that implements the Display trait (for \"{}\" ) or the Debug trait (for \"{:?}\" ). The Debug trait we let the compiler implement (derive) for us. That is what the line #[derive(Debug)] does. And for our Display trait we are lazy and just use the function that was created by #[derive(Debug)] . The Error trait lets you implement a source() method, that is used to get a nested Error inside your Error, that was its cause. Think of exception stacks, only that we do not have exceptions, of course. That is exactly what we want for AsmErrorReport ; it is, after all, a wrapper for AsmError . AsmError on the other hand does not have a nested error, so we do not implement the source() method. The empty impl error::Error for AsmError block is still needed. If you remove it, the Error trait will not be implemented for AsmError . Cool story, but why do we do all this? This is what enables us to use the magic of anyhow in our lovas.rs . We can use AsmError and AsmErrorReport (wrapped in an Err() ) as return for our main function. It returns anyhow::Result<()> . And when there is an error returned by it, an error message is created and printed for us. With this we can easily create useful error messages in the error type itself, at the place where we understand, what errors exist and what they mean. And we need do it in that one place only. Every program that uses our library (as lovas.rs does) benefits from that without any extra work or even without knowing, error types can be returned by the library. The source code for this post can be found under the tag v0.0.8-journey . v0.0.8-journey source code v0.0.8-journey release v0.0.8-journey.zip v0.0.8-journey.tar.gz git checkout v0.0.8-journey What does this mean?","title":" Assembling bytes"},{"location":"2022-08/assembling-bytes.html#assembling-bytes","text":"kratenko \u00b7 kratenko 2022-08-09 \u00b7 Entry #24 \u00b7 4 min read \u00b7 v0.0.8-journey Our new assembler is almost done assembling. Over the last entries we learned how the program parses the assembly sourcecode and produces a list of parsed instructions. What we now need to do, is turn that into bytes.","title":"Assembling bytes"},{"location":"2022-08/assembling-bytes.html#parsed","text":"Let us take a look at where we are. We have our sample program hallo-stack.lass : push_u8 123 push_u8 200 add pop fin If we debug-print the AsmPgm after the parsing, it looks like this: AsmPgm { name: \"pgm/hallo-stack.lass\", instructions: [ AsmInstruction { line_number: 1, opcode: 2, oparg: [123], pos: 0 }, AsmInstruction { line_number: 2, opcode: 2, oparg: [200], pos: 2 }, AsmInstruction { line_number: 3, opcode: 16, oparg: [], pos: 4 }, AsmInstruction { line_number: 4, opcode: 1, oparg: [], pos: 5 }, AsmInstruction { line_number: 5, opcode: 255, oparg: [], pos: 6 } ], line_number: 5, text_pos: 7, error: None } No error, that is nice. And we can see all five instructions parsed. We have a function that connects those bytes.","title":"Parsed"},{"location":"2022-08/assembling-bytes.html#connect-the-bytes","text":"/// Convert parsed assembly source to runnable program (or error report). fn to_program ( & self ) -> Result < Pgm , AsmErrorReport > { if let Some ( e ) = & self . error { // Assembling failed: Err ( AsmErrorReport { name : self . name . clone (), line : self . line_number , error : e . clone (), }) } else { // Assembling succeeded, return a Pgm instance: let mut text : Vec < u8 > = vec! []; for i in & self . instructions { text . push ( i . opcode ); text . extend ( & i . oparg ); } Ok ( Pgm { name : self . name . clone (), text , }) } } The error part is straightforward. A small detail is the clone() call for name and error. We need to do that, because we cannot move ownership of those values (they must still exist in the AsmPgm instance). And we cannot use references. There is no need to clone the line number; as an integer type it can simply be copied. The success part isn't complex either. We create a Vector of bytes and push all bytes into it: for each instruction the opcode and the opargs (which there can be zero). We have our bytecode now! Wrap it inside our new Pgm type, and we are done.","title":"Connect the bytes"},{"location":"2022-08/assembling-bytes.html#run-the-assembler","text":"Let us see what our program looks like, assembled: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- pgm/hallo-stack.lass Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas pgm/hallo-stack.lass` Pgm { name: \"pgm/hallo-stack.lass\", text: [2, 123, 2, 200, 16, 1, 255] } And how about our noisy program, noice.lass ? kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- pgm/noise.lass Finished dev [unoptimized + debuginfo] target(s) in 0.03s Running `target/debug/lovas pgm/noise.lass` Pgm { name: \"pgm/noise.lass\", text: [2, 123, 2, 200, 16, 1, 255] } So it does produce the same bytecode for both. As we demanded.","title":"Run the assembler"},{"location":"2022-08/assembling-bytes.html#running-into-errors","text":"What happens, if our program has errors? Easy to find out, I included a broken program: syntax-error.lass push_u8 123 push_u8 300 add pop fin Have you found the problem? Will the assembler? kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- pgm/syntax-error.lass Finished dev [unoptimized + debuginfo] target(s) in 0.04s Running `target/debug/lovas pgm/syntax-error.lass` Error: assembly failed in line 2 of program 'pgm/syntax-error.lass' Caused by: InvalidArgument It does find the error. Using the parse_int create already pays. And the error message really tells us, what is wrong and where. We get a lot of value for very few code we have written.","title":"Running into errors"},{"location":"2022-08/assembling-bytes.html#why-asmpgm","text":"There does not really seem to be a point of storing all that information inside AsmPgm . We could easily have created the bytecode directly. That would have been a lot easier. And if you have run the code yourself, you will have been bombarded with compiler warnings about unread fields. We will be needing that information soon, and it was easiest to build it like this right away. But let us just enjoy our new assembler for now.","title":"Why AsmPgm?"},{"location":"2022-08/assembling-bytes.html#impl-errorerror","text":"Okay, before we leave for today, one more thing that you might have spotted. What's with that impl blocks? impl Display for AsmError { fn fmt ( & self , f : & mut Formatter <' _ > ) -> std :: fmt :: Result { write! ( f , \"{:?}\" , self ) } } impl error :: Error for AsmError { } impl Display for AsmErrorReport { fn fmt ( & self , f : & mut Formatter <' _ > ) -> std :: fmt :: Result { write! ( f , \"assembly failed in line {} of program '{}'\" , self . line , self . name ) } } impl error :: Error for AsmErrorReport { fn source ( & self ) -> Option <& ( dyn error :: Error + ' static ) > { Some ( & self . error ) } } That is the price we have to pay when we want to use Rust magic. Rust's answer to writing generic code that can be applied to different types (that might not exist at the time of writing) are traits . A function can accept a trait as a type. If you implement that trait for your type, you can use that function. That is a very simplified introduction. A trait defines specific functions you have to write for a type. That is what we do here. We implement the trait std::error::Error for our AsmError and AsmErrorReport . To do so, we must also implement the trait std::fmt::Display (because the Error trait says so). There is not much we do there. Types implementing the Display trait can be printed using println!(\"{}\", value) . What the println! macro does is just calling that fmt method we define. The trait Debug does a similar thing, but for use with println!(\"{:?}\", value) . We can use any value with those constructs that implements the Display trait (for \"{}\" ) or the Debug trait (for \"{:?}\" ). The Debug trait we let the compiler implement (derive) for us. That is what the line #[derive(Debug)] does. And for our Display trait we are lazy and just use the function that was created by #[derive(Debug)] . The Error trait lets you implement a source() method, that is used to get a nested Error inside your Error, that was its cause. Think of exception stacks, only that we do not have exceptions, of course. That is exactly what we want for AsmErrorReport ; it is, after all, a wrapper for AsmError . AsmError on the other hand does not have a nested error, so we do not implement the source() method. The empty impl error::Error for AsmError block is still needed. If you remove it, the Error trait will not be implemented for AsmError . Cool story, but why do we do all this? This is what enables us to use the magic of anyhow in our lovas.rs . We can use AsmError and AsmErrorReport (wrapped in an Err() ) as return for our main function. It returns anyhow::Result<()> . And when there is an error returned by it, an error message is created and printed for us. With this we can easily create useful error messages in the error type itself, at the place where we understand, what errors exist and what they mean. And we need do it in that one place only. Every program that uses our library (as lovas.rs does) benefits from that without any extra work or even without knowing, error types can be returned by the library. The source code for this post can be found under the tag v0.0.8-journey . v0.0.8-journey source code v0.0.8-journey release v0.0.8-journey.zip v0.0.8-journey.tar.gz git checkout v0.0.8-journey What does this mean?","title":"impl error::Error"},{"location":"2022-08/handling-instructions.html","text":"Handling instructions \u00b6 kratenko \u00b7 kratenko 2022-08-08 \u00b7 Entry #23 \u00b7 4 min read \u00b7 v0.0.8-journey We took care of all the dirty work inside the assembler during the previous posts. We now have a cleanly parsed instruction with an optional argument that we can evaluate. Let us dive into parse_instruction() : /// Handles a single instruction of opcode an optional oparg parsed from Assembly file. fn parse_instruction ( & mut self , opname : & str , oparg : Option <& str > ) -> Result < (), AsmError > { match opname { \"nop\" => self . parse_a0_instruction ( op :: NOP , oparg ), \"fin\" => self . parse_a0_instruction ( op :: FIN , oparg ), \"pop\" => self . parse_a0_instruction ( op :: POP , oparg ), \"add\" => self . parse_a0_instruction ( op :: ADD , oparg ), \"sub\" => self . parse_a0_instruction ( op :: SUB , oparg ), \"mul\" => self . parse_a0_instruction ( op :: MUL , oparg ), \"div\" => self . parse_a0_instruction ( op :: DIV , oparg ), \"mod\" => self . parse_a0_instruction ( op :: MOD , oparg ), \"push_u8\" => { let oparg = oparg . ok_or ( AsmError :: MissingArgument ) ? ; let v = parse_int :: parse :: < u8 > ( oparg ). or ( Err ( AsmError :: InvalidArgument )) ? ; self . push_a1_instruction ( op :: PUSH_U8 , v ) }, \"goto\" => { let oparg = oparg . ok_or ( AsmError :: MissingArgument ) ? ; let v = parse_int :: parse :: < i16 > ( oparg ). or ( Err ( AsmError :: InvalidArgument )) ? ; let a = v . to_be_bytes (); self . push_a2_instruction ( op :: GOTO , a [ 0 ], a [ 1 ]) }, _ => Err ( AsmError :: UnknownInstruction ( String :: from ( opname ))) } } That is a surprisingly simple function. It receives two parameters. opname is a &str that holds the opname of the instruction. oparg is either None , if there was no argument in the instruction, or it holds a none-empty string that holds whatever argument was present in the instruction. The function only consists of a long match , that directly matches the opname against our known opnames. If there is no match, it returns a helpful error that even contains the unknown opname that was found. The explicit branches look a bit weirder. That is because I do not like to repeat myself when writing code. And Rust tends to allow some very dense source code. Different kind of instructions \u00b6 I decided to group by instructions into three categories. They are grouped by the number of bytes an instruction uses as argument. An a0 instruction has zero bytes of oparg, a1 has one byte, and a2 has two bytes. a0 \u00b6 Most of our operations do not allow any argument at all. We want to make sure that there is none given in the instruction. And the only difference in handling those instructions inside the assembler is the byte that will be written to the bytecode. We can handle all of those with the same function: parse_a0_instruction() : /// Helper that parses an instruction with no oparg and pushes it. fn parse_a0_instruction ( & mut self , opcode : u8 , oparg : Option <& str > ) -> Result < (), AsmError > { if oparg . is_some () { Err ( AsmError :: UnexpectedArgument ) } else { self . push_a0_instruction ( opcode ) } } If we did get an argument, we fail, since that is not allowed. And then we push a very basic instruction to the back of our program. We have helper functions to do that: /// Adds a single instruction to the end of the AsmProgram. fn push_instruction ( & mut self , i : AsmInstruction ) -> Result < (), AsmError > { self . text_pos += i . size (); self . instructions . push ( i ); Ok (()) } /// Helper that creates an instruction with 0 bytes of oparg and pushes it. fn push_a0_instruction ( & mut self , opcode : u8 ) -> Result < (), AsmError > { let i = AsmInstruction { line_number : self . line_number , opcode , oparg : vec ! [], pos : self . text_pos , }; self . push_instruction ( i ) } We create a new instruction instance and add it. We also track the position of every instruction in the bytecode, that is why we update the programs current position in the bytecode for every instruction we add (stored in text_pos ). There is nothing we do with that information, yet. But we will need that information later. a1: push_u8 \u00b6 We only have one operation that needs a single byte of oparg, and that is push_u8 . We use that operation to push values on the stack, taken directly from the bytecode. u8 is the only type supported at the moment. That is not even a hard restriction; you can easily get any i64 value to the stack by using basic arithmetics, and we have those. Parsing numbers is no fun. It is hard. So we let someone else do it for us. The crate we are using is called parse_int . Go take a look at what it can do. It allows us to enter numbers easily in hexadecimal, octal, or binary notation. That is a really handy feature in source code! Thanks, Rust community! So how are we parsing push_u8 ? \"push_u8\" => { let oparg = oparg . ok_or ( AsmError :: MissingArgument ) ? ; let v = parse_int :: parse :: < u8 > ( oparg ). or ( Err ( AsmError :: InvalidArgument )) ? ; self . push_a1_instruction ( op :: PUSH_U8 , v ) }, First we make sure that we have an argument. If not, we fail. We can again use our handy ? syntax. Then we try to parse it into a u8 , using parse_int . The syntax for that call takes some getting used to - I'm still waiting for me to getting used to it. But if it works, we now have a valid u8 . If it fails to parse, we quickly return with that failure information. If all goes well we will reach the third line, that calls our helper for adding a1 instructions. There is no big surprise in what that function does: /// Helper that creates an instruction with 1 byte of oparg and pushes it. fn push_a1_instruction ( & mut self , opcode : u8 , a0 : u8 ) -> Result < (), AsmError > { let i = AsmInstruction { line_number : self . line_number , opcode , oparg : vec ! [ a0 ], pos : self . text_pos , }; self . push_instruction ( i ) } An interesting detail is, that push_instruction() returns a Result , even though it can never fail! It always returns Ok(()) . And if you look at push_a2_instruction() , you will now see that it also will always return Ok(()) . We do be bother? Take a look at the handler for push_u8 again, in context of the complete function parse_instruction() . That function returns a Result , and it can return Err(...) . Because push_a1_instruction() has the same return value of Result , the calls integrate nicely with the layout of the complete function inside the match . For me, it gives the code a clean compactness. a2: goto \u00b6 There is one more branch to look at: \"goto\" => { let oparg = oparg . ok_or ( AsmError :: MissingArgument ) ? ; let v = parse_int :: parse :: < i16 > ( oparg ). or ( Err ( AsmError :: InvalidArgument )) ? ; let a = v . to_be_bytes (); self . push_a2_instruction ( op :: GOTO , a [ 0 ], a [ 1 ]) }, This time we use parse_int to read a i16 . Whether you like the ::<i16> syntax or not, at least you can see what it is for. We need to unpack the two bytes of the i16 after parsing, so that we can store the bytes correctly in the bytecode. to_be_bytes() gives us an array (of size 2) that holds the bytes in big endian byte order. to_le_bytes() is the little endian counterpart. I generally prefer big endian, when I can. And if you remember how we read the bytes in the VM, you can see that we are already using big endian there. There is nothing new in the push_a2_instruction() function, only one additional byte. /// Helper that creates an instruction with 1 byte of oparg and pushes it. fn push_a2_instruction ( & mut self , opcode : u8 , a0 : u8 , a1 : u8 ) -> Result < (), AsmError > { let i = AsmInstruction { line_number : self . line_number , opcode , oparg : vec ! [ a0 , a1 ], pos : self . text_pos , }; self . push_instruction ( i ) } Parsing completed \u00b6 We have now parsed the complete program source into the AsmPgm structure. Or we have failed to do so, in which case there is an Error stored in AsmPgm . Either way, you have now seen all the code that does the parsing. Next journal entry will finally produce the bytecode we are longing for. The source code for this post can be found under the tag v0.0.8-journey . v0.0.8-journey source code v0.0.8-journey release v0.0.8-journey.zip v0.0.8-journey.tar.gz git checkout v0.0.8-journey What does this mean?","title":" Handling instructions"},{"location":"2022-08/handling-instructions.html#handling-instructions","text":"kratenko \u00b7 kratenko 2022-08-08 \u00b7 Entry #23 \u00b7 4 min read \u00b7 v0.0.8-journey We took care of all the dirty work inside the assembler during the previous posts. We now have a cleanly parsed instruction with an optional argument that we can evaluate. Let us dive into parse_instruction() : /// Handles a single instruction of opcode an optional oparg parsed from Assembly file. fn parse_instruction ( & mut self , opname : & str , oparg : Option <& str > ) -> Result < (), AsmError > { match opname { \"nop\" => self . parse_a0_instruction ( op :: NOP , oparg ), \"fin\" => self . parse_a0_instruction ( op :: FIN , oparg ), \"pop\" => self . parse_a0_instruction ( op :: POP , oparg ), \"add\" => self . parse_a0_instruction ( op :: ADD , oparg ), \"sub\" => self . parse_a0_instruction ( op :: SUB , oparg ), \"mul\" => self . parse_a0_instruction ( op :: MUL , oparg ), \"div\" => self . parse_a0_instruction ( op :: DIV , oparg ), \"mod\" => self . parse_a0_instruction ( op :: MOD , oparg ), \"push_u8\" => { let oparg = oparg . ok_or ( AsmError :: MissingArgument ) ? ; let v = parse_int :: parse :: < u8 > ( oparg ). or ( Err ( AsmError :: InvalidArgument )) ? ; self . push_a1_instruction ( op :: PUSH_U8 , v ) }, \"goto\" => { let oparg = oparg . ok_or ( AsmError :: MissingArgument ) ? ; let v = parse_int :: parse :: < i16 > ( oparg ). or ( Err ( AsmError :: InvalidArgument )) ? ; let a = v . to_be_bytes (); self . push_a2_instruction ( op :: GOTO , a [ 0 ], a [ 1 ]) }, _ => Err ( AsmError :: UnknownInstruction ( String :: from ( opname ))) } } That is a surprisingly simple function. It receives two parameters. opname is a &str that holds the opname of the instruction. oparg is either None , if there was no argument in the instruction, or it holds a none-empty string that holds whatever argument was present in the instruction. The function only consists of a long match , that directly matches the opname against our known opnames. If there is no match, it returns a helpful error that even contains the unknown opname that was found. The explicit branches look a bit weirder. That is because I do not like to repeat myself when writing code. And Rust tends to allow some very dense source code.","title":"Handling instructions"},{"location":"2022-08/handling-instructions.html#different-kind-of-instructions","text":"I decided to group by instructions into three categories. They are grouped by the number of bytes an instruction uses as argument. An a0 instruction has zero bytes of oparg, a1 has one byte, and a2 has two bytes.","title":"Different kind of instructions"},{"location":"2022-08/handling-instructions.html#a0","text":"Most of our operations do not allow any argument at all. We want to make sure that there is none given in the instruction. And the only difference in handling those instructions inside the assembler is the byte that will be written to the bytecode. We can handle all of those with the same function: parse_a0_instruction() : /// Helper that parses an instruction with no oparg and pushes it. fn parse_a0_instruction ( & mut self , opcode : u8 , oparg : Option <& str > ) -> Result < (), AsmError > { if oparg . is_some () { Err ( AsmError :: UnexpectedArgument ) } else { self . push_a0_instruction ( opcode ) } } If we did get an argument, we fail, since that is not allowed. And then we push a very basic instruction to the back of our program. We have helper functions to do that: /// Adds a single instruction to the end of the AsmProgram. fn push_instruction ( & mut self , i : AsmInstruction ) -> Result < (), AsmError > { self . text_pos += i . size (); self . instructions . push ( i ); Ok (()) } /// Helper that creates an instruction with 0 bytes of oparg and pushes it. fn push_a0_instruction ( & mut self , opcode : u8 ) -> Result < (), AsmError > { let i = AsmInstruction { line_number : self . line_number , opcode , oparg : vec ! [], pos : self . text_pos , }; self . push_instruction ( i ) } We create a new instruction instance and add it. We also track the position of every instruction in the bytecode, that is why we update the programs current position in the bytecode for every instruction we add (stored in text_pos ). There is nothing we do with that information, yet. But we will need that information later.","title":"a0"},{"location":"2022-08/handling-instructions.html#a1-push_u8","text":"We only have one operation that needs a single byte of oparg, and that is push_u8 . We use that operation to push values on the stack, taken directly from the bytecode. u8 is the only type supported at the moment. That is not even a hard restriction; you can easily get any i64 value to the stack by using basic arithmetics, and we have those. Parsing numbers is no fun. It is hard. So we let someone else do it for us. The crate we are using is called parse_int . Go take a look at what it can do. It allows us to enter numbers easily in hexadecimal, octal, or binary notation. That is a really handy feature in source code! Thanks, Rust community! So how are we parsing push_u8 ? \"push_u8\" => { let oparg = oparg . ok_or ( AsmError :: MissingArgument ) ? ; let v = parse_int :: parse :: < u8 > ( oparg ). or ( Err ( AsmError :: InvalidArgument )) ? ; self . push_a1_instruction ( op :: PUSH_U8 , v ) }, First we make sure that we have an argument. If not, we fail. We can again use our handy ? syntax. Then we try to parse it into a u8 , using parse_int . The syntax for that call takes some getting used to - I'm still waiting for me to getting used to it. But if it works, we now have a valid u8 . If it fails to parse, we quickly return with that failure information. If all goes well we will reach the third line, that calls our helper for adding a1 instructions. There is no big surprise in what that function does: /// Helper that creates an instruction with 1 byte of oparg and pushes it. fn push_a1_instruction ( & mut self , opcode : u8 , a0 : u8 ) -> Result < (), AsmError > { let i = AsmInstruction { line_number : self . line_number , opcode , oparg : vec ! [ a0 ], pos : self . text_pos , }; self . push_instruction ( i ) } An interesting detail is, that push_instruction() returns a Result , even though it can never fail! It always returns Ok(()) . And if you look at push_a2_instruction() , you will now see that it also will always return Ok(()) . We do be bother? Take a look at the handler for push_u8 again, in context of the complete function parse_instruction() . That function returns a Result , and it can return Err(...) . Because push_a1_instruction() has the same return value of Result , the calls integrate nicely with the layout of the complete function inside the match . For me, it gives the code a clean compactness.","title":"a1: push_u8"},{"location":"2022-08/handling-instructions.html#a2-goto","text":"There is one more branch to look at: \"goto\" => { let oparg = oparg . ok_or ( AsmError :: MissingArgument ) ? ; let v = parse_int :: parse :: < i16 > ( oparg ). or ( Err ( AsmError :: InvalidArgument )) ? ; let a = v . to_be_bytes (); self . push_a2_instruction ( op :: GOTO , a [ 0 ], a [ 1 ]) }, This time we use parse_int to read a i16 . Whether you like the ::<i16> syntax or not, at least you can see what it is for. We need to unpack the two bytes of the i16 after parsing, so that we can store the bytes correctly in the bytecode. to_be_bytes() gives us an array (of size 2) that holds the bytes in big endian byte order. to_le_bytes() is the little endian counterpart. I generally prefer big endian, when I can. And if you remember how we read the bytes in the VM, you can see that we are already using big endian there. There is nothing new in the push_a2_instruction() function, only one additional byte. /// Helper that creates an instruction with 1 byte of oparg and pushes it. fn push_a2_instruction ( & mut self , opcode : u8 , a0 : u8 , a1 : u8 ) -> Result < (), AsmError > { let i = AsmInstruction { line_number : self . line_number , opcode , oparg : vec ! [ a0 , a1 ], pos : self . text_pos , }; self . push_instruction ( i ) }","title":"a2: goto"},{"location":"2022-08/handling-instructions.html#parsing-completed","text":"We have now parsed the complete program source into the AsmPgm structure. Or we have failed to do so, in which case there is an Error stored in AsmPgm . Either way, you have now seen all the code that does the parsing. Next journal entry will finally produce the bytecode we are longing for. The source code for this post can be found under the tag v0.0.8-journey . v0.0.8-journey source code v0.0.8-journey release v0.0.8-journey.zip v0.0.8-journey.tar.gz git checkout v0.0.8-journey What does this mean?","title":"Parsing completed"},{"location":"2022-08/running-assembler-programs.html","text":"Running assembler programs \u00b6 We will extend our assembler to do something useful, finally: execute our programs on lovem. kratenko \u00b7 kratenko 2022-08-10 \u00b7 Entry #25 \u00b7 6 min read \u00b7 v0.0.9-journey We have created ourselves an assembler in ~300 lines of code. And it has a command line interface, an API to be used in a program, and even useful error reporting. That is cool! But what do we do with the bytecode? It just dumps them to the console. That is not very useful. We could copy/paste that into one of our example binaries... This is not what we wanted. So let us enhance our assembler. Execution \u00b6 We add some features to lovas.rs . A new command line parameter --run , that takes no arguments. If you add that flag to the call, lovas will take the assembled program (if there are no errors), create an instance of the VM and run the program on it. Thanks to clap, that is really easy to do. We add another field to our Cli struct. Actually, while we are at it, we add four new parameters: #[clap(short, long, help = \"Run the assembled program in lovem.\" )] run : bool , #[clap(long, help = \"Enable tracing log when running lovem.\" )] trace : bool , #[clap(long, help = \"Output the program to stdout.\" )] print : bool , #[clap(long, default_value_t = 100, help = \"Setting the stack size for lovem when running the program.\" )] stack_size : usize , And we change what we do with a successfully created program, depending on our new flag: // run the assembler: match asm :: assemble ( & name , & content ) { Ok ( pgm ) => { if args . print { println! ( \"{:?}\" , pgm ); } // we succeeded and now have a program with bytecode: if args . run { // lovas was called with `--run`, so create a VM and execute program: run ( & pgm , & args ) ? } Ok (()) }, Err ( e ) => { // Something went wrong during assembly. // Convert the error report, so that `anyhow` can do its magic // and display some helpful error message: Err ( Error :: from ( e )) }, } Just printing the program to stdout is no very useful default behaviour for an assembler. It might still come in handy, if you want to see what you are executing, so we make it optional and for the caller to decide with the --print flag. If the --run flag is set, we call run() . So what does run() do? /// Executes a program in a freshly created lovem VM. fn run ( pgm : & Pgm , args : & Cli ) -> Result < () > { // Create our VM instance. let mut vm = VM :: new ( args . stack_size ); vm . trace = args . trace ; let start = Instant :: now (); let outcome = vm . run ( & pgm . text ); let duration = start . elapsed (); match outcome { Ok ( _ ) => { // Execution successful, program terminated: eprintln! ( \"Terminated. \\n Runtime={:?} \\n op_cnt={}, pc={}, stack-depth={}, watermark={}\" , duration , vm . op_cnt , vm . pc , vm . stack . len (), vm . watermark ); Ok (()) }, Err ( e ) => { // Runtime error. Error will be printed on return of main. eprintln! ( \"Runtime error! \\n Runtime={:?} \\n op_cnt={}, pc={}, stack-depth={}, watermark={}\" , duration , vm . op_cnt , vm . pc , vm . stack . len (), vm . watermark ); Err ( Error :: from ( e )) } } } We create a VM instance, and we run the program on it. If there is a RuntimeError , we return it, just as we did with the AsmErrorReport . Back in our examples, we created a VM with a stack size of 100 - simply because we needed a number there. 100 is still the default, but now you can choose the stack size, when calling lovas . If you do lovas --run pgm/some-program.lva --stack-size 512 lovas will execute the program in a VM with a stack that can hold 512 values. Trace Log \u00b6 When we were running a program in our VM, we did always get a lot of output during execution. That is nice for understanding, what a stack machine does, but in general it is not a got idea for a VM to do that. It can be very beneficial, if you run into a problem with your program, so it is an easily available tool for debugging. That is why I removed all those log messages from lovem, but I let some in that can be activated, if you set vm.trace = true . That is what we added the new command line parameter --trace for. You can now control, if you want to see it. Diagnostics \u00b6 There is some output by lovas , after the execution. It reports if the run was successfully terminated (by executing a fin instruction), or if there was a RuntimeError . In both cases it will show you the time the execution took (wallclock time), as well as the number of instructions executed by the VM, the final position of the programm counter, the number of values on the stack at termination, and the highest number of values on the stack at any time during execution (the watermark). This can give you some quick insight on what your program did and maybe where it ran into trouble. All this lead to some changes to vm.rs , but nothing that should give you any problems to understand. Remember that we have the power of git at our disposal, so you can easily find out what changed in a file between two releases. You could do that for vm.rs with this handy link: https://github.com/kratenko/lovem/compare/v0.0.8-journey...v0.0.9-journey#diff-3bc51552cab41d1a2dbf07842cb438088563f6134a9c69a266dfd0d79b631495 Our programs \u00b6 We have written a few example programs so far. Each is its own binary in src/bin/ , and all of them consist of the same Rust code of creating a VM and running a program. Only the bytecode changed between them. I got rid of all of those (except for the most basic one) and translated the programs into assembly programs that live in pgm/ . You can now execute those using lovas , like this: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/reverse-polish.lva --trace Compiling lovem v0.0.9 (/home/kratenko/git/lovem) Finished dev [unoptimized + debuginfo] target(s) in 2.02s Running `target/debug/lovas -r pgm/reverse-polish.lva --trace` VM { stack: [], pc: 0, op_cnt: 0, trace: true, watermark: 0 } Executing op 0x02 VM { stack: [5], pc: 2, op_cnt: 1, trace: true, watermark: 1 } Executing op 0x02 VM { stack: [5, 7], pc: 4, op_cnt: 2, trace: true, watermark: 2 } Executing op 0x02 VM { stack: [5, 7, 11], pc: 6, op_cnt: 3, trace: true, watermark: 3 } Executing op 0x11 VM { stack: [5, -4], pc: 7, op_cnt: 4, trace: true, watermark: 3 } Executing op 0x12 VM { stack: [-20], pc: 8, op_cnt: 5, trace: true, watermark: 3 } Executing op 0x02 VM { stack: [-20, 13], pc: 10, op_cnt: 6, trace: true, watermark: 3 } Executing op 0x02 VM { stack: [-20, 13, 17], pc: 12, op_cnt: 7, trace: true, watermark: 3 } Executing op 0x10 VM { stack: [-20, 30], pc: 13, op_cnt: 8, trace: true, watermark: 3 } Executing op 0x10 VM { stack: [10], pc: 14, op_cnt: 9, trace: true, watermark: 3 } Executing op 0x01 VM { stack: [], pc: 15, op_cnt: 10, trace: true, watermark: 3 } Terminated! VM { stack: [], pc: 16, op_cnt: 11, trace: true, watermark: 3 } Terminated. Runtime=49.33\u00b5s op_cnt=11, pc=16, stack size=0, watermark=3 Remember to add --trace to the call, or you won't see very much. It has become a lot easier, to play around with the VM. No more writing bytecode by hand! File extension \u00b6 You might have noticed that I changed the filename extension that I use for the assembly programs from .lass to .lva . There are multiple reasons, but the main one is, that I thought Lass could be a nice name for a programming language, when I will finally come to writing one for lovem. So I want to reserve the extension for that possible future. Playing around \u00b6 The diagnostic information given after the execution can be interesting, when you mess around. Let us play a bit with the program endless-stack.lva . # This program runs in an endless loop, but it will push a new value to the stack on every iteration. # It will inevitably lead to a stack overrun at some point and crash the program. push_u8 123 goto -5 fin The program will fill the stack until it is full, and then it will crash: Running `target/debug/lovas -r pgm/endless-stack.lva --print` Pgm { name: \"pgm/endless-stack.lva\", text: [2, 123, 32, 255, 251, 255] } Runtime error! Runtime=41.589\u00b5s op_cnt=201, pc=2, stack-depth=100, watermark=100 Error: StackOverflow After 201 executed instructions it crashes. The stack depth at the time of the crash is 100. That is the complete stack, the next instruction tried to push value 101, which must fail. Instruction number 201 did cause the crash. That makes sense, if you follow the execution in your head. And the program counter is on 2. The last instruction executed will be the one before that, which would be at 0. That is the push_u8 instruction. There is no surprise that the watermark is at 100. That is the highest possible value for it and also the current value of out stack depth. As we can now easily change the stack size, let us try what happens with a bigger stack: Running `target/debug/lovas -r pgm/endless-stack.lva --print --stack-size 150` Pgm { name: \"pgm/endless-stack.lva\", text: [2, 123, 32, 255, 251, 255] } Runtime error! Runtime=47.648\u00b5s op_cnt=301, pc=2, stack-depth=150, watermark=150 Error: StackOverflow So now the stack overflows at over 150 values, of course. And it takes 301 instructions to fill it. Runtime has been longer, but only about 15%. I would not have expected a rise of 50%, as there is overhead for starting the program. What happens, if we activate --trace ? Running `target/debug/lovas -r pgm/endless-stack.lva --print --stack-size 150 --trace` Pgm { name: \"pgm/endless-stack.lva\", text: [2, 123, 32, 255, 251, 255] } VM { stack: [], pc: 0, op_cnt: 0, trace: true, watermark: 0 } Executing op 0x02 VM { stack: [123], pc: 2, op_cnt: 1, trace: true, watermark: 1 } Executing op 0x20 [...] Executing op 0x02 Runtime error! Runtime=67.312973ms op_cnt=301, pc=2, stack-depth=150, watermark=150 Error: StackOverflow There is, of course, a lot of output, that I cut out. What is interesting is the change in execution time. I ran this inside the CLion IDE by JetBrains. The console there will not be a very fast console, as it does a lot with that output coming through. But the impact of the logging is enormous! The runtime until we hit our stack overflow is more than 1000 times longer! The exact numbers don't mean anything; we are running unoptimised Rust code with debuginfo, and the bottleneck is the console. But it is still fascinating to see. The source code for this post can be found under the tag v0.0.9-journey . v0.0.9-journey source code v0.0.9-journey release v0.0.9-journey.zip v0.0.9-journey.tar.gz git checkout v0.0.9-journey What does this mean?","title":" Running assembler programs"},{"location":"2022-08/running-assembler-programs.html#running-assembler-programs","text":"We will extend our assembler to do something useful, finally: execute our programs on lovem. kratenko \u00b7 kratenko 2022-08-10 \u00b7 Entry #25 \u00b7 6 min read \u00b7 v0.0.9-journey We have created ourselves an assembler in ~300 lines of code. And it has a command line interface, an API to be used in a program, and even useful error reporting. That is cool! But what do we do with the bytecode? It just dumps them to the console. That is not very useful. We could copy/paste that into one of our example binaries... This is not what we wanted. So let us enhance our assembler.","title":"Running assembler programs"},{"location":"2022-08/running-assembler-programs.html#execution","text":"We add some features to lovas.rs . A new command line parameter --run , that takes no arguments. If you add that flag to the call, lovas will take the assembled program (if there are no errors), create an instance of the VM and run the program on it. Thanks to clap, that is really easy to do. We add another field to our Cli struct. Actually, while we are at it, we add four new parameters: #[clap(short, long, help = \"Run the assembled program in lovem.\" )] run : bool , #[clap(long, help = \"Enable tracing log when running lovem.\" )] trace : bool , #[clap(long, help = \"Output the program to stdout.\" )] print : bool , #[clap(long, default_value_t = 100, help = \"Setting the stack size for lovem when running the program.\" )] stack_size : usize , And we change what we do with a successfully created program, depending on our new flag: // run the assembler: match asm :: assemble ( & name , & content ) { Ok ( pgm ) => { if args . print { println! ( \"{:?}\" , pgm ); } // we succeeded and now have a program with bytecode: if args . run { // lovas was called with `--run`, so create a VM and execute program: run ( & pgm , & args ) ? } Ok (()) }, Err ( e ) => { // Something went wrong during assembly. // Convert the error report, so that `anyhow` can do its magic // and display some helpful error message: Err ( Error :: from ( e )) }, } Just printing the program to stdout is no very useful default behaviour for an assembler. It might still come in handy, if you want to see what you are executing, so we make it optional and for the caller to decide with the --print flag. If the --run flag is set, we call run() . So what does run() do? /// Executes a program in a freshly created lovem VM. fn run ( pgm : & Pgm , args : & Cli ) -> Result < () > { // Create our VM instance. let mut vm = VM :: new ( args . stack_size ); vm . trace = args . trace ; let start = Instant :: now (); let outcome = vm . run ( & pgm . text ); let duration = start . elapsed (); match outcome { Ok ( _ ) => { // Execution successful, program terminated: eprintln! ( \"Terminated. \\n Runtime={:?} \\n op_cnt={}, pc={}, stack-depth={}, watermark={}\" , duration , vm . op_cnt , vm . pc , vm . stack . len (), vm . watermark ); Ok (()) }, Err ( e ) => { // Runtime error. Error will be printed on return of main. eprintln! ( \"Runtime error! \\n Runtime={:?} \\n op_cnt={}, pc={}, stack-depth={}, watermark={}\" , duration , vm . op_cnt , vm . pc , vm . stack . len (), vm . watermark ); Err ( Error :: from ( e )) } } } We create a VM instance, and we run the program on it. If there is a RuntimeError , we return it, just as we did with the AsmErrorReport . Back in our examples, we created a VM with a stack size of 100 - simply because we needed a number there. 100 is still the default, but now you can choose the stack size, when calling lovas . If you do lovas --run pgm/some-program.lva --stack-size 512 lovas will execute the program in a VM with a stack that can hold 512 values.","title":"Execution"},{"location":"2022-08/running-assembler-programs.html#trace-log","text":"When we were running a program in our VM, we did always get a lot of output during execution. That is nice for understanding, what a stack machine does, but in general it is not a got idea for a VM to do that. It can be very beneficial, if you run into a problem with your program, so it is an easily available tool for debugging. That is why I removed all those log messages from lovem, but I let some in that can be activated, if you set vm.trace = true . That is what we added the new command line parameter --trace for. You can now control, if you want to see it.","title":"Trace Log"},{"location":"2022-08/running-assembler-programs.html#diagnostics","text":"There is some output by lovas , after the execution. It reports if the run was successfully terminated (by executing a fin instruction), or if there was a RuntimeError . In both cases it will show you the time the execution took (wallclock time), as well as the number of instructions executed by the VM, the final position of the programm counter, the number of values on the stack at termination, and the highest number of values on the stack at any time during execution (the watermark). This can give you some quick insight on what your program did and maybe where it ran into trouble. All this lead to some changes to vm.rs , but nothing that should give you any problems to understand. Remember that we have the power of git at our disposal, so you can easily find out what changed in a file between two releases. You could do that for vm.rs with this handy link: https://github.com/kratenko/lovem/compare/v0.0.8-journey...v0.0.9-journey#diff-3bc51552cab41d1a2dbf07842cb438088563f6134a9c69a266dfd0d79b631495","title":"Diagnostics"},{"location":"2022-08/running-assembler-programs.html#our-programs","text":"We have written a few example programs so far. Each is its own binary in src/bin/ , and all of them consist of the same Rust code of creating a VM and running a program. Only the bytecode changed between them. I got rid of all of those (except for the most basic one) and translated the programs into assembly programs that live in pgm/ . You can now execute those using lovas , like this: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/reverse-polish.lva --trace Compiling lovem v0.0.9 (/home/kratenko/git/lovem) Finished dev [unoptimized + debuginfo] target(s) in 2.02s Running `target/debug/lovas -r pgm/reverse-polish.lva --trace` VM { stack: [], pc: 0, op_cnt: 0, trace: true, watermark: 0 } Executing op 0x02 VM { stack: [5], pc: 2, op_cnt: 1, trace: true, watermark: 1 } Executing op 0x02 VM { stack: [5, 7], pc: 4, op_cnt: 2, trace: true, watermark: 2 } Executing op 0x02 VM { stack: [5, 7, 11], pc: 6, op_cnt: 3, trace: true, watermark: 3 } Executing op 0x11 VM { stack: [5, -4], pc: 7, op_cnt: 4, trace: true, watermark: 3 } Executing op 0x12 VM { stack: [-20], pc: 8, op_cnt: 5, trace: true, watermark: 3 } Executing op 0x02 VM { stack: [-20, 13], pc: 10, op_cnt: 6, trace: true, watermark: 3 } Executing op 0x02 VM { stack: [-20, 13, 17], pc: 12, op_cnt: 7, trace: true, watermark: 3 } Executing op 0x10 VM { stack: [-20, 30], pc: 13, op_cnt: 8, trace: true, watermark: 3 } Executing op 0x10 VM { stack: [10], pc: 14, op_cnt: 9, trace: true, watermark: 3 } Executing op 0x01 VM { stack: [], pc: 15, op_cnt: 10, trace: true, watermark: 3 } Terminated! VM { stack: [], pc: 16, op_cnt: 11, trace: true, watermark: 3 } Terminated. Runtime=49.33\u00b5s op_cnt=11, pc=16, stack size=0, watermark=3 Remember to add --trace to the call, or you won't see very much. It has become a lot easier, to play around with the VM. No more writing bytecode by hand!","title":"Our programs"},{"location":"2022-08/running-assembler-programs.html#file-extension","text":"You might have noticed that I changed the filename extension that I use for the assembly programs from .lass to .lva . There are multiple reasons, but the main one is, that I thought Lass could be a nice name for a programming language, when I will finally come to writing one for lovem. So I want to reserve the extension for that possible future.","title":"File extension"},{"location":"2022-08/running-assembler-programs.html#playing-around","text":"The diagnostic information given after the execution can be interesting, when you mess around. Let us play a bit with the program endless-stack.lva . # This program runs in an endless loop, but it will push a new value to the stack on every iteration. # It will inevitably lead to a stack overrun at some point and crash the program. push_u8 123 goto -5 fin The program will fill the stack until it is full, and then it will crash: Running `target/debug/lovas -r pgm/endless-stack.lva --print` Pgm { name: \"pgm/endless-stack.lva\", text: [2, 123, 32, 255, 251, 255] } Runtime error! Runtime=41.589\u00b5s op_cnt=201, pc=2, stack-depth=100, watermark=100 Error: StackOverflow After 201 executed instructions it crashes. The stack depth at the time of the crash is 100. That is the complete stack, the next instruction tried to push value 101, which must fail. Instruction number 201 did cause the crash. That makes sense, if you follow the execution in your head. And the program counter is on 2. The last instruction executed will be the one before that, which would be at 0. That is the push_u8 instruction. There is no surprise that the watermark is at 100. That is the highest possible value for it and also the current value of out stack depth. As we can now easily change the stack size, let us try what happens with a bigger stack: Running `target/debug/lovas -r pgm/endless-stack.lva --print --stack-size 150` Pgm { name: \"pgm/endless-stack.lva\", text: [2, 123, 32, 255, 251, 255] } Runtime error! Runtime=47.648\u00b5s op_cnt=301, pc=2, stack-depth=150, watermark=150 Error: StackOverflow So now the stack overflows at over 150 values, of course. And it takes 301 instructions to fill it. Runtime has been longer, but only about 15%. I would not have expected a rise of 50%, as there is overhead for starting the program. What happens, if we activate --trace ? Running `target/debug/lovas -r pgm/endless-stack.lva --print --stack-size 150 --trace` Pgm { name: \"pgm/endless-stack.lva\", text: [2, 123, 32, 255, 251, 255] } VM { stack: [], pc: 0, op_cnt: 0, trace: true, watermark: 0 } Executing op 0x02 VM { stack: [123], pc: 2, op_cnt: 1, trace: true, watermark: 1 } Executing op 0x20 [...] Executing op 0x02 Runtime error! Runtime=67.312973ms op_cnt=301, pc=2, stack-depth=150, watermark=150 Error: StackOverflow There is, of course, a lot of output, that I cut out. What is interesting is the change in execution time. I ran this inside the CLion IDE by JetBrains. The console there will not be a very fast console, as it does a lot with that output coming through. But the impact of the logging is enormous! The runtime until we hit our stack overflow is more than 1000 times longer! The exact numbers don't mean anything; we are running unoptimised Rust code with debuginfo, and the bottleneck is the console. But it is still fascinating to see. The source code for this post can be found under the tag v0.0.9-journey . v0.0.9-journey source code v0.0.9-journey release v0.0.9-journey.zip v0.0.9-journey.tar.gz git checkout v0.0.9-journey What does this mean?","title":"Playing around"},{"location":"2022-08/what-if.html","text":"What if? \u00b6 Choose your path. kratenko \u00b7 kratenko 2022-08-19 \u00b7 Entry #27 \u00b7 6 min read \u00b7 v0.0.11-journey Our assembler gives us a lot of convenience for testing features of our VM. So let us start doing interesting stuff with it. We do have support for jumps already, but as it is now, save of an endless loop, there is absolutely no reason to do it, yet. All our programs run their predetermined way. If you look again at label.lva , you can see that none of those goto s introduce any dynamic. We could just ditch them and reorder the rest. It would do the same, only more efficient. They simple tangle up our linear code, without removing its linearity. Today we will introduce branches to our VM. A branch is a point in a program from which there are multiple possible paths to take. Two paths, normally. Which of those paths is takes is decided at runtime by looking at the state of the program. For us that means that we look at the value on top of the stack. How does it work? Conditional jump \u00b6 We already introduced the goto operation. What we will add now, works exactly the same way, but only if a certain condition is met. And, yes, we will call that operation if . But if what? How about if equal ? So we get the new opname ifeq , that pops a value from the stack and only executes its jump when that value is equal. Equal to what, you want to know? How about if it is equal to zero. If you want to compare it to a different number, it is easy to subtract that number from your value before you compare it to zero, and you achieve what you need. New operations \u00b6 We will introduce multiple if-operations. Six, to be precise. src/op.rs 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 /// opcode: Conditional relative jump (branch) on pop == zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFEQ : u8 = 0x21 ; /// opcode: Conditional relative jump (branch) on pop != zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFNE : u8 = 0x22 ; /// opcode: Conditional relative jump (branch) on pop < zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFLT : u8 = 0x23 ; /// opcode: Conditional relative jump (branch) on pop <= zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFLE : u8 = 0x24 ; /// opcode: Conditional relative jump (branch) on pop > zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFGT : u8 = 0x25 ; /// opcode: Conditional relative jump (branch) on pop >= zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFGE : u8 = 0x26 ; And we add another operation, while we add it: dup src/op.rs 21 22 23 24 25 /// opcode: Pop value from stack and push it back, twice. /// /// pop: 1, push: 2 /// oparg: 0 pub const DUP : u8 = 0x03 ; This one simply duplicates the value on top of the stack, so that there will be another copy of it on top of it. We will use that often when testing values with an if , if we still need the value after testing it. The if will consume the top most value. Extending the assembler \u00b6 We add the parsing handlers for our new instructions: src/asm.rs 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 fn parse_instruction ( & mut self , opname : & str , oparg : Option <& str > ) -> Result < (), AsmError > { match opname { \"nop\" => self . parse_a0_instruction ( op :: NOP , oparg ), \"fin\" => self . parse_a0_instruction ( op :: FIN , oparg ), \"pop\" => self . parse_a0_instruction ( op :: POP , oparg ), \"dup\" => self . parse_a0_instruction ( op :: DUP , oparg ), \"add\" => self . parse_a0_instruction ( op :: ADD , oparg ), \"sub\" => self . parse_a0_instruction ( op :: SUB , oparg ), \"mul\" => self . parse_a0_instruction ( op :: MUL , oparg ), \"div\" => self . parse_a0_instruction ( op :: DIV , oparg ), \"mod\" => self . parse_a0_instruction ( op :: MOD , oparg ), \"push_u8\" => { let oparg = oparg . ok_or ( AsmError :: MissingArgument ) ? ; let v = parse_int :: parse :: < u8 > ( oparg ). or ( Err ( AsmError :: InvalidArgument )) ? ; self . push_a1_instruction ( op :: PUSH_U8 , v ) }, \"goto\" => self . parse_label_instruction ( op :: GOTO , oparg ), \"ifeq\" => self . parse_label_instruction ( op :: IFEQ , oparg ), \"ifne\" => self . parse_label_instruction ( op :: IFNE , oparg ), \"iflt\" => self . parse_label_instruction ( op :: IFLT , oparg ), \"ifle\" => self . parse_label_instruction ( op :: IFLE , oparg ), \"ifgt\" => self . parse_label_instruction ( op :: IFGT , oparg ), \"ifge\" => self . parse_label_instruction ( op :: IFGE , oparg ), _ => Err ( AsmError :: UnknownInstruction ( String :: from ( opname ))) } } And that is all we need to change on our assembler. The way we have written it, it is easy to introduce new operations, when they share the same syntax in assembly and in bytecode as existing ones. Adjust the VM \u00b6 First, we add the handler for the dup . Just pop a value and push it back, twice. Easy. src/vm.rs 175 176 177 178 179 180 op :: DUP => { let v = self . pop () ? ; self . push ( v ) ? ; self . push ( v ) ? ; Ok (()) }, And now, the if* -handlers. They are similar to the goto -handler, just with an if added. src/vm.rs 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 op :: GOTO => { let d = self . fetch_i16 ( pgm ) ? ; self . relative_jump ( pgm , d ) }, op :: IFEQ => { let d = self . fetch_i16 ( pgm ) ? ; let v = self . pop () ? ; if v == 0 { self . relative_jump ( pgm , d ) } else { Ok (()) } }, op :: IFNE => { let d = self . fetch_i16 ( pgm ) ? ; let v = self . pop () ? ; if v != 0 { self . relative_jump ( pgm , d ) } else { Ok (()) } }, op :: IFLT => { let d = self . fetch_i16 ( pgm ) ? ; let v = self . pop () ? ; if v < 0 { self . relative_jump ( pgm , d ) } else { Ok (()) } }, op :: IFLE => { let d = self . fetch_i16 ( pgm ) ? ; let v = self . pop () ? ; if v <= 0 { self . relative_jump ( pgm , d ) } else { Ok (()) } }, op :: IFGT => { let d = self . fetch_i16 ( pgm ) ? ; let v = self . pop () ? ; if v > 0 { self . relative_jump ( pgm , d ) } else { Ok (()) } }, op :: IFGE => { let d = self . fetch_i16 ( pgm ) ? ; let v = self . pop () ? ; if v >= 0 { self . relative_jump ( pgm , d ) } else { Ok (()) } }, And that is all the code we have to change. Our VM can now execute conditional jumps. Now we can do some serious programming! A for-loop \u00b6 Can't wait to use an if in program: pgm/loop.lva 1 2 3 4 5 6 7 8 9 10 # Demonstrate the conditional jump (a branch) # The program has a loop that it executes thrice, before it terminates. push_u8 3 loop: push_u8 1 sub dup ifgt loop pop fin And execute it: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/loop.lva --print --trace Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas -r pgm/loop.lva --print --trace` Pgm { name: \"pgm/loop.lva\", text: [2, 3, 2, 1, 17, 3, 37, 255, 249, 1, 255] } VM { stack: [], pc: 0, op_cnt: 0, trace: true, watermark: 0 } Executing op 0x02 VM { stack: [3], pc: 2, op_cnt: 1, trace: true, watermark: 1 } Executing op 0x02 VM { stack: [3, 1], pc: 4, op_cnt: 2, trace: true, watermark: 2 } Executing op 0x11 VM { stack: [2], pc: 5, op_cnt: 3, trace: true, watermark: 2 } Executing op 0x03 VM { stack: [2, 2], pc: 6, op_cnt: 4, trace: true, watermark: 2 } Executing op 0x25 Jump from 9 by -7 VM { stack: [2], pc: 2, op_cnt: 5, trace: true, watermark: 2 } Executing op 0x02 VM { stack: [2, 1], pc: 4, op_cnt: 6, trace: true, watermark: 2 } Executing op 0x11 VM { stack: [1], pc: 5, op_cnt: 7, trace: true, watermark: 2 } Executing op 0x03 VM { stack: [1, 1], pc: 6, op_cnt: 8, trace: true, watermark: 2 } Executing op 0x25 Jump from 9 by -7 VM { stack: [1], pc: 2, op_cnt: 9, trace: true, watermark: 2 } Executing op 0x02 VM { stack: [1, 1], pc: 4, op_cnt: 10, trace: true, watermark: 2 } Executing op 0x11 VM { stack: [0], pc: 5, op_cnt: 11, trace: true, watermark: 2 } Executing op 0x03 VM { stack: [0, 0], pc: 6, op_cnt: 12, trace: true, watermark: 2 } Executing op 0x25 VM { stack: [0], pc: 9, op_cnt: 13, trace: true, watermark: 2 } Executing op 0x01 VM { stack: [], pc: 10, op_cnt: 14, trace: true, watermark: 2 } Terminated! VM { stack: [], pc: 11, op_cnt: 15, trace: true, watermark: 2 } Terminated. Runtime=100.972\u00b5s op_cnt=15, pc=11, stack-depth=0, watermark=2 Nice! This is basically a for-loop. Granted, it does not do anything but loop, but you can see how the program counts down from 3 to 0 and after the third time it reaches line 8, it stops jumping back to loop: and advances to the end. We can increase the number in line 3, and the number of runs increase with it. If we change it to 200 , we get this (I ditched the --trace for this). kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/loop.lva --print Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas -r pgm/loop.lva --print` Pgm { name: \"pgm/loop.lva\", text: [2, 200, 2, 1, 17, 3, 37, 255, 249, 1, 255] } Terminated. Runtime=128.709\u00b5s op_cnt=803, pc=11, stack-depth=0, watermark=2 More than 800 operations with only 10 lines of code. Shall we cranc it up to a million? kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/loop.lva --print Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas -r pgm/loop.lva --print` Pgm { name: \"pgm/loop.lva\", text: [2, 100, 2, 100, 18, 2, 100, 18, 2, 1, 17, 3, 37, 255, 249, 1, 255] } Terminated. Runtime=564.184652ms op_cnt=4000007, pc=17, stack-depth=0, watermark=2 Takes about have a second to execute, over 4000000 operations where executed. And the stack never held more than 2 values, as you can see by the watermark. We are programming! Homework \u00b6 Wait a second! Our only way of getting values on the stack is push_u8 . That can only push a u8 , so only values 0 - 255 . How did I push that 1000000 there? The source code for this post can be found under the tag v0.0.11-journey . v0.0.11-journey source code v0.0.11-journey release v0.0.11-journey.zip v0.0.11-journey.tar.gz git checkout v0.0.11-journey What does this mean?","title":" What if?"},{"location":"2022-08/what-if.html#what-if","text":"Choose your path. kratenko \u00b7 kratenko 2022-08-19 \u00b7 Entry #27 \u00b7 6 min read \u00b7 v0.0.11-journey Our assembler gives us a lot of convenience for testing features of our VM. So let us start doing interesting stuff with it. We do have support for jumps already, but as it is now, save of an endless loop, there is absolutely no reason to do it, yet. All our programs run their predetermined way. If you look again at label.lva , you can see that none of those goto s introduce any dynamic. We could just ditch them and reorder the rest. It would do the same, only more efficient. They simple tangle up our linear code, without removing its linearity. Today we will introduce branches to our VM. A branch is a point in a program from which there are multiple possible paths to take. Two paths, normally. Which of those paths is takes is decided at runtime by looking at the state of the program. For us that means that we look at the value on top of the stack. How does it work?","title":"What if?"},{"location":"2022-08/what-if.html#conditional-jump","text":"We already introduced the goto operation. What we will add now, works exactly the same way, but only if a certain condition is met. And, yes, we will call that operation if . But if what? How about if equal ? So we get the new opname ifeq , that pops a value from the stack and only executes its jump when that value is equal. Equal to what, you want to know? How about if it is equal to zero. If you want to compare it to a different number, it is easy to subtract that number from your value before you compare it to zero, and you achieve what you need.","title":"Conditional jump"},{"location":"2022-08/what-if.html#new-operations","text":"We will introduce multiple if-operations. Six, to be precise. src/op.rs 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 /// opcode: Conditional relative jump (branch) on pop == zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFEQ : u8 = 0x21 ; /// opcode: Conditional relative jump (branch) on pop != zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFNE : u8 = 0x22 ; /// opcode: Conditional relative jump (branch) on pop < zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFLT : u8 = 0x23 ; /// opcode: Conditional relative jump (branch) on pop <= zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFLE : u8 = 0x24 ; /// opcode: Conditional relative jump (branch) on pop > zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFGT : u8 = 0x25 ; /// opcode: Conditional relative jump (branch) on pop >= zero. /// /// pop: 1, push: 0 /// oparg: 2B, i16 relative jump pub const IFGE : u8 = 0x26 ; And we add another operation, while we add it: dup src/op.rs 21 22 23 24 25 /// opcode: Pop value from stack and push it back, twice. /// /// pop: 1, push: 2 /// oparg: 0 pub const DUP : u8 = 0x03 ; This one simply duplicates the value on top of the stack, so that there will be another copy of it on top of it. We will use that often when testing values with an if , if we still need the value after testing it. The if will consume the top most value.","title":"New operations"},{"location":"2022-08/what-if.html#extending-the-assembler","text":"We add the parsing handlers for our new instructions: src/asm.rs 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 fn parse_instruction ( & mut self , opname : & str , oparg : Option <& str > ) -> Result < (), AsmError > { match opname { \"nop\" => self . parse_a0_instruction ( op :: NOP , oparg ), \"fin\" => self . parse_a0_instruction ( op :: FIN , oparg ), \"pop\" => self . parse_a0_instruction ( op :: POP , oparg ), \"dup\" => self . parse_a0_instruction ( op :: DUP , oparg ), \"add\" => self . parse_a0_instruction ( op :: ADD , oparg ), \"sub\" => self . parse_a0_instruction ( op :: SUB , oparg ), \"mul\" => self . parse_a0_instruction ( op :: MUL , oparg ), \"div\" => self . parse_a0_instruction ( op :: DIV , oparg ), \"mod\" => self . parse_a0_instruction ( op :: MOD , oparg ), \"push_u8\" => { let oparg = oparg . ok_or ( AsmError :: MissingArgument ) ? ; let v = parse_int :: parse :: < u8 > ( oparg ). or ( Err ( AsmError :: InvalidArgument )) ? ; self . push_a1_instruction ( op :: PUSH_U8 , v ) }, \"goto\" => self . parse_label_instruction ( op :: GOTO , oparg ), \"ifeq\" => self . parse_label_instruction ( op :: IFEQ , oparg ), \"ifne\" => self . parse_label_instruction ( op :: IFNE , oparg ), \"iflt\" => self . parse_label_instruction ( op :: IFLT , oparg ), \"ifle\" => self . parse_label_instruction ( op :: IFLE , oparg ), \"ifgt\" => self . parse_label_instruction ( op :: IFGT , oparg ), \"ifge\" => self . parse_label_instruction ( op :: IFGE , oparg ), _ => Err ( AsmError :: UnknownInstruction ( String :: from ( opname ))) } } And that is all we need to change on our assembler. The way we have written it, it is easy to introduce new operations, when they share the same syntax in assembly and in bytecode as existing ones.","title":"Extending the assembler"},{"location":"2022-08/what-if.html#adjust-the-vm","text":"First, we add the handler for the dup . Just pop a value and push it back, twice. Easy. src/vm.rs 175 176 177 178 179 180 op :: DUP => { let v = self . pop () ? ; self . push ( v ) ? ; self . push ( v ) ? ; Ok (()) }, And now, the if* -handlers. They are similar to the goto -handler, just with an if added. src/vm.rs 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 op :: GOTO => { let d = self . fetch_i16 ( pgm ) ? ; self . relative_jump ( pgm , d ) }, op :: IFEQ => { let d = self . fetch_i16 ( pgm ) ? ; let v = self . pop () ? ; if v == 0 { self . relative_jump ( pgm , d ) } else { Ok (()) } }, op :: IFNE => { let d = self . fetch_i16 ( pgm ) ? ; let v = self . pop () ? ; if v != 0 { self . relative_jump ( pgm , d ) } else { Ok (()) } }, op :: IFLT => { let d = self . fetch_i16 ( pgm ) ? ; let v = self . pop () ? ; if v < 0 { self . relative_jump ( pgm , d ) } else { Ok (()) } }, op :: IFLE => { let d = self . fetch_i16 ( pgm ) ? ; let v = self . pop () ? ; if v <= 0 { self . relative_jump ( pgm , d ) } else { Ok (()) } }, op :: IFGT => { let d = self . fetch_i16 ( pgm ) ? ; let v = self . pop () ? ; if v > 0 { self . relative_jump ( pgm , d ) } else { Ok (()) } }, op :: IFGE => { let d = self . fetch_i16 ( pgm ) ? ; let v = self . pop () ? ; if v >= 0 { self . relative_jump ( pgm , d ) } else { Ok (()) } }, And that is all the code we have to change. Our VM can now execute conditional jumps. Now we can do some serious programming!","title":"Adjust the VM"},{"location":"2022-08/what-if.html#a-for-loop","text":"Can't wait to use an if in program: pgm/loop.lva 1 2 3 4 5 6 7 8 9 10 # Demonstrate the conditional jump (a branch) # The program has a loop that it executes thrice, before it terminates. push_u8 3 loop: push_u8 1 sub dup ifgt loop pop fin And execute it: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/loop.lva --print --trace Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas -r pgm/loop.lva --print --trace` Pgm { name: \"pgm/loop.lva\", text: [2, 3, 2, 1, 17, 3, 37, 255, 249, 1, 255] } VM { stack: [], pc: 0, op_cnt: 0, trace: true, watermark: 0 } Executing op 0x02 VM { stack: [3], pc: 2, op_cnt: 1, trace: true, watermark: 1 } Executing op 0x02 VM { stack: [3, 1], pc: 4, op_cnt: 2, trace: true, watermark: 2 } Executing op 0x11 VM { stack: [2], pc: 5, op_cnt: 3, trace: true, watermark: 2 } Executing op 0x03 VM { stack: [2, 2], pc: 6, op_cnt: 4, trace: true, watermark: 2 } Executing op 0x25 Jump from 9 by -7 VM { stack: [2], pc: 2, op_cnt: 5, trace: true, watermark: 2 } Executing op 0x02 VM { stack: [2, 1], pc: 4, op_cnt: 6, trace: true, watermark: 2 } Executing op 0x11 VM { stack: [1], pc: 5, op_cnt: 7, trace: true, watermark: 2 } Executing op 0x03 VM { stack: [1, 1], pc: 6, op_cnt: 8, trace: true, watermark: 2 } Executing op 0x25 Jump from 9 by -7 VM { stack: [1], pc: 2, op_cnt: 9, trace: true, watermark: 2 } Executing op 0x02 VM { stack: [1, 1], pc: 4, op_cnt: 10, trace: true, watermark: 2 } Executing op 0x11 VM { stack: [0], pc: 5, op_cnt: 11, trace: true, watermark: 2 } Executing op 0x03 VM { stack: [0, 0], pc: 6, op_cnt: 12, trace: true, watermark: 2 } Executing op 0x25 VM { stack: [0], pc: 9, op_cnt: 13, trace: true, watermark: 2 } Executing op 0x01 VM { stack: [], pc: 10, op_cnt: 14, trace: true, watermark: 2 } Terminated! VM { stack: [], pc: 11, op_cnt: 15, trace: true, watermark: 2 } Terminated. Runtime=100.972\u00b5s op_cnt=15, pc=11, stack-depth=0, watermark=2 Nice! This is basically a for-loop. Granted, it does not do anything but loop, but you can see how the program counts down from 3 to 0 and after the third time it reaches line 8, it stops jumping back to loop: and advances to the end. We can increase the number in line 3, and the number of runs increase with it. If we change it to 200 , we get this (I ditched the --trace for this). kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/loop.lva --print Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas -r pgm/loop.lva --print` Pgm { name: \"pgm/loop.lva\", text: [2, 200, 2, 1, 17, 3, 37, 255, 249, 1, 255] } Terminated. Runtime=128.709\u00b5s op_cnt=803, pc=11, stack-depth=0, watermark=2 More than 800 operations with only 10 lines of code. Shall we cranc it up to a million? kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/loop.lva --print Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas -r pgm/loop.lva --print` Pgm { name: \"pgm/loop.lva\", text: [2, 100, 2, 100, 18, 2, 100, 18, 2, 1, 17, 3, 37, 255, 249, 1, 255] } Terminated. Runtime=564.184652ms op_cnt=4000007, pc=17, stack-depth=0, watermark=2 Takes about have a second to execute, over 4000000 operations where executed. And the stack never held more than 2 values, as you can see by the watermark. We are programming!","title":"A for-loop"},{"location":"2022-08/what-if.html#homework","text":"Wait a second! Our only way of getting values on the stack is push_u8 . That can only push a u8 , so only values 0 - 255 . How did I push that 1000000 there? The source code for this post can be found under the tag v0.0.11-journey . v0.0.11-journey source code v0.0.11-journey release v0.0.11-journey.zip v0.0.11-journey.tar.gz git checkout v0.0.11-journey What does this mean?","title":"Homework"},{"location":"2022-08/you-labeled-me-i-ll-label-you.html","text":"You labeled me, I'll label you \u00b6 We add a feature to our assembler that we overlooked before. kratenko \u00b7 kratenko 2022-08-11 \u00b7 Entry #26 \u00b7 10 min read \u00b7 v0.0.10-journey Over the last few entries we created ourselves a really useful little assembler program. I hope you played around with it and enjoyed not having to write bytecode directly. If you did, you should have noticed that I left out a really important detail. Remember when I was complaining about how bad writing bytecode is? And that it got even worth, when we introduced jumps? Yeah, I did not solve that problem at all. If anything, I made it worse, because you still have to count the relative bytes to your destination, but you do not see those bytes any longer. You just have to know, how many bytes each instruction will produce. Labels \u00b6 There was so much already going on in that assembler program, that I did not want to introduce more complexity up front. Let's fix that now: we will introduce a way to give a position inside your program a name, so that you can goto that name later. And in good tradition, we will call this names labels . The traditional way of defining labels in assembly is by writing them first thing on a line, followed by a colon : . Take a look at this little program, label.lva . It is neither good style, nor does it do anything useful, but it shows us labels: pgm/label.lva 1 2 3 4 5 6 7 8 9 10 # A small demonstration of how labels work with goto. push_u8 1 goto coda back: push_u8 3 fin coda: push_u8 2 goto back There are two labels defined here: back in line 5, and coda in line 9. A label definition is a short string that is directly followed by a colon : . We restrict it to letters, numbers, and underscore, with a letter at the front. For the curious, the regex is: ^[A-Za-z][0-9A-Za-z_]{0,31}$ . As you can see in the example, there can be an optional instruction in the same line as the label definition. Now, how will our assembler parse those? Reconstruction \u00b6 First of all, I did a little reconstruction inside asm.rs , because I did not like how the parsing was done inside an associated function, that also created the AsmPgm instance. That seems messed up. After the change, the fn assemble() creates the instance itself and then calls a method on it, to parse the source code. Here is the new version: src/asm.rs 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 /// Parse assembly source code and turn it into a runnable program (or create report). pub fn assemble ( name : & str , content : & str ) -> Result < Pgm , AsmErrorReport > { // create a new, clean instance to fill during parsing: let mut asm_pgm = AsmPgm { name : String :: from ( name ), instructions : vec ! [], line_number : 0 , text_pos : 0 , error : None , labels : Default :: default (), }; // evaluate the source code: asm_pgm . process_assembly ( content ); // convert to Pgm instance if successful, or to Error Report, if assembly failed: asm_pgm . to_program () } And there is no problem with us changing the code like this. The only public function inside asm.rs is that pub fn assemble() . All methods of AsmPgm are private and therefore internal detail. Not that it would matter at this state of development, but it demonstrates how separation of public API and internal implementation work. What is also new in that function is a new field inside AsmPgm : labels . /// A assembler program during parsing/assembling. #[derive(Debug)] struct AsmPgm { .. . /// A map storing label definitions by name with there position in bytecode. labels : HashMap < String , usize > , } It is a HashMap (aka. associative array in other languages). This is where we put all label definitions we find, while parsing the source file. It maps the label's name to its position inside the bytecode. Here we can look up where to jump, for a goto that wants to jump to a label. This is what our parsing methods now look like: 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 fn process ( & mut self , content : & str ) -> Result < (), AsmError > { // Go over complete source, extracting instructions. Some will have their opargs // left empty (with placeholders). self . parse ( content ) ? ; self . update_instructions () } /// Process assembly source code. Must be used with \"empty\" AsmPgm. fn process_assembly ( & mut self , content : & str ) { // this function is just a wrapper around `process()`, so that I can use the // return magic and don't need to write the error check twice. if let Err ( e ) = self . process ( content ) { self . error = Some ( e ); } } The important part is, that we have to steps now. We parse the complete source, as before. The second run is needed to write the actual relative jump address to the instructions. We do not know them during parsing, at least not for jumps forward. Parsing label definitions \u00b6 I got a little fancy again, while writing the function for parsing label definitions: 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 /// Parses and extracts optional label definition from line. /// /// Looks for a colon ':'. If one exists, the part before the first colon will be /// seen as the name for a label, that is defined on this line. Instructions inside /// the program that execute jumps can refer to these labels as a destination. /// Lines containing a label definition may also contain an instruction and/or a comment. /// This can return `AsmError::InvalidLabel` if the part before the colon is not a valid /// label name, or `AsmError::DuplicateLabel` if a label name is reused. /// If a label could be parsed, it will be stored to the `AsmPgm`. /// On success, the line without the label definition is returned, so that it can be /// used to extract an instruction. This will be the complete line, if there was no /// label definition. fn parse_label_definition <' a > ( & mut self , line : & ' a str ) -> Result <&' a str , AsmError > { if let Some (( label , rest )) = line . split_once ( \":\" ) { let label = label . trim_start (); if VALID_LABEL . is_match ( label ) { if self . labels . contains_key ( label ) { Err ( AsmError :: DuplicateLabel ( String :: from ( label ))) } else { self . labels . insert ( String :: from ( label ), self . text_pos ); Ok ( rest ) } } else { Err ( AsmError :: InvalidLabel ( String :: from ( label ))) } } else { Ok ( line ) } } The method is trying to find a label definition in the line, and if so, handles it. We use our trusted Result<> returning, to communicate potential errors. But instead of Ok(()) , which is the empty okay value, we return a &str on success. This is because there might also be an instruction in the line. If we find a label definition, it returns the line after the colon. If there is none, it returns the complete line it got. This gives us the lines as we used to get before we introduced labels. Great. But what is that weird 'a that shows up in that highlighted line everywhere? Lifetime \u00b6 Yeah, this is where it becomes rusty, again. I said, in an early post, that you would hate the Rust compiler and its pedantic error messages. The thing Rust is most pedantic about, is ownership and access to values you do not own. We are working with references to String s here. A &str references the bytes inside that String directly (a &str need not reference a String , but it does here). We did that before, where is the problem now? This is the first time we are returning a &str . When you are using references, Rust makes sure that the value you are referencing exists at least as long as the reference exists. That is easy for functions, as long as you drop every reference you have when you are done. But in this function, we return a reference to the parameter we got. Rust cannot allow that without some special care. When I remove the 'a parts of the method, I get a compilation error: error[E0623]: lifetime mismatch --> src/asm.rs:277:21 | 269 | fn parse_label_definition(&mut self, line: &str) -> Result<&str, AsmError> { | ---- ---------------------- | | | this parameter and the return type are declared with different lifetimes... ... 277 | Ok(rest) | ^^^^^^^^ ...but data from `line` is returned here | = note: each elided lifetime in input position becomes a distinct lifetime help: consider introducing a named lifetime parameter and update trait if needed | 269 | fn parse_label_definition<'a>(&'a mut self, line: &'a str) -> Result<&str, AsmError> { | ++++ ++ ++ The compiler tells me, that I messed up the lifetimes. It even proposes a change that introduces lifetime parameters (but gets it slightly wrong). What do we do with the 'a ? Well we introduce a lifetime parameter called a . The syntax for that is the apostrophe, which looked weird to me at start, but it is so lightweight, that I came to like it. It is custom, to just call your lifetimes 'a , 'b , ... \u2013 they normally don't have a long scope anyway. The thing we are telling the compiler with this parameter is this: the lifetime of the returned &str is dependent on the lifetime of the parameter line: &str . So whenever the reference the function is called with runs out of scope, the reference that was returned must be out of scope as well. An example \u00b6 This is a concept that is new to many programmers when they learn Rust. I think, what we do here demonstrates it quiet well. Let us look at what happens for line 9 of our assembly program: pgm/label.lva 9 coda: push_u8 2 Our function receives a reference to a String holding that line: \" coda: push_u8 2\" . It finds the label coda and stores it inside self.labels . Its work is done, but there might be more to this line. It returns a reference to a substring of it ( &str are actually slices; they can reference only a part of a String 's data). That is what we return, a reference to the part data inside the String , starting at the first char after the colon, so it looks like this \" push_u8 2\" . It is not a copy, it is the same area inside the computer's memory! So if you want to make certain, that there are no accesses to memory after its content has run out of scope (use after free, or use of local variable after it runs our of scope), you must not allow access to it, unless you are sure the value still exists. And this is what Rust does. This is what makes Rust a secure language. Many bugs and exploits in the world exist, because most languages do not check this, but leave the responsibility to the programmer. And the really cool thing about Rust is, it does this completely at compile time, as you can see by the fact that we got a compiler error. The way we call our function is not a problem at all: src/asm.rs 292 293 294 295 296 297 298 for ( n , line ) in content . lines (). enumerate () { // File lines start counting at 1: self . line_number = n + 1 ; let line = self . parse_label_definition ( line ) ? ; let line = AsmPgm :: clean_line ( line ); self . parse_clean_line ( line ) ? ; } Our initial line comes from line 228. It is already a reference, because content.lines() is also giving us a reference to the memory inside of content . That is a reference already, the String variable that holds (and owns) the data lives inside lovas.rs : src/bin/lovas.rs 67 68 69 70 71 72 73 // read complete source file into String: let content = std :: fs :: read_to_string ( & args . source ) . with_context ( || format! ( \"could not read file `{}`\" , & name ) ) ? ; // run the assembler: match asm :: assemble ( & name , & content ) { We do not copy any of that bytes along the way. The first time we do that is in clean_line() . Returning a &str will not work there, because we actually modify the contents of the string, by replacing characters inside it. Have you ever tried to work with inplace \"substrings\" (I mean char arrays, like this char *str ), without modifying the contents (placing \\0 bytes). It is not fun. In Rust, it can be, if you understand lifetime restrictions. Easy way out \u00b6 If you run into problems with your &str inside a Rust program, there is often an easy way to get around that. You can simply create a new String from your &str , as we do in clean_line() . That will copy the bytes. For our program, that would have been no problem at all. Cloning a few bytes of source code for every line during assembly would cost us next to nothing. You would not notice in execution time. But things are different when you need to quickly handle long substrings in a program. Think of a diagnostic job on a busy server. And remember that String s will be created on the heap. That is a complexity that you sometimes want to avoid. When programming microcontrollers, there is a chance that you do not even have a memory allocator at your disposal. And microcontrollers is, what we are aiming for in our project. There are already some parts of lovem, that we will need to change, because of that. But that is a story for another time. I just thought that this was a nice little example to introduce you to lifetime parameters. We will need them at some point... Run it already! \u00b6 This is a long entry already. You can look at the complete state of the assembler directly in the sourcecode. You should know how to find the tags inside the repo by now. But I want to execute our new program, using the labels, before I end this. Here it is again: pgm/label.lva 1 2 3 4 5 6 7 8 9 10 # A small demonstration of how labels work with goto. push_u8 1 goto coda back: push_u8 3 fin coda: push_u8 2 goto back We need to execute it with the --trace flag, or we will not see anything: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/label.lva --print --trace Compiling lovem v0.0.10 (/home/kratenko/git/lovem) Finished dev [unoptimized + debuginfo] target(s) in 1.33s Running `target/debug/lovas -r pgm/label.lva --print --trace` Pgm { name: \"pgm/label.lva\", text: [2, 1, 32, 0, 3, 2, 3, 255, 2, 2, 32, 255, 248] } VM { stack: [], pc: 0, op_cnt: 0, trace: true, watermark: 0 } Executing op 0x02 VM { stack: [1], pc: 2, op_cnt: 1, trace: true, watermark: 1 } Executing op 0x20 Jump from 5 by 3 VM { stack: [1], pc: 8, op_cnt: 2, trace: true, watermark: 1 } Executing op 0x02 VM { stack: [1, 2], pc: 10, op_cnt: 3, trace: true, watermark: 2 } Executing op 0x20 Jump from 13 by -8 VM { stack: [1, 2], pc: 5, op_cnt: 4, trace: true, watermark: 2 } Executing op 0x02 VM { stack: [1, 2, 3], pc: 7, op_cnt: 5, trace: true, watermark: 3 } Terminated! VM { stack: [1, 2, 3], pc: 8, op_cnt: 6, trace: true, watermark: 3 } Terminated. Runtime=65.598\u00b5s op_cnt=6, pc=8, stack-depth=3, watermark=3 The program has three push_u8 operations. If you executed them in the order of the source code, they would push [1, 3, 2] to the stack. But because of the goto instructions, they are not executed in that order. You can see the jumps in the trace, and you can see that the stack at termination holds the values in this order: [1, 2, 3] . Not much of a program, but it shows you, how our new labels work. And finally: no more counting bytes! Homework \u00b6 Our programs endless.lva and endless-stack.lva no longer work, because we changed how the goto instruction must be written. Can you fix them? The source code for this post can be found under the tag v0.0.10-journey . v0.0.10-journey source code v0.0.10-journey release v0.0.10-journey.zip v0.0.10-journey.tar.gz git checkout v0.0.10-journey What does this mean?","title":" You labeled me, I'll label you"},{"location":"2022-08/you-labeled-me-i-ll-label-you.html#you-labeled-me-ill-label-you","text":"We add a feature to our assembler that we overlooked before. kratenko \u00b7 kratenko 2022-08-11 \u00b7 Entry #26 \u00b7 10 min read \u00b7 v0.0.10-journey Over the last few entries we created ourselves a really useful little assembler program. I hope you played around with it and enjoyed not having to write bytecode directly. If you did, you should have noticed that I left out a really important detail. Remember when I was complaining about how bad writing bytecode is? And that it got even worth, when we introduced jumps? Yeah, I did not solve that problem at all. If anything, I made it worse, because you still have to count the relative bytes to your destination, but you do not see those bytes any longer. You just have to know, how many bytes each instruction will produce.","title":"You labeled me, I'll label you"},{"location":"2022-08/you-labeled-me-i-ll-label-you.html#labels","text":"There was so much already going on in that assembler program, that I did not want to introduce more complexity up front. Let's fix that now: we will introduce a way to give a position inside your program a name, so that you can goto that name later. And in good tradition, we will call this names labels . The traditional way of defining labels in assembly is by writing them first thing on a line, followed by a colon : . Take a look at this little program, label.lva . It is neither good style, nor does it do anything useful, but it shows us labels: pgm/label.lva 1 2 3 4 5 6 7 8 9 10 # A small demonstration of how labels work with goto. push_u8 1 goto coda back: push_u8 3 fin coda: push_u8 2 goto back There are two labels defined here: back in line 5, and coda in line 9. A label definition is a short string that is directly followed by a colon : . We restrict it to letters, numbers, and underscore, with a letter at the front. For the curious, the regex is: ^[A-Za-z][0-9A-Za-z_]{0,31}$ . As you can see in the example, there can be an optional instruction in the same line as the label definition. Now, how will our assembler parse those?","title":"Labels"},{"location":"2022-08/you-labeled-me-i-ll-label-you.html#reconstruction","text":"First of all, I did a little reconstruction inside asm.rs , because I did not like how the parsing was done inside an associated function, that also created the AsmPgm instance. That seems messed up. After the change, the fn assemble() creates the instance itself and then calls a method on it, to parse the source code. Here is the new version: src/asm.rs 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 /// Parse assembly source code and turn it into a runnable program (or create report). pub fn assemble ( name : & str , content : & str ) -> Result < Pgm , AsmErrorReport > { // create a new, clean instance to fill during parsing: let mut asm_pgm = AsmPgm { name : String :: from ( name ), instructions : vec ! [], line_number : 0 , text_pos : 0 , error : None , labels : Default :: default (), }; // evaluate the source code: asm_pgm . process_assembly ( content ); // convert to Pgm instance if successful, or to Error Report, if assembly failed: asm_pgm . to_program () } And there is no problem with us changing the code like this. The only public function inside asm.rs is that pub fn assemble() . All methods of AsmPgm are private and therefore internal detail. Not that it would matter at this state of development, but it demonstrates how separation of public API and internal implementation work. What is also new in that function is a new field inside AsmPgm : labels . /// A assembler program during parsing/assembling. #[derive(Debug)] struct AsmPgm { .. . /// A map storing label definitions by name with there position in bytecode. labels : HashMap < String , usize > , } It is a HashMap (aka. associative array in other languages). This is where we put all label definitions we find, while parsing the source file. It maps the label's name to its position inside the bytecode. Here we can look up where to jump, for a goto that wants to jump to a label. This is what our parsing methods now look like: 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 fn process ( & mut self , content : & str ) -> Result < (), AsmError > { // Go over complete source, extracting instructions. Some will have their opargs // left empty (with placeholders). self . parse ( content ) ? ; self . update_instructions () } /// Process assembly source code. Must be used with \"empty\" AsmPgm. fn process_assembly ( & mut self , content : & str ) { // this function is just a wrapper around `process()`, so that I can use the // return magic and don't need to write the error check twice. if let Err ( e ) = self . process ( content ) { self . error = Some ( e ); } } The important part is, that we have to steps now. We parse the complete source, as before. The second run is needed to write the actual relative jump address to the instructions. We do not know them during parsing, at least not for jumps forward.","title":"Reconstruction"},{"location":"2022-08/you-labeled-me-i-ll-label-you.html#parsing-label-definitions","text":"I got a little fancy again, while writing the function for parsing label definitions: 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 /// Parses and extracts optional label definition from line. /// /// Looks for a colon ':'. If one exists, the part before the first colon will be /// seen as the name for a label, that is defined on this line. Instructions inside /// the program that execute jumps can refer to these labels as a destination. /// Lines containing a label definition may also contain an instruction and/or a comment. /// This can return `AsmError::InvalidLabel` if the part before the colon is not a valid /// label name, or `AsmError::DuplicateLabel` if a label name is reused. /// If a label could be parsed, it will be stored to the `AsmPgm`. /// On success, the line without the label definition is returned, so that it can be /// used to extract an instruction. This will be the complete line, if there was no /// label definition. fn parse_label_definition <' a > ( & mut self , line : & ' a str ) -> Result <&' a str , AsmError > { if let Some (( label , rest )) = line . split_once ( \":\" ) { let label = label . trim_start (); if VALID_LABEL . is_match ( label ) { if self . labels . contains_key ( label ) { Err ( AsmError :: DuplicateLabel ( String :: from ( label ))) } else { self . labels . insert ( String :: from ( label ), self . text_pos ); Ok ( rest ) } } else { Err ( AsmError :: InvalidLabel ( String :: from ( label ))) } } else { Ok ( line ) } } The method is trying to find a label definition in the line, and if so, handles it. We use our trusted Result<> returning, to communicate potential errors. But instead of Ok(()) , which is the empty okay value, we return a &str on success. This is because there might also be an instruction in the line. If we find a label definition, it returns the line after the colon. If there is none, it returns the complete line it got. This gives us the lines as we used to get before we introduced labels. Great. But what is that weird 'a that shows up in that highlighted line everywhere?","title":"Parsing label definitions"},{"location":"2022-08/you-labeled-me-i-ll-label-you.html#lifetime","text":"Yeah, this is where it becomes rusty, again. I said, in an early post, that you would hate the Rust compiler and its pedantic error messages. The thing Rust is most pedantic about, is ownership and access to values you do not own. We are working with references to String s here. A &str references the bytes inside that String directly (a &str need not reference a String , but it does here). We did that before, where is the problem now? This is the first time we are returning a &str . When you are using references, Rust makes sure that the value you are referencing exists at least as long as the reference exists. That is easy for functions, as long as you drop every reference you have when you are done. But in this function, we return a reference to the parameter we got. Rust cannot allow that without some special care. When I remove the 'a parts of the method, I get a compilation error: error[E0623]: lifetime mismatch --> src/asm.rs:277:21 | 269 | fn parse_label_definition(&mut self, line: &str) -> Result<&str, AsmError> { | ---- ---------------------- | | | this parameter and the return type are declared with different lifetimes... ... 277 | Ok(rest) | ^^^^^^^^ ...but data from `line` is returned here | = note: each elided lifetime in input position becomes a distinct lifetime help: consider introducing a named lifetime parameter and update trait if needed | 269 | fn parse_label_definition<'a>(&'a mut self, line: &'a str) -> Result<&str, AsmError> { | ++++ ++ ++ The compiler tells me, that I messed up the lifetimes. It even proposes a change that introduces lifetime parameters (but gets it slightly wrong). What do we do with the 'a ? Well we introduce a lifetime parameter called a . The syntax for that is the apostrophe, which looked weird to me at start, but it is so lightweight, that I came to like it. It is custom, to just call your lifetimes 'a , 'b , ... \u2013 they normally don't have a long scope anyway. The thing we are telling the compiler with this parameter is this: the lifetime of the returned &str is dependent on the lifetime of the parameter line: &str . So whenever the reference the function is called with runs out of scope, the reference that was returned must be out of scope as well.","title":"Lifetime"},{"location":"2022-08/you-labeled-me-i-ll-label-you.html#an-example","text":"This is a concept that is new to many programmers when they learn Rust. I think, what we do here demonstrates it quiet well. Let us look at what happens for line 9 of our assembly program: pgm/label.lva 9 coda: push_u8 2 Our function receives a reference to a String holding that line: \" coda: push_u8 2\" . It finds the label coda and stores it inside self.labels . Its work is done, but there might be more to this line. It returns a reference to a substring of it ( &str are actually slices; they can reference only a part of a String 's data). That is what we return, a reference to the part data inside the String , starting at the first char after the colon, so it looks like this \" push_u8 2\" . It is not a copy, it is the same area inside the computer's memory! So if you want to make certain, that there are no accesses to memory after its content has run out of scope (use after free, or use of local variable after it runs our of scope), you must not allow access to it, unless you are sure the value still exists. And this is what Rust does. This is what makes Rust a secure language. Many bugs and exploits in the world exist, because most languages do not check this, but leave the responsibility to the programmer. And the really cool thing about Rust is, it does this completely at compile time, as you can see by the fact that we got a compiler error. The way we call our function is not a problem at all: src/asm.rs 292 293 294 295 296 297 298 for ( n , line ) in content . lines (). enumerate () { // File lines start counting at 1: self . line_number = n + 1 ; let line = self . parse_label_definition ( line ) ? ; let line = AsmPgm :: clean_line ( line ); self . parse_clean_line ( line ) ? ; } Our initial line comes from line 228. It is already a reference, because content.lines() is also giving us a reference to the memory inside of content . That is a reference already, the String variable that holds (and owns) the data lives inside lovas.rs : src/bin/lovas.rs 67 68 69 70 71 72 73 // read complete source file into String: let content = std :: fs :: read_to_string ( & args . source ) . with_context ( || format! ( \"could not read file `{}`\" , & name ) ) ? ; // run the assembler: match asm :: assemble ( & name , & content ) { We do not copy any of that bytes along the way. The first time we do that is in clean_line() . Returning a &str will not work there, because we actually modify the contents of the string, by replacing characters inside it. Have you ever tried to work with inplace \"substrings\" (I mean char arrays, like this char *str ), without modifying the contents (placing \\0 bytes). It is not fun. In Rust, it can be, if you understand lifetime restrictions.","title":"An example"},{"location":"2022-08/you-labeled-me-i-ll-label-you.html#easy-way-out","text":"If you run into problems with your &str inside a Rust program, there is often an easy way to get around that. You can simply create a new String from your &str , as we do in clean_line() . That will copy the bytes. For our program, that would have been no problem at all. Cloning a few bytes of source code for every line during assembly would cost us next to nothing. You would not notice in execution time. But things are different when you need to quickly handle long substrings in a program. Think of a diagnostic job on a busy server. And remember that String s will be created on the heap. That is a complexity that you sometimes want to avoid. When programming microcontrollers, there is a chance that you do not even have a memory allocator at your disposal. And microcontrollers is, what we are aiming for in our project. There are already some parts of lovem, that we will need to change, because of that. But that is a story for another time. I just thought that this was a nice little example to introduce you to lifetime parameters. We will need them at some point...","title":"Easy way out"},{"location":"2022-08/you-labeled-me-i-ll-label-you.html#run-it-already","text":"This is a long entry already. You can look at the complete state of the assembler directly in the sourcecode. You should know how to find the tags inside the repo by now. But I want to execute our new program, using the labels, before I end this. Here it is again: pgm/label.lva 1 2 3 4 5 6 7 8 9 10 # A small demonstration of how labels work with goto. push_u8 1 goto coda back: push_u8 3 fin coda: push_u8 2 goto back We need to execute it with the --trace flag, or we will not see anything: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/label.lva --print --trace Compiling lovem v0.0.10 (/home/kratenko/git/lovem) Finished dev [unoptimized + debuginfo] target(s) in 1.33s Running `target/debug/lovas -r pgm/label.lva --print --trace` Pgm { name: \"pgm/label.lva\", text: [2, 1, 32, 0, 3, 2, 3, 255, 2, 2, 32, 255, 248] } VM { stack: [], pc: 0, op_cnt: 0, trace: true, watermark: 0 } Executing op 0x02 VM { stack: [1], pc: 2, op_cnt: 1, trace: true, watermark: 1 } Executing op 0x20 Jump from 5 by 3 VM { stack: [1], pc: 8, op_cnt: 2, trace: true, watermark: 1 } Executing op 0x02 VM { stack: [1, 2], pc: 10, op_cnt: 3, trace: true, watermark: 2 } Executing op 0x20 Jump from 13 by -8 VM { stack: [1, 2], pc: 5, op_cnt: 4, trace: true, watermark: 2 } Executing op 0x02 VM { stack: [1, 2, 3], pc: 7, op_cnt: 5, trace: true, watermark: 3 } Terminated! VM { stack: [1, 2, 3], pc: 8, op_cnt: 6, trace: true, watermark: 3 } Terminated. Runtime=65.598\u00b5s op_cnt=6, pc=8, stack-depth=3, watermark=3 The program has three push_u8 operations. If you executed them in the order of the source code, they would push [1, 3, 2] to the stack. But because of the goto instructions, they are not executed in that order. You can see the jumps in the trace, and you can see that the stack at termination holds the values in this order: [1, 2, 3] . Not much of a program, but it shows you, how our new labels work. And finally: no more counting bytes!","title":"Run it already!"},{"location":"2022-08/you-labeled-me-i-ll-label-you.html#homework","text":"Our programs endless.lva and endless-stack.lva no longer work, because we changed how the goto instruction must be written. Can you fix them? The source code for this post can be found under the tag v0.0.10-journey . v0.0.10-journey source code v0.0.10-journey release v0.0.10-journey.zip v0.0.10-journey.tar.gz git checkout v0.0.10-journey What does this mean?","title":"Homework"},{"location":"2024-02/index.html","text":"Journal entries from February 2024 \u00b6 Read all in single page We have variables! \u00b6 A stack alone is not that mighty. But now we can stow data away. kratenko \u00b7 kratenko 2024-02-11 \u00b7 Entry #30 \u00b7 4 min read \u00b7 v0.0.13-journey I implemented variables for the VM. And I did it in a way, that will freak out programmers, who have only ever worked with high languages in well-behaved environments \u2013 we now have variable support, but for global variables only. Continue reading Stop right there, that's far enough! \u00b6 We introduce an optional execution limit to our VM. kratenko \u00b7 kratenko 2024-02-02 \u00b7 Entry #29 \u00b7 3 min read \u00b7 v0.0.12-journey Since we have goto , we can write looping programs. With if* we have potentially looping programs as well. Both of this open the potential for endless loops. There are situations, in which endless loops are required. But often they are something to be avoided. Continue reading It has been a while... \u00b6 Love is not dead! It just got distracted. kratenko \u00b7 kratenko 2024-02-01 \u00b7 Entry #28 \u00b7 1 min read Yes, I have been gone for a while. More than a year, in fact. The project \u2013 lovem \u2013 is not dead, however. In fact, I even have multiple posts already written, that I just need to publish. So let's start doing that. After this short intermission, I will publish an additional entry in the journey, that will take us further along the path to creating our VM. Continue reading","title":"Journal entries from February 2024"},{"location":"2024-02/index.html#journal-entries-from-february-2024","text":"Read all in single page","title":"Journal entries from February 2024"},{"location":"2024-02/index.html#we-have-variables","text":"A stack alone is not that mighty. But now we can stow data away. kratenko \u00b7 kratenko 2024-02-11 \u00b7 Entry #30 \u00b7 4 min read \u00b7 v0.0.13-journey I implemented variables for the VM. And I did it in a way, that will freak out programmers, who have only ever worked with high languages in well-behaved environments \u2013 we now have variable support, but for global variables only. Continue reading","title":"We have variables!"},{"location":"2024-02/index.html#stop-right-there-thats-far-enough","text":"We introduce an optional execution limit to our VM. kratenko \u00b7 kratenko 2024-02-02 \u00b7 Entry #29 \u00b7 3 min read \u00b7 v0.0.12-journey Since we have goto , we can write looping programs. With if* we have potentially looping programs as well. Both of this open the potential for endless loops. There are situations, in which endless loops are required. But often they are something to be avoided. Continue reading","title":"Stop right there, that's far enough!"},{"location":"2024-02/index.html#it-has-been-a-while","text":"Love is not dead! It just got distracted. kratenko \u00b7 kratenko 2024-02-01 \u00b7 Entry #28 \u00b7 1 min read Yes, I have been gone for a while. More than a year, in fact. The project \u2013 lovem \u2013 is not dead, however. In fact, I even have multiple posts already written, that I just need to publish. So let's start doing that. After this short intermission, I will publish an additional entry in the journey, that will take us further along the path to creating our VM. Continue reading","title":"It has been a while..."},{"location":"2024-02/ALL.html","text":"Complete month of February 2024 \u00b6 It has been a while... \u00b6 Love is not dead! It just got distracted. kratenko \u00b7 kratenko 2024-02-01 \u00b7 Entry #28 \u00b7 1 min read Yes, I have been gone for a while. More than a year, in fact. The project \u2013 lovem \u2013 is not dead, however. In fact, I even have multiple posts already written, that I just need to publish. So let's start doing that. After this short intermission, I will publish an additional entry in the journey, that will take us further along the path to creating our VM. To be quite honest \u2013 I dated this entry back to yesterday. The reason is, that my journal, as I currently run it, does not really support multiple entries on the same day. Yes, I could simply add a time to the publication date, but that breaks continuity. And I don't plan to normally release multiple entries on the same day, as I want to keep the pace not too high. One post every two or three days is what I aim for, just the way I used to have it. A few things have changed in the meantime. For reasons that I have no desire to explain, I have removed the link to my Twitter account from the journal, and replaced it with a link to my Mastodon account. You can find me under @kratenko@chaos.social there. I also used to announce new entries over Twitter. I guess I will move that over to Mastodon as well. I guess we will see how that goes. But now let's get back to the journey. We will next implement a simple feature, that makes allows the VM to limit the processing time of a program \u2013 which can be very useful, especially when running user supplied code inside the machine. Building an endless loop inside a turing complete (or not even) language is quite easy. Having an embedded device stuck in an endless loop is often a catastrophe... Stop right there, that's far enough! \u00b6 We introduce an optional execution limit to our VM. kratenko \u00b7 kratenko 2024-02-02 \u00b7 Entry #29 \u00b7 3 min read \u00b7 v0.0.12-journey Since we have goto , we can write looping programs. With if* we have potentially looping programs as well. Both of this open the potential for endless loops. There are situations, in which endless loops are required. But often they are something to be avoided. Looping a long time \u00b6 Let us look at a little program: pgm/long-loop.lva 1 2 3 4 5 6 7 8 9 10 ## Looping a looooong time. ## This program will not run forever, but you will not see it terminate either. push_u8 0 loop: push_u8 1 add dup ifgt loop pop fin Someone messed up the loop condition there. If you run this program, it will be running for a long time. We start at zero and add to the value until our number is smaller than 0. Sounds impossible to reach for normal people, programmers will now better. Eventually we will reach the integer overflow, and our signed integer will loop around from its highest possible value to the lowest possible one. But do remember, what type we currently use to store our values: i64 . So how big is that highest number? 9223372036854775807 Is that a lot? That depends. Last entry I had my program loop for 1 million rounds. It took my modern laptop about half a second. So reaching that number should take 9223372036854.775807 times as long, that is around 4611686018427 seconds or just about 146135 years. Is that a lot? Oh, and by the way, the Rust professionals reading this will have spotted a potentially false claim there. While we run our program in debug mode, there will be no integer wraparound, instead the program will panic. If we build our Rust program in release mode, we will have integer wraparound, and will (theoretically) eventually reach the end of our loop. But that is besides the point. Limited execution \u00b6 The reason I started writing lovem , is that I need an embeddable lightweight VM to execute programmable handlers when certain events occur on my restrained embedded devices. So we are talking about some form of user generated content that is executed as a program! We can never trust those programs to be solid. We need a way to limit execution in some way, so that the device has the possibility to terminate those programs. There is an easy way to achieve that with what we already have. We put a limit on the number of operations the VM will execute. We add a few lines to our VM's main loop: src/vm.rs 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 // Loop going through the whole program, one instruction at a time. loop { // Log the vm's complete state, so we can follow what happens in console: if self . trace { println! ( \"{:?}\" , self ); } // Fetch next opcode from program (increases program counter): let opcode = self . fetch_u8 ( pgm ) ? ; // Limit execution by number of instructions that will be executed: if self . instruction_limit != 0 && self . op_cnt >= self . instruction_limit { return Err ( RuntimeError :: InstructionLimitExceeded ); } // We count the number of instructions we execute: self . op_cnt += 1 ; // If we are done, break loop and stop execution: if opcode == op :: FIN { break ; } // Execute the current instruction (with the opcode we loaded already): self . execute_op ( pgm , opcode ) ? ; } And of course we also add that new RuntimeError::InstructionLimitExceeded and a new field pub instruction_limit: usize, to our VM struct. lovas gets a new optional parameter: src/bin/lovas.rs 34 35 # #[clap(long, default_value_t = 1000000, help = \"Limit max number of instructions allowed for execution. 0 for unlimited.\" )] instruction_limit : usize , And we need to pass that to the VM in the run() function: src/bin/lovas.rs 38 39 40 41 42 43 44 45 46 47 /// Executes a program in a freshly created lovem VM. fn run ( pgm : & Pgm , args : & Cli ) -> Result < () > { // Create our VM instance. let mut vm = VM :: new ( args . stack_size ); vm . trace = args . trace ; vm . instruction_limit = args . instruction_limit ; let start = Instant :: now (); let outcome = vm . run ( & pgm . text ); let duration = start . elapsed (); .. . And, well, that's it. We now have an optional execution limitation that we default at 1 million. Testing it \u00b6 kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/long-loop.lva --print Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas -r pgm/long-loop.lva --print` Pgm { name: \"pgm/long-loop.lva\", text: [2, 0, 2, 1, 16, 3, 37, 255, 249, 1, 255] } Runtime error! Runtime=142.400812ms op_cnt=1000000, pc=7, stack-depth=2, watermark=2 Error: InstructionLimitExceeded We can adjust it easily: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/long-loop.lva --print --instruction-limit=100 Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas -r pgm/long-loop.lva --print --instruction-limit=100` Pgm { name: \"pgm/long-loop.lva\", text: [2, 0, 2, 1, 16, 3, 37, 255, 249, 1, 255] } Runtime error! Runtime=19.096\u00b5s op_cnt=100, pc=7, stack-depth=2, watermark=2 Error: InstructionLimitExceeded And we can just as well disable it completely: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/long-loop.lva --print --instruction-limit=0 Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas -r pgm/long-loop.lva --print --instruction-limit=0` Pgm { name: \"pgm/long-loop.lva\", text: [2, 0, 2, 1, 16, 3, 37, 255, 249, 1, 255] } Good luck waiting for this one. I hope you know how to terminate a running program on your system... We have variables! \u00b6 A stack alone is not that mighty. But now we can stow data away. kratenko \u00b7 kratenko 2024-02-11 \u00b7 Entry #30 \u00b7 4 min read \u00b7 v0.0.13-journey I implemented variables for the VM. And I did it in a way, that will freak out programmers, who have only ever worked with high languages in well-behaved environments \u2013 we now have variable support, but for global variables only. Why would I do that? Well, it was easy. You might be surprised how easy it was. And it helps a lot in having something useful. For what I am going for, it would actually be a viable thing, too. You could do a lot. But don't worry, I want local variables, too. Tell me were to stick it \u00b6 Variables need to live somewhere. When I first talked about stack machines, I said that \"no other direct manipulations of the stack [were] allowed [but push or pop].\" We will now see, why I added the direct there. Variables hold values; words, to be more precise. We have an entity, that can hold an arbitrary number of words: the stack. So, what is the idea? When I write a program, I will know how many variables it will need. Actually, our assembler now can do that for us. When I pass the program to the VM for execution, it looks at that number, and pushes that many zeros on the stack. Then it marks the current stack position as the new bottom. It does that by the newly introduces special Frame Base Register (FB) . What's with that funny name? This is something I will need later, when I introduce real function calls inside the VM. A call will create a new frame that is somewhat like a new local execution environment. This will also allow for local variables (told ya, I want those). But for now we have up to 256 global variables at our disposal. That is quite a bit. Variable operations \u00b6 There are two new operations for handling global variables: store : pop a value from the stack and store it in the global variable identified by the 1-byte oparg. load : read value from the global variable identified by the 1-byte oparg and push it to the stack. Variables in the assembler \u00b6 This took more work than the changes in the VM. That is good, because we want to hide complexity away from the VM. The assembler runs on a powerful computer, and typically programs are run more often than they are assembled/compiled. I want named variables in assembler source. The VM works only with numbers to identify them. Our assembler translates that for us. store and load each take the name of a variable as argument. When the assembler finds a new variable name, it is assigned a number (starting at 0). We actually just chunk them in a Vector and run through it everytime. We only support 256 variables, so there is no need to optimise there. It's fast enough. The index number is written as u8 as a single byte oparg. I leave it to you to look at the new source code in asm.rs this time. It is not too hard, and you should know enough Rust by now. A new Program \u00b6 There is more information to store for a Program now, than only the text (aka. the bytecode): the global variables. The information we store is just the number of variables the program has. That is all we need, we are not interested in their names. And it is the bytecode's responsibility, to access the correct variables. But since we now need that information in the VM, we finally change the parameter passed to run() from &[u8] to &Pgm . That is what caused the most changes inside vm.rs . The real additions are few. Variables in the VM \u00b6 The VM itself gets a new field: fb: usize . That is the frame base register, and it currently does nothing but point to the position inside the stack behind the last global variable. So with zero variables, nothing changes. We also add RuntimeError::InvalidVariable . Initialising the VM now includes making space for the variables: src/vm.rs 146 147 148 149 150 // create global variables in stack: for _ in 0 .. pgm . vars { self . push ( 0 ) ? ; } self . fb = pgm . vars as usize ; Popping values now needs to respect the frame base register, so it now looks this: src/vm.rs 68 69 70 71 72 73 74 75 /// Tries and pops a value from value stack, respecting frame base. fn pop ( & mut self ) -> Result < i64 , RuntimeError > { if self . stack . len () > self . fb { Ok ( self . stack . pop (). unwrap ()) } else { Err ( RuntimeError :: StackUnderflow ) } } And we need operation handlers, of course: src/vm.rs 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 op :: STORE => { let idx = self . fetch_u8 ( pgm ) ? ; if idx >= pgm . vars { Err ( RuntimeError :: InvalidVariable ) } else { let v = self . pop () ? ; self . stack [ idx as usize ] = v ; Ok (()) } }, op :: LOAD => { let idx = self . fetch_u8 ( pgm ) ? ; if idx >= pgm . vars { Err ( RuntimeError :: InvalidVariable ) } else { self . push ( self . stack [ idx as usize ]) ? ; Ok (()) } }, That's it. We now support variables! Show me your values \u00b6 I added another operation with the opname out . It pops a value from the stack and prints it to stdout. This is not an operation that you would normally want in your VM. Output should be generated by function calls. But we don't have those, yet. I want something to easily show values during development, so you can see what happens, without always using --trace . We can always remove it, later. There is nothing new to that operation, so I won't discuss the code here. A new program! \u00b6 pgm/duplicate.lva 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 ## A program demonstrating use of variables. start: # val = 1 push_u8 1 store val # variable is declared implicitly here. We only have one type: i64 # for loop, 5 rounds: push_u8 5 loop: # val = val * 2: load val push_u8 2 mul store val # check loop counter: push_u8 1 sub dup ifgt loop end: pop # output final value of val load val out fin The program is documented with comments. And you might have noticed that I define labels that I never use. I just want to structure the program and name its parts. We don't have functions, so I use what we have. kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/duplicate.lva --print Compiling lovem v0.0.13 (/home/kratenko/git/lovem) Finished dev [unoptimized + debuginfo] target(s) in 2.66s Running `target/debug/lovas -r pgm/duplicate.lva --print` Pgm { name: \"pgm/duplicate.lva\", text: [2, 1, 4, 0, 2, 5, 5, 0, 2, 2, 18, 4, 0, 2, 1, 17, 3, 37, 255, 242, 1, 5, 0, 6, 255], vars: 1 } Out: 32 (@46) Terminated. Runtime=18.156\u00b5s op_cnt=47, pc=25, stack-depth=1, watermark=4 It outputs a 32. That is good, because we start with a 1 and multiply it by 2 five times. We can write programs! Oh... and a bugfix \u00b6 I found out that I introduced a bug when writing the parsing label definitions. I parsed for the colon : , before I removed the comments. So a line with no label definition, but with a comment containing a colon did produce a parsing error. ## this was fine :label # this was fine :another # even this : was fine ## but this would produce an error: just a colon in a comment I fixed that by removing comments from lines first.","title":"February 2024 complete"},{"location":"2024-02/ALL.html#complete-month-of-february-2024","text":"","title":"Complete month of February 2024"},{"location":"2024-02/ALL.html#it-has-been-a-while","text":"Love is not dead! It just got distracted. kratenko \u00b7 kratenko 2024-02-01 \u00b7 Entry #28 \u00b7 1 min read Yes, I have been gone for a while. More than a year, in fact. The project \u2013 lovem \u2013 is not dead, however. In fact, I even have multiple posts already written, that I just need to publish. So let's start doing that. After this short intermission, I will publish an additional entry in the journey, that will take us further along the path to creating our VM. To be quite honest \u2013 I dated this entry back to yesterday. The reason is, that my journal, as I currently run it, does not really support multiple entries on the same day. Yes, I could simply add a time to the publication date, but that breaks continuity. And I don't plan to normally release multiple entries on the same day, as I want to keep the pace not too high. One post every two or three days is what I aim for, just the way I used to have it. A few things have changed in the meantime. For reasons that I have no desire to explain, I have removed the link to my Twitter account from the journal, and replaced it with a link to my Mastodon account. You can find me under @kratenko@chaos.social there. I also used to announce new entries over Twitter. I guess I will move that over to Mastodon as well. I guess we will see how that goes. But now let's get back to the journey. We will next implement a simple feature, that makes allows the VM to limit the processing time of a program \u2013 which can be very useful, especially when running user supplied code inside the machine. Building an endless loop inside a turing complete (or not even) language is quite easy. Having an embedded device stuck in an endless loop is often a catastrophe...","title":"It has been a while..."},{"location":"2024-02/ALL.html#stop-right-there-thats-far-enough","text":"We introduce an optional execution limit to our VM. kratenko \u00b7 kratenko 2024-02-02 \u00b7 Entry #29 \u00b7 3 min read \u00b7 v0.0.12-journey Since we have goto , we can write looping programs. With if* we have potentially looping programs as well. Both of this open the potential for endless loops. There are situations, in which endless loops are required. But often they are something to be avoided.","title":"Stop right there, that's far enough!"},{"location":"2024-02/ALL.html#looping-a-long-time","text":"Let us look at a little program: pgm/long-loop.lva 1 2 3 4 5 6 7 8 9 10 ## Looping a looooong time. ## This program will not run forever, but you will not see it terminate either. push_u8 0 loop: push_u8 1 add dup ifgt loop pop fin Someone messed up the loop condition there. If you run this program, it will be running for a long time. We start at zero and add to the value until our number is smaller than 0. Sounds impossible to reach for normal people, programmers will now better. Eventually we will reach the integer overflow, and our signed integer will loop around from its highest possible value to the lowest possible one. But do remember, what type we currently use to store our values: i64 . So how big is that highest number? 9223372036854775807 Is that a lot? That depends. Last entry I had my program loop for 1 million rounds. It took my modern laptop about half a second. So reaching that number should take 9223372036854.775807 times as long, that is around 4611686018427 seconds or just about 146135 years. Is that a lot? Oh, and by the way, the Rust professionals reading this will have spotted a potentially false claim there. While we run our program in debug mode, there will be no integer wraparound, instead the program will panic. If we build our Rust program in release mode, we will have integer wraparound, and will (theoretically) eventually reach the end of our loop. But that is besides the point.","title":"Looping a long time"},{"location":"2024-02/ALL.html#limited-execution","text":"The reason I started writing lovem , is that I need an embeddable lightweight VM to execute programmable handlers when certain events occur on my restrained embedded devices. So we are talking about some form of user generated content that is executed as a program! We can never trust those programs to be solid. We need a way to limit execution in some way, so that the device has the possibility to terminate those programs. There is an easy way to achieve that with what we already have. We put a limit on the number of operations the VM will execute. We add a few lines to our VM's main loop: src/vm.rs 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 // Loop going through the whole program, one instruction at a time. loop { // Log the vm's complete state, so we can follow what happens in console: if self . trace { println! ( \"{:?}\" , self ); } // Fetch next opcode from program (increases program counter): let opcode = self . fetch_u8 ( pgm ) ? ; // Limit execution by number of instructions that will be executed: if self . instruction_limit != 0 && self . op_cnt >= self . instruction_limit { return Err ( RuntimeError :: InstructionLimitExceeded ); } // We count the number of instructions we execute: self . op_cnt += 1 ; // If we are done, break loop and stop execution: if opcode == op :: FIN { break ; } // Execute the current instruction (with the opcode we loaded already): self . execute_op ( pgm , opcode ) ? ; } And of course we also add that new RuntimeError::InstructionLimitExceeded and a new field pub instruction_limit: usize, to our VM struct. lovas gets a new optional parameter: src/bin/lovas.rs 34 35 # #[clap(long, default_value_t = 1000000, help = \"Limit max number of instructions allowed for execution. 0 for unlimited.\" )] instruction_limit : usize , And we need to pass that to the VM in the run() function: src/bin/lovas.rs 38 39 40 41 42 43 44 45 46 47 /// Executes a program in a freshly created lovem VM. fn run ( pgm : & Pgm , args : & Cli ) -> Result < () > { // Create our VM instance. let mut vm = VM :: new ( args . stack_size ); vm . trace = args . trace ; vm . instruction_limit = args . instruction_limit ; let start = Instant :: now (); let outcome = vm . run ( & pgm . text ); let duration = start . elapsed (); .. . And, well, that's it. We now have an optional execution limitation that we default at 1 million.","title":"Limited execution"},{"location":"2024-02/ALL.html#testing-it","text":"kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/long-loop.lva --print Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas -r pgm/long-loop.lva --print` Pgm { name: \"pgm/long-loop.lva\", text: [2, 0, 2, 1, 16, 3, 37, 255, 249, 1, 255] } Runtime error! Runtime=142.400812ms op_cnt=1000000, pc=7, stack-depth=2, watermark=2 Error: InstructionLimitExceeded We can adjust it easily: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/long-loop.lva --print --instruction-limit=100 Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas -r pgm/long-loop.lva --print --instruction-limit=100` Pgm { name: \"pgm/long-loop.lva\", text: [2, 0, 2, 1, 16, 3, 37, 255, 249, 1, 255] } Runtime error! Runtime=19.096\u00b5s op_cnt=100, pc=7, stack-depth=2, watermark=2 Error: InstructionLimitExceeded And we can just as well disable it completely: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/long-loop.lva --print --instruction-limit=0 Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas -r pgm/long-loop.lva --print --instruction-limit=0` Pgm { name: \"pgm/long-loop.lva\", text: [2, 0, 2, 1, 16, 3, 37, 255, 249, 1, 255] } Good luck waiting for this one. I hope you know how to terminate a running program on your system...","title":"Testing it"},{"location":"2024-02/ALL.html#we-have-variables","text":"A stack alone is not that mighty. But now we can stow data away. kratenko \u00b7 kratenko 2024-02-11 \u00b7 Entry #30 \u00b7 4 min read \u00b7 v0.0.13-journey I implemented variables for the VM. And I did it in a way, that will freak out programmers, who have only ever worked with high languages in well-behaved environments \u2013 we now have variable support, but for global variables only. Why would I do that? Well, it was easy. You might be surprised how easy it was. And it helps a lot in having something useful. For what I am going for, it would actually be a viable thing, too. You could do a lot. But don't worry, I want local variables, too.","title":"We have variables!"},{"location":"2024-02/ALL.html#tell-me-were-to-stick-it","text":"Variables need to live somewhere. When I first talked about stack machines, I said that \"no other direct manipulations of the stack [were] allowed [but push or pop].\" We will now see, why I added the direct there. Variables hold values; words, to be more precise. We have an entity, that can hold an arbitrary number of words: the stack. So, what is the idea? When I write a program, I will know how many variables it will need. Actually, our assembler now can do that for us. When I pass the program to the VM for execution, it looks at that number, and pushes that many zeros on the stack. Then it marks the current stack position as the new bottom. It does that by the newly introduces special Frame Base Register (FB) . What's with that funny name? This is something I will need later, when I introduce real function calls inside the VM. A call will create a new frame that is somewhat like a new local execution environment. This will also allow for local variables (told ya, I want those). But for now we have up to 256 global variables at our disposal. That is quite a bit.","title":"Tell me were to stick it"},{"location":"2024-02/ALL.html#variable-operations","text":"There are two new operations for handling global variables: store : pop a value from the stack and store it in the global variable identified by the 1-byte oparg. load : read value from the global variable identified by the 1-byte oparg and push it to the stack.","title":"Variable operations"},{"location":"2024-02/ALL.html#variables-in-the-assembler","text":"This took more work than the changes in the VM. That is good, because we want to hide complexity away from the VM. The assembler runs on a powerful computer, and typically programs are run more often than they are assembled/compiled. I want named variables in assembler source. The VM works only with numbers to identify them. Our assembler translates that for us. store and load each take the name of a variable as argument. When the assembler finds a new variable name, it is assigned a number (starting at 0). We actually just chunk them in a Vector and run through it everytime. We only support 256 variables, so there is no need to optimise there. It's fast enough. The index number is written as u8 as a single byte oparg. I leave it to you to look at the new source code in asm.rs this time. It is not too hard, and you should know enough Rust by now.","title":"Variables in the assembler"},{"location":"2024-02/ALL.html#a-new-program","text":"There is more information to store for a Program now, than only the text (aka. the bytecode): the global variables. The information we store is just the number of variables the program has. That is all we need, we are not interested in their names. And it is the bytecode's responsibility, to access the correct variables. But since we now need that information in the VM, we finally change the parameter passed to run() from &[u8] to &Pgm . That is what caused the most changes inside vm.rs . The real additions are few.","title":"A new Program"},{"location":"2024-02/ALL.html#variables-in-the-vm","text":"The VM itself gets a new field: fb: usize . That is the frame base register, and it currently does nothing but point to the position inside the stack behind the last global variable. So with zero variables, nothing changes. We also add RuntimeError::InvalidVariable . Initialising the VM now includes making space for the variables: src/vm.rs 146 147 148 149 150 // create global variables in stack: for _ in 0 .. pgm . vars { self . push ( 0 ) ? ; } self . fb = pgm . vars as usize ; Popping values now needs to respect the frame base register, so it now looks this: src/vm.rs 68 69 70 71 72 73 74 75 /// Tries and pops a value from value stack, respecting frame base. fn pop ( & mut self ) -> Result < i64 , RuntimeError > { if self . stack . len () > self . fb { Ok ( self . stack . pop (). unwrap ()) } else { Err ( RuntimeError :: StackUnderflow ) } } And we need operation handlers, of course: src/vm.rs 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 op :: STORE => { let idx = self . fetch_u8 ( pgm ) ? ; if idx >= pgm . vars { Err ( RuntimeError :: InvalidVariable ) } else { let v = self . pop () ? ; self . stack [ idx as usize ] = v ; Ok (()) } }, op :: LOAD => { let idx = self . fetch_u8 ( pgm ) ? ; if idx >= pgm . vars { Err ( RuntimeError :: InvalidVariable ) } else { self . push ( self . stack [ idx as usize ]) ? ; Ok (()) } }, That's it. We now support variables!","title":"Variables in the VM"},{"location":"2024-02/ALL.html#show-me-your-values","text":"I added another operation with the opname out . It pops a value from the stack and prints it to stdout. This is not an operation that you would normally want in your VM. Output should be generated by function calls. But we don't have those, yet. I want something to easily show values during development, so you can see what happens, without always using --trace . We can always remove it, later. There is nothing new to that operation, so I won't discuss the code here.","title":"Show me your values"},{"location":"2024-02/ALL.html#a-new-program_1","text":"pgm/duplicate.lva 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 ## A program demonstrating use of variables. start: # val = 1 push_u8 1 store val # variable is declared implicitly here. We only have one type: i64 # for loop, 5 rounds: push_u8 5 loop: # val = val * 2: load val push_u8 2 mul store val # check loop counter: push_u8 1 sub dup ifgt loop end: pop # output final value of val load val out fin The program is documented with comments. And you might have noticed that I define labels that I never use. I just want to structure the program and name its parts. We don't have functions, so I use what we have. kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/duplicate.lva --print Compiling lovem v0.0.13 (/home/kratenko/git/lovem) Finished dev [unoptimized + debuginfo] target(s) in 2.66s Running `target/debug/lovas -r pgm/duplicate.lva --print` Pgm { name: \"pgm/duplicate.lva\", text: [2, 1, 4, 0, 2, 5, 5, 0, 2, 2, 18, 4, 0, 2, 1, 17, 3, 37, 255, 242, 1, 5, 0, 6, 255], vars: 1 } Out: 32 (@46) Terminated. Runtime=18.156\u00b5s op_cnt=47, pc=25, stack-depth=1, watermark=4 It outputs a 32. That is good, because we start with a 1 and multiply it by 2 five times. We can write programs!","title":"A new program!"},{"location":"2024-02/ALL.html#oh-and-a-bugfix","text":"I found out that I introduced a bug when writing the parsing label definitions. I parsed for the colon : , before I removed the comments. So a line with no label definition, but with a comment containing a colon did produce a parsing error. ## this was fine :label # this was fine :another # even this : was fine ## but this would produce an error: just a colon in a comment I fixed that by removing comments from lines first.","title":"Oh... and a bugfix"},{"location":"2024-02/NAV.html","text":"We have variables! Stop right there, that's far enough! It has been a while...","title":"NAV"},{"location":"2024-02/it-has-been-a-while.html","text":"It has been a while... \u00b6 Love is not dead! It just got distracted. kratenko \u00b7 kratenko 2024-02-01 \u00b7 Entry #28 \u00b7 1 min read Yes, I have been gone for a while. More than a year, in fact. The project \u2013 lovem \u2013 is not dead, however. In fact, I even have multiple posts already written, that I just need to publish. So let's start doing that. After this short intermission, I will publish an additional entry in the journey, that will take us further along the path to creating our VM. To be quite honest \u2013 I dated this entry back to yesterday. The reason is, that my journal, as I currently run it, does not really support multiple entries on the same day. Yes, I could simply add a time to the publication date, but that breaks continuity. And I don't plan to normally release multiple entries on the same day, as I want to keep the pace not too high. One post every two or three days is what I aim for, just the way I used to have it. A few things have changed in the meantime. For reasons that I have no desire to explain, I have removed the link to my Twitter account from the journal, and replaced it with a link to my Mastodon account. You can find me under @kratenko@chaos.social there. I also used to announce new entries over Twitter. I guess I will move that over to Mastodon as well. I guess we will see how that goes. But now let's get back to the journey. We will next implement a simple feature, that makes allows the VM to limit the processing time of a program \u2013 which can be very useful, especially when running user supplied code inside the machine. Building an endless loop inside a turing complete (or not even) language is quite easy. Having an embedded device stuck in an endless loop is often a catastrophe...","title":" It has been a while..."},{"location":"2024-02/it-has-been-a-while.html#it-has-been-a-while","text":"Love is not dead! It just got distracted. kratenko \u00b7 kratenko 2024-02-01 \u00b7 Entry #28 \u00b7 1 min read Yes, I have been gone for a while. More than a year, in fact. The project \u2013 lovem \u2013 is not dead, however. In fact, I even have multiple posts already written, that I just need to publish. So let's start doing that. After this short intermission, I will publish an additional entry in the journey, that will take us further along the path to creating our VM. To be quite honest \u2013 I dated this entry back to yesterday. The reason is, that my journal, as I currently run it, does not really support multiple entries on the same day. Yes, I could simply add a time to the publication date, but that breaks continuity. And I don't plan to normally release multiple entries on the same day, as I want to keep the pace not too high. One post every two or three days is what I aim for, just the way I used to have it. A few things have changed in the meantime. For reasons that I have no desire to explain, I have removed the link to my Twitter account from the journal, and replaced it with a link to my Mastodon account. You can find me under @kratenko@chaos.social there. I also used to announce new entries over Twitter. I guess I will move that over to Mastodon as well. I guess we will see how that goes. But now let's get back to the journey. We will next implement a simple feature, that makes allows the VM to limit the processing time of a program \u2013 which can be very useful, especially when running user supplied code inside the machine. Building an endless loop inside a turing complete (or not even) language is quite easy. Having an embedded device stuck in an endless loop is often a catastrophe...","title":"It has been a while..."},{"location":"2024-02/stop-right-there-that-s-far-enough.html","text":"Stop right there, that's far enough! \u00b6 We introduce an optional execution limit to our VM. kratenko \u00b7 kratenko 2024-02-02 \u00b7 Entry #29 \u00b7 3 min read \u00b7 v0.0.12-journey Since we have goto , we can write looping programs. With if* we have potentially looping programs as well. Both of this open the potential for endless loops. There are situations, in which endless loops are required. But often they are something to be avoided. Looping a long time \u00b6 Let us look at a little program: pgm/long-loop.lva 1 2 3 4 5 6 7 8 9 10 # Looping a looooong time. # This program will not run forever, but you will not see it terminate either. push_u8 0 loop: push_u8 1 add dup ifgt loop pop fin Someone messed up the loop condition there. If you run this program, it will be running for a long time. We start at zero and add to the value until our number is smaller than 0. Sounds impossible to reach for normal people, programmers will now better. Eventually we will reach the integer overflow, and our signed integer will loop around from its highest possible value to the lowest possible one. But do remember, what type we currently use to store our values: i64 . So how big is that highest number? 9223372036854775807 Is that a lot? That depends. Last entry I had my program loop for 1 million rounds. It took my modern laptop about half a second. So reaching that number should take 9223372036854.775807 times as long, that is around 4611686018427 seconds or just about 146135 years. Is that a lot? Oh, and by the way, the Rust professionals reading this will have spotted a potentially false claim there. While we run our program in debug mode, there will be no integer wraparound, instead the program will panic. If we build our Rust program in release mode, we will have integer wraparound, and will (theoretically) eventually reach the end of our loop. But that is besides the point. Limited execution \u00b6 The reason I started writing lovem , is that I need an embeddable lightweight VM to execute programmable handlers when certain events occur on my restrained embedded devices. So we are talking about some form of user generated content that is executed as a program! We can never trust those programs to be solid. We need a way to limit execution in some way, so that the device has the possibility to terminate those programs. There is an easy way to achieve that with what we already have. We put a limit on the number of operations the VM will execute. We add a few lines to our VM's main loop: src/vm.rs 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 // Loop going through the whole program, one instruction at a time. loop { // Log the vm's complete state, so we can follow what happens in console: if self . trace { println! ( \"{:?}\" , self ); } // Fetch next opcode from program (increases program counter): let opcode = self . fetch_u8 ( pgm ) ? ; // Limit execution by number of instructions that will be executed: if self . instruction_limit != 0 && self . op_cnt >= self . instruction_limit { return Err ( RuntimeError :: InstructionLimitExceeded ); } // We count the number of instructions we execute: self . op_cnt += 1 ; // If we are done, break loop and stop execution: if opcode == op :: FIN { break ; } // Execute the current instruction (with the opcode we loaded already): self . execute_op ( pgm , opcode ) ? ; } And of course we also add that new RuntimeError::InstructionLimitExceeded and a new field pub instruction_limit: usize, to our VM struct. lovas gets a new optional parameter: src/bin/lovas.rs 34 35 #[clap(long, default_value_t = 1000000, help = \"Limit max number of instructions allowed for execution. 0 for unlimited.\" )] instruction_limit : usize , And we need to pass that to the VM in the run() function: src/bin/lovas.rs 38 39 40 41 42 43 44 45 46 47 /// Executes a program in a freshly created lovem VM. fn run ( pgm : & Pgm , args : & Cli ) -> Result < () > { // Create our VM instance. let mut vm = VM :: new ( args . stack_size ); vm . trace = args . trace ; vm . instruction_limit = args . instruction_limit ; let start = Instant :: now (); let outcome = vm . run ( & pgm . text ); let duration = start . elapsed (); .. . And, well, that's it. We now have an optional execution limitation that we default at 1 million. Testing it \u00b6 kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/long-loop.lva --print Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas -r pgm/long-loop.lva --print` Pgm { name: \"pgm/long-loop.lva\", text: [2, 0, 2, 1, 16, 3, 37, 255, 249, 1, 255] } Runtime error! Runtime=142.400812ms op_cnt=1000000, pc=7, stack-depth=2, watermark=2 Error: InstructionLimitExceeded We can adjust it easily: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/long-loop.lva --print --instruction-limit=100 Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas -r pgm/long-loop.lva --print --instruction-limit=100` Pgm { name: \"pgm/long-loop.lva\", text: [2, 0, 2, 1, 16, 3, 37, 255, 249, 1, 255] } Runtime error! Runtime=19.096\u00b5s op_cnt=100, pc=7, stack-depth=2, watermark=2 Error: InstructionLimitExceeded And we can just as well disable it completely: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/long-loop.lva --print --instruction-limit=0 Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas -r pgm/long-loop.lva --print --instruction-limit=0` Pgm { name: \"pgm/long-loop.lva\", text: [2, 0, 2, 1, 16, 3, 37, 255, 249, 1, 255] } Good luck waiting for this one. I hope you know how to terminate a running program on your system... The source code for this post can be found under the tag v0.0.12-journey . v0.0.12-journey source code v0.0.12-journey release v0.0.12-journey.zip v0.0.12-journey.tar.gz git checkout v0.0.12-journey What does this mean?","title":" Stop right there, that's far enough!"},{"location":"2024-02/stop-right-there-that-s-far-enough.html#stop-right-there-thats-far-enough","text":"We introduce an optional execution limit to our VM. kratenko \u00b7 kratenko 2024-02-02 \u00b7 Entry #29 \u00b7 3 min read \u00b7 v0.0.12-journey Since we have goto , we can write looping programs. With if* we have potentially looping programs as well. Both of this open the potential for endless loops. There are situations, in which endless loops are required. But often they are something to be avoided.","title":"Stop right there, that's far enough!"},{"location":"2024-02/stop-right-there-that-s-far-enough.html#looping-a-long-time","text":"Let us look at a little program: pgm/long-loop.lva 1 2 3 4 5 6 7 8 9 10 # Looping a looooong time. # This program will not run forever, but you will not see it terminate either. push_u8 0 loop: push_u8 1 add dup ifgt loop pop fin Someone messed up the loop condition there. If you run this program, it will be running for a long time. We start at zero and add to the value until our number is smaller than 0. Sounds impossible to reach for normal people, programmers will now better. Eventually we will reach the integer overflow, and our signed integer will loop around from its highest possible value to the lowest possible one. But do remember, what type we currently use to store our values: i64 . So how big is that highest number? 9223372036854775807 Is that a lot? That depends. Last entry I had my program loop for 1 million rounds. It took my modern laptop about half a second. So reaching that number should take 9223372036854.775807 times as long, that is around 4611686018427 seconds or just about 146135 years. Is that a lot? Oh, and by the way, the Rust professionals reading this will have spotted a potentially false claim there. While we run our program in debug mode, there will be no integer wraparound, instead the program will panic. If we build our Rust program in release mode, we will have integer wraparound, and will (theoretically) eventually reach the end of our loop. But that is besides the point.","title":"Looping a long time"},{"location":"2024-02/stop-right-there-that-s-far-enough.html#limited-execution","text":"The reason I started writing lovem , is that I need an embeddable lightweight VM to execute programmable handlers when certain events occur on my restrained embedded devices. So we are talking about some form of user generated content that is executed as a program! We can never trust those programs to be solid. We need a way to limit execution in some way, so that the device has the possibility to terminate those programs. There is an easy way to achieve that with what we already have. We put a limit on the number of operations the VM will execute. We add a few lines to our VM's main loop: src/vm.rs 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 // Loop going through the whole program, one instruction at a time. loop { // Log the vm's complete state, so we can follow what happens in console: if self . trace { println! ( \"{:?}\" , self ); } // Fetch next opcode from program (increases program counter): let opcode = self . fetch_u8 ( pgm ) ? ; // Limit execution by number of instructions that will be executed: if self . instruction_limit != 0 && self . op_cnt >= self . instruction_limit { return Err ( RuntimeError :: InstructionLimitExceeded ); } // We count the number of instructions we execute: self . op_cnt += 1 ; // If we are done, break loop and stop execution: if opcode == op :: FIN { break ; } // Execute the current instruction (with the opcode we loaded already): self . execute_op ( pgm , opcode ) ? ; } And of course we also add that new RuntimeError::InstructionLimitExceeded and a new field pub instruction_limit: usize, to our VM struct. lovas gets a new optional parameter: src/bin/lovas.rs 34 35 #[clap(long, default_value_t = 1000000, help = \"Limit max number of instructions allowed for execution. 0 for unlimited.\" )] instruction_limit : usize , And we need to pass that to the VM in the run() function: src/bin/lovas.rs 38 39 40 41 42 43 44 45 46 47 /// Executes a program in a freshly created lovem VM. fn run ( pgm : & Pgm , args : & Cli ) -> Result < () > { // Create our VM instance. let mut vm = VM :: new ( args . stack_size ); vm . trace = args . trace ; vm . instruction_limit = args . instruction_limit ; let start = Instant :: now (); let outcome = vm . run ( & pgm . text ); let duration = start . elapsed (); .. . And, well, that's it. We now have an optional execution limitation that we default at 1 million.","title":"Limited execution"},{"location":"2024-02/stop-right-there-that-s-far-enough.html#testing-it","text":"kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/long-loop.lva --print Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas -r pgm/long-loop.lva --print` Pgm { name: \"pgm/long-loop.lva\", text: [2, 0, 2, 1, 16, 3, 37, 255, 249, 1, 255] } Runtime error! Runtime=142.400812ms op_cnt=1000000, pc=7, stack-depth=2, watermark=2 Error: InstructionLimitExceeded We can adjust it easily: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/long-loop.lva --print --instruction-limit=100 Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas -r pgm/long-loop.lva --print --instruction-limit=100` Pgm { name: \"pgm/long-loop.lva\", text: [2, 0, 2, 1, 16, 3, 37, 255, 249, 1, 255] } Runtime error! Runtime=19.096\u00b5s op_cnt=100, pc=7, stack-depth=2, watermark=2 Error: InstructionLimitExceeded And we can just as well disable it completely: kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/long-loop.lva --print --instruction-limit=0 Finished dev [unoptimized + debuginfo] target(s) in 0.02s Running `target/debug/lovas -r pgm/long-loop.lva --print --instruction-limit=0` Pgm { name: \"pgm/long-loop.lva\", text: [2, 0, 2, 1, 16, 3, 37, 255, 249, 1, 255] } Good luck waiting for this one. I hope you know how to terminate a running program on your system... The source code for this post can be found under the tag v0.0.12-journey . v0.0.12-journey source code v0.0.12-journey release v0.0.12-journey.zip v0.0.12-journey.tar.gz git checkout v0.0.12-journey What does this mean?","title":"Testing it"},{"location":"2024-02/we-have-variables.html","text":"We have variables! \u00b6 A stack alone is not that mighty. But now we can stow data away. kratenko \u00b7 kratenko 2024-02-11 \u00b7 Entry #30 \u00b7 4 min read \u00b7 v0.0.13-journey I implemented variables for the VM. And I did it in a way, that will freak out programmers, who have only ever worked with high languages in well-behaved environments \u2013 we now have variable support, but for global variables only. Why would I do that? Well, it was easy. You might be surprised how easy it was. And it helps a lot in having something useful. For what I am going for, it would actually be a viable thing, too. You could do a lot. But don't worry, I want local variables, too. Tell me were to stick it \u00b6 Variables need to live somewhere. When I first talked about stack machines, I said that \"no other direct manipulations of the stack [were] allowed [but push or pop].\" We will now see, why I added the direct there. Variables hold values; words, to be more precise. We have an entity, that can hold an arbitrary number of words: the stack. So, what is the idea? When I write a program, I will know how many variables it will need. Actually, our assembler now can do that for us. When I pass the program to the VM for execution, it looks at that number, and pushes that many zeros on the stack. Then it marks the current stack position as the new bottom. It does that by the newly introduces special Frame Base Register (FB) . What's with that funny name? This is something I will need later, when I introduce real function calls inside the VM. A call will create a new frame that is somewhat like a new local execution environment. This will also allow for local variables (told ya, I want those). But for now we have up to 256 global variables at our disposal. That is quite a bit. Variable operations \u00b6 There are two new operations for handling global variables: store : pop a value from the stack and store it in the global variable identified by the 1-byte oparg. load : read value from the global variable identified by the 1-byte oparg and push it to the stack. Variables in the assembler \u00b6 This took more work than the changes in the VM. That is good, because we want to hide complexity away from the VM. The assembler runs on a powerful computer, and typically programs are run more often than they are assembled/compiled. I want named variables in assembler source. The VM works only with numbers to identify them. Our assembler translates that for us. store and load each take the name of a variable as argument. When the assembler finds a new variable name, it is assigned a number (starting at 0). We actually just chunk them in a Vector and run through it everytime. We only support 256 variables, so there is no need to optimise there. It's fast enough. The index number is written as u8 as a single byte oparg. I leave it to you to look at the new source code in asm.rs this time. It is not too hard, and you should know enough Rust by now. A new Program \u00b6 There is more information to store for a Program now, than only the text (aka. the bytecode): the global variables. The information we store is just the number of variables the program has. That is all we need, we are not interested in their names. And it is the bytecode's responsibility, to access the correct variables. But since we now need that information in the VM, we finally change the parameter passed to run() from &[u8] to &Pgm . That is what caused the most changes inside vm.rs . The real additions are few. Variables in the VM \u00b6 The VM itself gets a new field: fb: usize . That is the frame base register, and it currently does nothing but point to the position inside the stack behind the last global variable. So with zero variables, nothing changes. We also add RuntimeError::InvalidVariable . Initialising the VM now includes making space for the variables: src/vm.rs 146 147 148 149 150 // create global variables in stack: for _ in 0 .. pgm . vars { self . push ( 0 ) ? ; } self . fb = pgm . vars as usize ; Popping values now needs to respect the frame base register, so it now looks this: src/vm.rs 68 69 70 71 72 73 74 75 /// Tries and pops a value from value stack, respecting frame base. fn pop ( & mut self ) -> Result < i64 , RuntimeError > { if self . stack . len () > self . fb { Ok ( self . stack . pop (). unwrap ()) } else { Err ( RuntimeError :: StackUnderflow ) } } And we need operation handlers, of course: src/vm.rs 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 op :: STORE => { let idx = self . fetch_u8 ( pgm ) ? ; if idx >= pgm . vars { Err ( RuntimeError :: InvalidVariable ) } else { let v = self . pop () ? ; self . stack [ idx as usize ] = v ; Ok (()) } }, op :: LOAD => { let idx = self . fetch_u8 ( pgm ) ? ; if idx >= pgm . vars { Err ( RuntimeError :: InvalidVariable ) } else { self . push ( self . stack [ idx as usize ]) ? ; Ok (()) } }, That's it. We now support variables! Show me your values \u00b6 I added another operation with the opname out . It pops a value from the stack and prints it to stdout. This is not an operation that you would normally want in your VM. Output should be generated by function calls. But we don't have those, yet. I want something to easily show values during development, so you can see what happens, without always using --trace . We can always remove it, later. There is nothing new to that operation, so I won't discuss the code here. A new program! \u00b6 pgm/duplicate.lva 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # A program demonstrating use of variables. start: # val = 1 push_u8 1 store val # variable is declared implicitly here. We only have one type: i64 # for loop, 5 rounds: push_u8 5 loop: # val = val * 2: load val push_u8 2 mul store val # check loop counter: push_u8 1 sub dup ifgt loop end: pop # output final value of val load val out fin The program is documented with comments. And you might have noticed that I define labels that I never use. I just want to structure the program and name its parts. We don't have functions, so I use what we have. kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/duplicate.lva --print Compiling lovem v0.0.13 (/home/kratenko/git/lovem) Finished dev [unoptimized + debuginfo] target(s) in 2.66s Running `target/debug/lovas -r pgm/duplicate.lva --print` Pgm { name: \"pgm/duplicate.lva\", text: [2, 1, 4, 0, 2, 5, 5, 0, 2, 2, 18, 4, 0, 2, 1, 17, 3, 37, 255, 242, 1, 5, 0, 6, 255], vars: 1 } Out: 32 (@46) Terminated. Runtime=18.156\u00b5s op_cnt=47, pc=25, stack-depth=1, watermark=4 It outputs a 32. That is good, because we start with a 1 and multiply it by 2 five times. We can write programs! Oh... and a bugfix \u00b6 I found out that I introduced a bug when writing the parsing label definitions. I parsed for the colon : , before I removed the comments. So a line with no label definition, but with a comment containing a colon did produce a parsing error. # this was fine :label # this was fine :another # even this : was fine # but this would produce an error: just a colon in a comment I fixed that by removing comments from lines first. The source code for this post can be found under the tag v0.0.13-journey . v0.0.13-journey source code v0.0.13-journey release v0.0.13-journey.zip v0.0.13-journey.tar.gz git checkout v0.0.13-journey What does this mean?","title":" We have variables!"},{"location":"2024-02/we-have-variables.html#we-have-variables","text":"A stack alone is not that mighty. But now we can stow data away. kratenko \u00b7 kratenko 2024-02-11 \u00b7 Entry #30 \u00b7 4 min read \u00b7 v0.0.13-journey I implemented variables for the VM. And I did it in a way, that will freak out programmers, who have only ever worked with high languages in well-behaved environments \u2013 we now have variable support, but for global variables only. Why would I do that? Well, it was easy. You might be surprised how easy it was. And it helps a lot in having something useful. For what I am going for, it would actually be a viable thing, too. You could do a lot. But don't worry, I want local variables, too.","title":"We have variables!"},{"location":"2024-02/we-have-variables.html#tell-me-were-to-stick-it","text":"Variables need to live somewhere. When I first talked about stack machines, I said that \"no other direct manipulations of the stack [were] allowed [but push or pop].\" We will now see, why I added the direct there. Variables hold values; words, to be more precise. We have an entity, that can hold an arbitrary number of words: the stack. So, what is the idea? When I write a program, I will know how many variables it will need. Actually, our assembler now can do that for us. When I pass the program to the VM for execution, it looks at that number, and pushes that many zeros on the stack. Then it marks the current stack position as the new bottom. It does that by the newly introduces special Frame Base Register (FB) . What's with that funny name? This is something I will need later, when I introduce real function calls inside the VM. A call will create a new frame that is somewhat like a new local execution environment. This will also allow for local variables (told ya, I want those). But for now we have up to 256 global variables at our disposal. That is quite a bit.","title":"Tell me were to stick it"},{"location":"2024-02/we-have-variables.html#variable-operations","text":"There are two new operations for handling global variables: store : pop a value from the stack and store it in the global variable identified by the 1-byte oparg. load : read value from the global variable identified by the 1-byte oparg and push it to the stack.","title":"Variable operations"},{"location":"2024-02/we-have-variables.html#variables-in-the-assembler","text":"This took more work than the changes in the VM. That is good, because we want to hide complexity away from the VM. The assembler runs on a powerful computer, and typically programs are run more often than they are assembled/compiled. I want named variables in assembler source. The VM works only with numbers to identify them. Our assembler translates that for us. store and load each take the name of a variable as argument. When the assembler finds a new variable name, it is assigned a number (starting at 0). We actually just chunk them in a Vector and run through it everytime. We only support 256 variables, so there is no need to optimise there. It's fast enough. The index number is written as u8 as a single byte oparg. I leave it to you to look at the new source code in asm.rs this time. It is not too hard, and you should know enough Rust by now.","title":"Variables in the assembler"},{"location":"2024-02/we-have-variables.html#a-new-program","text":"There is more information to store for a Program now, than only the text (aka. the bytecode): the global variables. The information we store is just the number of variables the program has. That is all we need, we are not interested in their names. And it is the bytecode's responsibility, to access the correct variables. But since we now need that information in the VM, we finally change the parameter passed to run() from &[u8] to &Pgm . That is what caused the most changes inside vm.rs . The real additions are few.","title":"A new Program"},{"location":"2024-02/we-have-variables.html#variables-in-the-vm","text":"The VM itself gets a new field: fb: usize . That is the frame base register, and it currently does nothing but point to the position inside the stack behind the last global variable. So with zero variables, nothing changes. We also add RuntimeError::InvalidVariable . Initialising the VM now includes making space for the variables: src/vm.rs 146 147 148 149 150 // create global variables in stack: for _ in 0 .. pgm . vars { self . push ( 0 ) ? ; } self . fb = pgm . vars as usize ; Popping values now needs to respect the frame base register, so it now looks this: src/vm.rs 68 69 70 71 72 73 74 75 /// Tries and pops a value from value stack, respecting frame base. fn pop ( & mut self ) -> Result < i64 , RuntimeError > { if self . stack . len () > self . fb { Ok ( self . stack . pop (). unwrap ()) } else { Err ( RuntimeError :: StackUnderflow ) } } And we need operation handlers, of course: src/vm.rs 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 op :: STORE => { let idx = self . fetch_u8 ( pgm ) ? ; if idx >= pgm . vars { Err ( RuntimeError :: InvalidVariable ) } else { let v = self . pop () ? ; self . stack [ idx as usize ] = v ; Ok (()) } }, op :: LOAD => { let idx = self . fetch_u8 ( pgm ) ? ; if idx >= pgm . vars { Err ( RuntimeError :: InvalidVariable ) } else { self . push ( self . stack [ idx as usize ]) ? ; Ok (()) } }, That's it. We now support variables!","title":"Variables in the VM"},{"location":"2024-02/we-have-variables.html#show-me-your-values","text":"I added another operation with the opname out . It pops a value from the stack and prints it to stdout. This is not an operation that you would normally want in your VM. Output should be generated by function calls. But we don't have those, yet. I want something to easily show values during development, so you can see what happens, without always using --trace . We can always remove it, later. There is nothing new to that operation, so I won't discuss the code here.","title":"Show me your values"},{"location":"2024-02/we-have-variables.html#a-new-program_1","text":"pgm/duplicate.lva 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # A program demonstrating use of variables. start: # val = 1 push_u8 1 store val # variable is declared implicitly here. We only have one type: i64 # for loop, 5 rounds: push_u8 5 loop: # val = val * 2: load val push_u8 2 mul store val # check loop counter: push_u8 1 sub dup ifgt loop end: pop # output final value of val load val out fin The program is documented with comments. And you might have noticed that I define labels that I never use. I just want to structure the program and name its parts. We don't have functions, so I use what we have. kratenko@jotun:~/git/lovem$ cargo run --bin lovas -- -r pgm/duplicate.lva --print Compiling lovem v0.0.13 (/home/kratenko/git/lovem) Finished dev [unoptimized + debuginfo] target(s) in 2.66s Running `target/debug/lovas -r pgm/duplicate.lva --print` Pgm { name: \"pgm/duplicate.lva\", text: [2, 1, 4, 0, 2, 5, 5, 0, 2, 2, 18, 4, 0, 2, 1, 17, 3, 37, 255, 242, 1, 5, 0, 6, 255], vars: 1 } Out: 32 (@46) Terminated. Runtime=18.156\u00b5s op_cnt=47, pc=25, stack-depth=1, watermark=4 It outputs a 32. That is good, because we start with a 1 and multiply it by 2 five times. We can write programs!","title":"A new program!"},{"location":"2024-02/we-have-variables.html#oh-and-a-bugfix","text":"I found out that I introduced a bug when writing the parsing label definitions. I parsed for the colon : , before I removed the comments. So a line with no label definition, but with a comment containing a colon did produce a parsing error. # this was fine :label # this was fine :another # even this : was fine # but this would produce an error: just a colon in a comment I fixed that by removing comments from lines first. The source code for this post can be found under the tag v0.0.13-journey . v0.0.13-journey source code v0.0.13-journey release v0.0.13-journey.zip v0.0.13-journey.tar.gz git checkout v0.0.13-journey What does this mean?","title":"Oh... and a bugfix"},{"location":"journal/index.html","text":"Jounal \u00b6 Starting points \u00b6 Latest entry \u00b6 We have variables! 2024-02-11 \u00b7 Entry #30 \u00b7 4 min read \u00b7 v0.0.13-journey First entry \u00b6 Lovem again! 2022-06-24 \u00b7 Entry #1 \u00b7 2 min read Complete month in single page \u00b6 If you want to read the whole story, this might be easier to follow. June 2022 complete July 2022 complete August 2022 complete February 2024 complete","title":"Jounal"},{"location":"journal/index.html#jounal","text":"","title":"Jounal"},{"location":"journal/index.html#starting-points","text":"","title":"Starting points"},{"location":"journal/index.html#latest-entry","text":"We have variables! 2024-02-11 \u00b7 Entry #30 \u00b7 4 min read \u00b7 v0.0.13-journey","title":"Latest entry"},{"location":"journal/index.html#first-entry","text":"Lovem again! 2022-06-24 \u00b7 Entry #1 \u00b7 2 min read","title":"First entry"},{"location":"journal/index.html#complete-month-in-single-page","text":"If you want to read the whole story, this might be easier to follow. June 2022 complete July 2022 complete August 2022 complete February 2024 complete","title":"Complete month in single page"},{"location":"journal/NAV.html","text":"February 2024 August 2022 July 2022 June 2022","title":"NAV"},{"location":"months/NAV.html","text":"February 2024 complete August 2022 complete July 2022 complete June 2022 complete","title":"NAV"}]}